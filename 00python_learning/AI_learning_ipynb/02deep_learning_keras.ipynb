{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0805 16:08:39.436510 19812 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0805 16:08:39.456848 19812 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0805 16:08:39.460815 19812 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0805 16:08:39.473222 19812 deprecation.py:506] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0805 16:08:39.504462 19812 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0805 16:08:39.625493 19812 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0805 16:08:39.633919 19812 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0805 16:08:39.763909 19812 deprecation.py:323] From c:\\python3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.4018 - acc: 0.3111\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 1.0412 - acc: 0.3852\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 389us/step - loss: 1.0861 - acc: 0.5852\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 375us/step - loss: 0.9945 - acc: 0.5852\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 400us/step - loss: 0.9932 - acc: 0.5704\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.9984 - acc: 0.5333\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.8786 - acc: 0.6000\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 375us/step - loss: 0.8718 - acc: 0.5481\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 375us/step - loss: 0.7917 - acc: 0.5926\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.7765 - acc: 0.5926\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 500us/step - loss: 0.6642 - acc: 0.6370\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 569us/step - loss: 0.6569 - acc: 0.6074\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 463us/step - loss: 0.6719 - acc: 0.6148\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.6625 - acc: 0.6593\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 430us/step - loss: 0.6986 - acc: 0.5926\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 489us/step - loss: 0.7024 - acc: 0.6148\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 452us/step - loss: 0.6292 - acc: 0.7037\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 441us/step - loss: 0.6535 - acc: 0.6815\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 375us/step - loss: 0.5803 - acc: 0.7111\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.6356 - acc: 0.6889\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.7118 - acc: 0.5852\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5793 - acc: 0.6815\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 478us/step - loss: 0.6134 - acc: 0.6815\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 356us/step - loss: 0.5419 - acc: 0.6889\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.6200 - acc: 0.6889\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 492us/step - loss: 0.5140 - acc: 0.7333\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 430us/step - loss: 0.5277 - acc: 0.7185\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.7069 - acc: 0.6593\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.6330 - acc: 0.6370\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 397us/step - loss: 0.5720 - acc: 0.7037\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 345us/step - loss: 0.5509 - acc: 0.7037\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 353us/step - loss: 0.5808 - acc: 0.7185\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 481us/step - loss: 0.6304 - acc: 0.6667\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.5821 - acc: 0.6815\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5823 - acc: 0.6889\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.6247 - acc: 0.6741\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5657 - acc: 0.7185\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 360us/step - loss: 0.5038 - acc: 0.7259\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 386us/step - loss: 0.5519 - acc: 0.7333\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 345us/step - loss: 0.6200 - acc: 0.6963\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.4615 - acc: 0.7481\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.5506 - acc: 0.7333\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4874 - acc: 0.7852\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.4856 - acc: 0.7111\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5311 - acc: 0.6963\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5706 - acc: 0.7259\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5421 - acc: 0.7111\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4836 - acc: 0.7037\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 345us/step - loss: 0.5372 - acc: 0.7259\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.5960 - acc: 0.7111\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.4786 - acc: 0.7852\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5866 - acc: 0.6741\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4835 - acc: 0.7407\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5592 - acc: 0.7259\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4733 - acc: 0.7630\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 173us/step - loss: 0.5529 - acc: 0.7259\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.4962 - acc: 0.7630\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.5815 - acc: 0.6815\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4888 - acc: 0.7333\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.6159 - acc: 0.6741\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.4704 - acc: 0.7407\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.5186 - acc: 0.7630\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5403 - acc: 0.7111\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 198us/step - loss: 0.6287 - acc: 0.7037\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.4979 - acc: 0.7778\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4882 - acc: 0.7333\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5048 - acc: 0.7259\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5542 - acc: 0.7333\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.5312 - acc: 0.7333\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5092 - acc: 0.7407\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4835 - acc: 0.7778\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.5177 - acc: 0.7333\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5739 - acc: 0.7037\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.5158 - acc: 0.7333\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.6125 - acc: 0.7037\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 176us/step - loss: 0.5180 - acc: 0.7704\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5681 - acc: 0.7481\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.4894 - acc: 0.7926\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5421 - acc: 0.7407\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5673 - acc: 0.6593\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.4762 - acc: 0.7259\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.5668 - acc: 0.7556\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5611 - acc: 0.7630\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5641 - acc: 0.7630\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 338us/step - loss: 0.4946 - acc: 0.7407\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5064 - acc: 0.7407\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5271 - acc: 0.7556\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4699 - acc: 0.7926\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4935 - acc: 0.7778\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5428 - acc: 0.7481\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4892 - acc: 0.7778\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5262 - acc: 0.7556\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 184us/step - loss: 0.6597 - acc: 0.7037\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5610 - acc: 0.7259\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 243us/step - loss: 0.5243 - acc: 0.7556\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5225 - acc: 0.7407\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.4945 - acc: 0.7407\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.5378 - acc: 0.7778\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 253us/step - loss: 0.5170 - acc: 0.7630\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 247us/step - loss: 0.5299 - acc: 0.7407\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4619 - acc: 0.8222\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5100 - acc: 0.7852\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5490 - acc: 0.7111\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 198us/step - loss: 0.4061 - acc: 0.8519\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 205us/step - loss: 0.6205 - acc: 0.6741\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 0.6137 - acc: 0.7185\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5057 - acc: 0.7333\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.5507 - acc: 0.7111\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4938 - acc: 0.7778\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.4241 - acc: 0.7704\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.6179 - acc: 0.7481\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.4489 - acc: 0.8222\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.5393 - acc: 0.7630\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5835 - acc: 0.7185\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.5567 - acc: 0.7259\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 243us/step - loss: 0.4380 - acc: 0.7926\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5463 - acc: 0.7407\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.5938 - acc: 0.7556\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.5208 - acc: 0.7556\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5838 - acc: 0.7259\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5476 - acc: 0.7407\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5391 - acc: 0.7111\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5238 - acc: 0.8000\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4793 - acc: 0.7556\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.4449 - acc: 0.7778\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4544 - acc: 0.7852\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.6166 - acc: 0.7481\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5100 - acc: 0.6815\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.4423 - acc: 0.7926\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5769 - acc: 0.7185\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.4716 - acc: 0.7852\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4991 - acc: 0.7556\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.4459 - acc: 0.7630\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5002 - acc: 0.7704\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5011 - acc: 0.8074\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5254 - acc: 0.7704\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 173us/step - loss: 0.5031 - acc: 0.7407\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.5390 - acc: 0.7481\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4654 - acc: 0.7778\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.5424 - acc: 0.7630\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5432 - acc: 0.7556\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.6466 - acc: 0.6593\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 180us/step - loss: 0.4648 - acc: 0.8444\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.4523 - acc: 0.7852\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.4254 - acc: 0.7926\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5578 - acc: 0.7407\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.4554 - acc: 0.7926\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5377 - acc: 0.7481\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5051 - acc: 0.7630\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5817 - acc: 0.7259\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5125 - acc: 0.7481\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5682 - acc: 0.7481\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4620 - acc: 0.7852\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5776 - acc: 0.7407\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 198us/step - loss: 0.5577 - acc: 0.7407\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4869 - acc: 0.8000\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4790 - acc: 0.7704\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.6024 - acc: 0.7037\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.6122 - acc: 0.7407\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 154us/step - loss: 0.5482 - acc: 0.7111\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5160 - acc: 0.7333\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5530 - acc: 0.7259\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5003 - acc: 0.7481\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4964 - acc: 0.7259\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 213us/step - loss: 0.5097 - acc: 0.7556\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5346 - acc: 0.7630\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4412 - acc: 0.8148\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4719 - acc: 0.8000\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5163 - acc: 0.7704\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4626 - acc: 0.7407\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.4752 - acc: 0.7481\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4997 - acc: 0.7407\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5399 - acc: 0.7111\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5349 - acc: 0.6889\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.5207 - acc: 0.7926\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.4970 - acc: 0.7481\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4002 - acc: 0.8444\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 187us/step - loss: 0.4846 - acc: 0.7704\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5610 - acc: 0.7111\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5914 - acc: 0.6889\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5238 - acc: 0.7556\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4809 - acc: 0.7481\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.4155 - acc: 0.8074\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4921 - acc: 0.7704\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5375 - acc: 0.7111\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5477 - acc: 0.7333\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4620 - acc: 0.7852\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.4937 - acc: 0.7556\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.4466 - acc: 0.7481\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5194 - acc: 0.7333\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5253 - acc: 0.7407\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5688 - acc: 0.7037\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5533 - acc: 0.7185\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 187us/step - loss: 0.4568 - acc: 0.7481\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4926 - acc: 0.7333\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5200 - acc: 0.7704\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.4661 - acc: 0.8222\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5101 - acc: 0.7556\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5092 - acc: 0.7704\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.5745 - acc: 0.7111\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1751 - acc: 0.3259\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 1.1124 - acc: 0.2963\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.9342 - acc: 0.5704\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.7581 - acc: 0.6815\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.7560 - acc: 0.5926\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.6598 - acc: 0.6963\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.7695 - acc: 0.5926\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.7812 - acc: 0.5926\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.6606 - acc: 0.6963\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.6372 - acc: 0.6963\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 275us/step - loss: 0.6915 - acc: 0.7111\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.6125 - acc: 0.7778\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.6407 - acc: 0.6519\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.6140 - acc: 0.7333\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6270 - acc: 0.7185\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.6512 - acc: 0.6963\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.6104 - acc: 0.7259\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5529 - acc: 0.7333\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5419 - acc: 0.7111\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.6148 - acc: 0.7259\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.6354 - acc: 0.6667\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.6474 - acc: 0.6963\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.6245 - acc: 0.6815\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5831 - acc: 0.6889\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6031 - acc: 0.7630\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.6504 - acc: 0.7111\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5259 - acc: 0.7778\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.6656 - acc: 0.6593\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6097 - acc: 0.7037\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5501 - acc: 0.7630\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5553 - acc: 0.7407\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5095 - acc: 0.7481\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4809 - acc: 0.7926\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.5176 - acc: 0.7556\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6192 - acc: 0.7333\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5339 - acc: 0.7556\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.6151 - acc: 0.7185\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5166 - acc: 0.7852\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4690 - acc: 0.7926\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5178 - acc: 0.8222\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4528 - acc: 0.8148\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5471 - acc: 0.7704\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.6615 - acc: 0.7481\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5349 - acc: 0.7259\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5081 - acc: 0.7852\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.6085 - acc: 0.7037\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 209us/step - loss: 0.5115 - acc: 0.8000\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5210 - acc: 0.7407\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6171 - acc: 0.7111\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.6310 - acc: 0.7333\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5477 - acc: 0.7259\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4826 - acc: 0.7556\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.5036 - acc: 0.7778\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4655 - acc: 0.8074\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5192 - acc: 0.7556\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5286 - acc: 0.7778\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.5883 - acc: 0.7259\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.5811 - acc: 0.7481\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4500 - acc: 0.8222\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5073 - acc: 0.8148\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.6044 - acc: 0.7037\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5435 - acc: 0.7111\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5873 - acc: 0.7481\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4833 - acc: 0.7481\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.5203 - acc: 0.7407\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.5856 - acc: 0.6963\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 253us/step - loss: 0.5418 - acc: 0.7333\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.4113 - acc: 0.8074\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.4916 - acc: 0.7556\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.6149 - acc: 0.6815\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.5916 - acc: 0.7481\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5318 - acc: 0.7852\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 198us/step - loss: 0.5175 - acc: 0.7926\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4333 - acc: 0.8074\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.4414 - acc: 0.8148\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.4763 - acc: 0.8148\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4825 - acc: 0.7926\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4908 - acc: 0.7852\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.4665 - acc: 0.7481\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5506 - acc: 0.7037\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4581 - acc: 0.8593\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.6100 - acc: 0.7259\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 253us/step - loss: 0.4087 - acc: 0.8667\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3747 - acc: 0.8815\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3709 - acc: 0.8593\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4319 - acc: 0.8815\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.3185 - acc: 0.9037\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.4088 - acc: 0.8889\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.4156 - acc: 0.8444\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3174 - acc: 0.8889\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3794 - acc: 0.8815\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3871 - acc: 0.8519\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.2732 - acc: 0.8963\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 198us/step - loss: 0.3123 - acc: 0.9333\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.3791 - acc: 0.8519\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3020 - acc: 0.8963\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3410 - acc: 0.9037\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 0.3444 - acc: 0.9111\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3458 - acc: 0.8963\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3922 - acc: 0.8815\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.3942 - acc: 0.8593\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.2535 - acc: 0.9111\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.2512 - acc: 0.9481\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.2915 - acc: 0.8741\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.2693 - acc: 0.8889\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 198us/step - loss: 0.2257 - acc: 0.9259\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.2695 - acc: 0.9259\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 199us/step - loss: 0.2794 - acc: 0.9037\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.2976 - acc: 0.8963\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.3732 - acc: 0.8889\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3021 - acc: 0.8815\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 187us/step - loss: 0.4460 - acc: 0.8296\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.3541 - acc: 0.8963\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.2682 - acc: 0.8741\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3068 - acc: 0.8889\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 198us/step - loss: 0.3439 - acc: 0.8519\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.3853 - acc: 0.8667\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.3561 - acc: 0.8741\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.2717 - acc: 0.9111\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.3104 - acc: 0.8815\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3286 - acc: 0.9037\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.2903 - acc: 0.8889\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 180us/step - loss: 0.3350 - acc: 0.8667\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3168 - acc: 0.8815\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 184us/step - loss: 0.2212 - acc: 0.9481\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.2458 - acc: 0.8815\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3172 - acc: 0.8815\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3115 - acc: 0.8889\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3993 - acc: 0.8519\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 187us/step - loss: 0.4029 - acc: 0.8370\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3939 - acc: 0.8593\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.3748 - acc: 0.8741\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.4241 - acc: 0.8000\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3010 - acc: 0.8889\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.2473 - acc: 0.9185\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 253us/step - loss: 0.2809 - acc: 0.8963\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.3495 - acc: 0.8593\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 0.3478 - acc: 0.8815\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.2551 - acc: 0.9333\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.2631 - acc: 0.9185\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3242 - acc: 0.9111\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.2367 - acc: 0.9259\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3278 - acc: 0.8889\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.3912 - acc: 0.8444\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.2259 - acc: 0.9111\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.2218 - acc: 0.9259\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.1949 - acc: 0.9481\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.3419 - acc: 0.8741\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4073 - acc: 0.8593\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 243us/step - loss: 0.3375 - acc: 0.8889\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3108 - acc: 0.8889\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3223 - acc: 0.8815\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 173us/step - loss: 0.2394 - acc: 0.9111\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.3091 - acc: 0.8815\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.2908 - acc: 0.8963\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.2784 - acc: 0.9037\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3538 - acc: 0.8889\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.2768 - acc: 0.9111\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.2558 - acc: 0.9185\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.2219 - acc: 0.9259\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 297us/step - loss: 0.1865 - acc: 0.9407\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.2157 - acc: 0.9037\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 375us/step - loss: 0.2603 - acc: 0.8963\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 397us/step - loss: 0.2521 - acc: 0.9259\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.2725 - acc: 0.9111\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.2763 - acc: 0.9111\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3504 - acc: 0.8148\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.3344 - acc: 0.8889\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.2571 - acc: 0.8963\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.5948 - acc: 0.800 - 0s 283us/step - loss: 0.2130 - acc: 0.9259\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.2621 - acc: 0.8963\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.2682 - acc: 0.9111\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.2733 - acc: 0.8963\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.2704 - acc: 0.9111\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.2442 - acc: 0.8889\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.2510 - acc: 0.9333\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 176us/step - loss: 0.2014 - acc: 0.9407\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.2194 - acc: 0.9185\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3532 - acc: 0.8741\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.2896 - acc: 0.8963\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3293 - acc: 0.8519\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.2527 - acc: 0.9111\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5078 - acc: 0.8148\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3630 - acc: 0.8593\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.2835 - acc: 0.9185\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.2270 - acc: 0.9333\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.2407 - acc: 0.9259\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.2484 - acc: 0.9185\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 165us/step - loss: 0.3045 - acc: 0.8963\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3201 - acc: 0.8889\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.2342 - acc: 0.9333\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.2018 - acc: 0.9556\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 232us/step - loss: 0.2278 - acc: 0.9259\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.2682 - acc: 0.8741\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.2287 - acc: 0.9259\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.2581 - acc: 0.9407\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 221us/step - loss: 0.2143 - acc: 0.9185\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4273 - acc: 0.8444\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 345us/step - loss: 0.3809 - acc: 0.8370\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 599us/step - loss: 0.3183 - acc: 0.8593\n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.4847 - acc: 0.1778\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 1.1039 - acc: 0.3111\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 1.1117 - acc: 0.3333\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 1.0728 - acc: 0.4815\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 1.0371 - acc: 0.4593\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 1.0146 - acc: 0.5333\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.9714 - acc: 0.6148\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.9188 - acc: 0.5704\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.8494 - acc: 0.6222\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 250us/step - loss: 0.8557 - acc: 0.5556\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.8046 - acc: 0.6074\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.7632 - acc: 0.6370\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.7552 - acc: 0.6222\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 243us/step - loss: 0.7258 - acc: 0.6519\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 367us/step - loss: 0.7181 - acc: 0.6667\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 963us/step - loss: 0.6741 - acc: 0.7037\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 573us/step - loss: 0.6333 - acc: 0.6963\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.6255 - acc: 0.7037\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.6439 - acc: 0.7037\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5841 - acc: 0.7111\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.6275 - acc: 0.7037\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.6107 - acc: 0.7407\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.6387 - acc: 0.6963\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.6495 - acc: 0.6889\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5755 - acc: 0.7407\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.6019 - acc: 0.6815\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5977 - acc: 0.6593\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 184us/step - loss: 0.6014 - acc: 0.7037\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.5922 - acc: 0.7556\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.6109 - acc: 0.7185\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5662 - acc: 0.7630\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.7847 - acc: 0.6074\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5583 - acc: 0.7185\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5721 - acc: 0.7185\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5784 - acc: 0.7481\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6329 - acc: 0.6148\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.6115 - acc: 0.7481\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5206 - acc: 0.7704\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.6533 - acc: 0.6889\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 441us/step - loss: 0.5810 - acc: 0.7407\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6111 - acc: 0.6889\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5586 - acc: 0.7333\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.6038 - acc: 0.6889\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5449 - acc: 0.7630\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5158 - acc: 0.7407\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5824 - acc: 0.7111\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5782 - acc: 0.7259\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5200 - acc: 0.7333\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.5552 - acc: 0.7111\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5525 - acc: 0.7926\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4697 - acc: 0.8148\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.6861 - acc: 0.6667\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.5891 - acc: 0.7037\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.4904 - acc: 0.8000\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5606 - acc: 0.7630\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5424 - acc: 0.7778\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.6159 - acc: 0.7037\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5625 - acc: 0.7556\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.6544 - acc: 0.6889\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5917 - acc: 0.7333\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5796 - acc: 0.6815\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5557 - acc: 0.7259\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 253us/step - loss: 0.5312 - acc: 0.7407\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 198us/step - loss: 0.4410 - acc: 0.8000\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4792 - acc: 0.7259\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5241 - acc: 0.7407\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.6240 - acc: 0.7259\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.6031 - acc: 0.7111\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5487 - acc: 0.7259\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.6535 - acc: 0.7111\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.5005 - acc: 0.7407\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5064 - acc: 0.7778\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5759 - acc: 0.6741\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5158 - acc: 0.7481\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.5486 - acc: 0.7704\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 243us/step - loss: 0.5897 - acc: 0.7111\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.4926 - acc: 0.7778\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.6140 - acc: 0.7407\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5000 - acc: 0.7556\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.4989 - acc: 0.7407\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5712 - acc: 0.6667\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4557 - acc: 0.7556\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.6313 - acc: 0.6963\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.6854 - acc: 0.6370\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.6095 - acc: 0.7630\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 180us/step - loss: 0.4852 - acc: 0.7704\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 184us/step - loss: 0.5621 - acc: 0.6889\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.5310 - acc: 0.7630\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.4867 - acc: 0.7926\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.5720 - acc: 0.7037\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 187us/step - loss: 0.5688 - acc: 0.7333\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5306 - acc: 0.7259\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.5072 - acc: 0.7481\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.6148 - acc: 0.6815\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5201 - acc: 0.7037\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.5750 - acc: 0.6963\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5184 - acc: 0.7259\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5942 - acc: 0.7333\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5772 - acc: 0.7111\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.5475 - acc: 0.7481\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5150 - acc: 0.7259\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5823 - acc: 0.6889\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5485 - acc: 0.6889\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4873 - acc: 0.7037\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5850 - acc: 0.7778\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 0.6704 - acc: 0.6593\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4517 - acc: 0.7926\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.6801 - acc: 0.6444\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4938 - acc: 0.7926\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 367us/step - loss: 0.4647 - acc: 0.7407\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.5787 - acc: 0.7259\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.5351 - acc: 0.7556\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5378 - acc: 0.7333\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 371us/step - loss: 0.4448 - acc: 0.8000\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5362 - acc: 0.7333\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5608 - acc: 0.7481\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.6040 - acc: 0.6963\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5447 - acc: 0.7037\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5728 - acc: 0.7704\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.5335 - acc: 0.7852\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5230 - acc: 0.7556\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4914 - acc: 0.7556\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.6213 - acc: 0.7111\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 243us/step - loss: 0.5328 - acc: 0.7926\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.6024 - acc: 0.7185\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5704 - acc: 0.6963\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.4579 - acc: 0.7778\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4521 - acc: 0.8074\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5654 - acc: 0.7407\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5546 - acc: 0.7037\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.6314 - acc: 0.6815\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5322 - acc: 0.7407\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5502 - acc: 0.7630\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5877 - acc: 0.7037\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.5869 - acc: 0.6593\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5592 - acc: 0.7704\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5785 - acc: 0.7185\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5673 - acc: 0.6889\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5123 - acc: 0.8000\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5367 - acc: 0.7481\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.5228 - acc: 0.7556\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5141 - acc: 0.7407\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5368 - acc: 0.7185\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5060 - acc: 0.7778\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5927 - acc: 0.6963\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5981 - acc: 0.7111\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5663 - acc: 0.7259\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.6952 - acc: 0.6815\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5658 - acc: 0.7333\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 176us/step - loss: 0.4672 - acc: 0.7778\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.4802 - acc: 0.8074\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4544 - acc: 0.7333\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5231 - acc: 0.7407\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5917 - acc: 0.6741\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5158 - acc: 0.7556\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5094 - acc: 0.8000\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5701 - acc: 0.7185\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.5021 - acc: 0.7852\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5562 - acc: 0.7630\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5036 - acc: 0.8074\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.6714 - acc: 0.7037\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4959 - acc: 0.7111\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5587 - acc: 0.7556\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.5617 - acc: 0.800 - 0s 206us/step - loss: 0.5929 - acc: 0.7111\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5585 - acc: 0.7185\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5374 - acc: 0.6963\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.6095 - acc: 0.7037\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5529 - acc: 0.7556\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 180us/step - loss: 0.5021 - acc: 0.7556\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4749 - acc: 0.8074\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 169us/step - loss: 0.6426 - acc: 0.7185\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.5652 - acc: 0.7333\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 246us/step - loss: 0.5353 - acc: 0.7556\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 221us/step - loss: 0.4923 - acc: 0.7704\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5032 - acc: 0.7704\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5044 - acc: 0.7778\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5743 - acc: 0.6889\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.5386 - acc: 0.7111\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5009 - acc: 0.7704\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5579 - acc: 0.7259\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5122 - acc: 0.7481\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.6128 - acc: 0.7556\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5786 - acc: 0.7630\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5644 - acc: 0.7630\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5714 - acc: 0.6963\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 0.6056 - acc: 0.7037\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.6425 - acc: 0.6667\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4990 - acc: 0.7778\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.4852 - acc: 0.6963\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5094 - acc: 0.7481\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.4918 - acc: 0.7630\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5139 - acc: 0.7111\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.5186 - acc: 0.6963\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5960 - acc: 0.7407\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6484 - acc: 0.7185\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.6293 - acc: 0.6963\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5475 - acc: 0.7037\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5955 - acc: 0.7333\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.6481 - acc: 0.6963\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4901 - acc: 0.7926\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.2828 - acc: 0.2741\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 1.0783 - acc: 0.3630\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 1.0282 - acc: 0.4370\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.9222 - acc: 0.6148\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.8420 - acc: 0.5778\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.8119 - acc: 0.6074\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.8249 - acc: 0.6000\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.7328 - acc: 0.6889\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.7274 - acc: 0.6444\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.7684 - acc: 0.6667\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.6979 - acc: 0.6667\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.7507 - acc: 0.6741\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.7426 - acc: 0.6519\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.7742 - acc: 0.6296\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.7520 - acc: 0.6889\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.7724 - acc: 0.6667\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.6690 - acc: 0.6889\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.6858 - acc: 0.6815\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.7621 - acc: 0.6370\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.6652 - acc: 0.6889\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.7113 - acc: 0.7111\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.6649 - acc: 0.6815\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5679 - acc: 0.7481\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5509 - acc: 0.7704\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.6043 - acc: 0.6815\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.6505 - acc: 0.6963\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5892 - acc: 0.7037\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.7244 - acc: 0.6963\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.6053 - acc: 0.7037\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5377 - acc: 0.7037\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.6055 - acc: 0.7037\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5500 - acc: 0.7926\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 243us/step - loss: 0.4985 - acc: 0.8148\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5788 - acc: 0.7630\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 187us/step - loss: 0.5629 - acc: 0.8000\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.6314 - acc: 0.7259\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5700 - acc: 0.7407\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.6364 - acc: 0.6889\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.6433 - acc: 0.7037\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5615 - acc: 0.7704\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.5119 - acc: 0.8370\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4313 - acc: 0.8222\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.4195 - acc: 0.8519\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.5724 - acc: 0.7556\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5839 - acc: 0.6963\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4847 - acc: 0.8222\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 172us/step - loss: 0.5595 - acc: 0.7333\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.6058 - acc: 0.7630\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 143us/step - loss: 0.5577 - acc: 0.7333\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.4512 - acc: 0.8370\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.4838 - acc: 0.8074\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5480 - acc: 0.7778\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5088 - acc: 0.7630\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.6754 - acc: 0.7111\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4845 - acc: 0.7704\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5054 - acc: 0.7333\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5464 - acc: 0.7333\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4834 - acc: 0.7926\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.5785 - acc: 0.7704\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5282 - acc: 0.7333\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4366 - acc: 0.8519\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.4567 - acc: 0.8000\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.4651 - acc: 0.8000\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5332 - acc: 0.7259\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4401 - acc: 0.8370\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4230 - acc: 0.7852\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4849 - acc: 0.8000\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.4943 - acc: 0.8000\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.4138 - acc: 0.8444\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.4398 - acc: 0.7630\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4093 - acc: 0.7926\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4578 - acc: 0.7778\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.4722 - acc: 0.8074\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.4244 - acc: 0.7778\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4283 - acc: 0.8222\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.4981 - acc: 0.7704\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.4644 - acc: 0.8000\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5034 - acc: 0.7556\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.4355 - acc: 0.7926\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.6783 - acc: 0.7259\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.4028 - acc: 0.8000\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3982 - acc: 0.8148\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4518 - acc: 0.8074\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5310 - acc: 0.7407\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.4481 - acc: 0.8296\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3492 - acc: 0.8296\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4102 - acc: 0.8296\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.3937 - acc: 0.8741\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4792 - acc: 0.7778\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 243us/step - loss: 0.4149 - acc: 0.8370\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 198us/step - loss: 0.5097 - acc: 0.7556\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.3596 - acc: 0.8296\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3953 - acc: 0.7778\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4387 - acc: 0.7926\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5403 - acc: 0.7185\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3575 - acc: 0.8593\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3575 - acc: 0.8222\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4166 - acc: 0.8000\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4848 - acc: 0.7704\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3985 - acc: 0.8519\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.3848 - acc: 0.8519\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.3712 - acc: 0.8222\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4420 - acc: 0.8593\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3614 - acc: 0.8370\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 184us/step - loss: 0.4853 - acc: 0.8296\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.3114 - acc: 0.8667\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3968 - acc: 0.8519\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3610 - acc: 0.8370\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3337 - acc: 0.8519\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 187us/step - loss: 0.4947 - acc: 0.7852\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.4367 - acc: 0.8444\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.4560 - acc: 0.8296\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4572 - acc: 0.8074\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 165us/step - loss: 0.4197 - acc: 0.8148\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4215 - acc: 0.8074\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4087 - acc: 0.8444\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.4108 - acc: 0.8074\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.3345 - acc: 0.8370\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3734 - acc: 0.8444\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.3365 - acc: 0.8889\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 187us/step - loss: 0.3876 - acc: 0.8148\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.3795 - acc: 0.8148\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 165us/step - loss: 0.4218 - acc: 0.7778\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 184us/step - loss: 0.3198 - acc: 0.8593\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 187us/step - loss: 0.3233 - acc: 0.8889\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3925 - acc: 0.8000\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 210us/step - loss: 0.4653 - acc: 0.8000\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4258 - acc: 0.8222\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.3535 - acc: 0.8222\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4124 - acc: 0.8370\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.3928 - acc: 0.8000\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.3836 - acc: 0.8370\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3365 - acc: 0.8741\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3791 - acc: 0.8370\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3308 - acc: 0.8593\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4345 - acc: 0.7926\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 235us/step - loss: 0.3582 - acc: 0.8444\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3253 - acc: 0.8667\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.4195 - acc: 0.8222\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3910 - acc: 0.8444\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.3899 - acc: 0.7926\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3680 - acc: 0.8963\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.3416 - acc: 0.8519\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.4254 - acc: 0.8444\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3030 - acc: 0.9037\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.3709 - acc: 0.8815\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5430 - acc: 0.7407\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3441 - acc: 0.8370\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.3657 - acc: 0.8296\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.4871 - acc: 0.8222\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4287 - acc: 0.7926\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3845 - acc: 0.8074\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.3629 - acc: 0.8519\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.3270 - acc: 0.8444\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.3894 - acc: 0.8519\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 0.3270 - acc: 0.8815\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3233 - acc: 0.8444\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.4130 - acc: 0.8444\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3115 - acc: 0.8370\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.3850 - acc: 0.8370\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4263 - acc: 0.8000\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.3356 - acc: 0.8444\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3699 - acc: 0.8519\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.4140 - acc: 0.8000\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.3955 - acc: 0.8296\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3504 - acc: 0.8815\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3722 - acc: 0.8519\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5747 - acc: 0.7481\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3348 - acc: 0.8667\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 221us/step - loss: 0.4173 - acc: 0.8000\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.3908 - acc: 0.8370\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 253us/step - loss: 0.3291 - acc: 0.8667\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.3266 - acc: 0.8296\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 162us/step - loss: 0.3545 - acc: 0.8444\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.3747 - acc: 0.8370\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3126 - acc: 0.8667\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.3766 - acc: 0.8370\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.2491 - acc: 0.9037\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.3202 - acc: 0.8519\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3712 - acc: 0.8222\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3200 - acc: 0.8667\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3438 - acc: 0.8296\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 253us/step - loss: 0.2812 - acc: 0.8889\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 198us/step - loss: 0.3046 - acc: 0.8519\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.4217 - acc: 0.8000\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3910 - acc: 0.8222\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3717 - acc: 0.8519\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3066 - acc: 0.8963\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.3570 - acc: 0.8444\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.2906 - acc: 0.8889\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3093 - acc: 0.8593\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4290 - acc: 0.8148\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.3498 - acc: 0.8667\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3019 - acc: 0.8815\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.4002 - acc: 0.8000\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.3897 - acc: 0.8222\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.2934 - acc: 0.8519\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3223 - acc: 0.8667\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3616 - acc: 0.8000\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.3390 - acc: 0.8444\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.2235 - acc: 0.4000\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.9297 - acc: 0.5111\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.8806 - acc: 0.5852\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.7817 - acc: 0.6296\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.7759 - acc: 0.6222\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.6920 - acc: 0.6222\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.7141 - acc: 0.6370\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.6883 - acc: 0.6148\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.7355 - acc: 0.6074\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.7072 - acc: 0.6296\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.7495 - acc: 0.6000\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.7079 - acc: 0.6370\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.6873 - acc: 0.6074\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5538 - acc: 0.7333\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.6498 - acc: 0.7259\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5961 - acc: 0.7185\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.6103 - acc: 0.7333\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.5760 - acc: 0.6963\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5236 - acc: 0.7185\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5808 - acc: 0.6889\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5784 - acc: 0.8000\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5633 - acc: 0.7259\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5381 - acc: 0.7037\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5854 - acc: 0.7481\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5412 - acc: 0.7852\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.6326 - acc: 0.7037\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.6607 - acc: 0.6889\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5885 - acc: 0.7259\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.5878 - acc: 0.7185\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6211 - acc: 0.6815\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5310 - acc: 0.7778\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.5050 - acc: 0.7407\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5715 - acc: 0.7259\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.5501 - acc: 0.7037\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6198 - acc: 0.7111\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.6000 - acc: 0.7407\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5421 - acc: 0.7630\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5099 - acc: 0.7481\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 0.4763 - acc: 0.7630\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.4306 - acc: 0.8370\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5052 - acc: 0.7704\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5862 - acc: 0.6815\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5194 - acc: 0.7333\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.5027 - acc: 0.7185\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5021 - acc: 0.7481\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 253us/step - loss: 0.5462 - acc: 0.7407\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.4687 - acc: 0.7481\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4680 - acc: 0.7852\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4692 - acc: 0.7481\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5146 - acc: 0.7481\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5431 - acc: 0.7259\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.4607 - acc: 0.8000\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4793 - acc: 0.7407\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.4426 - acc: 0.7778\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4478 - acc: 0.7704\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5204 - acc: 0.7481\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4722 - acc: 0.7926\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5451 - acc: 0.7407\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4467 - acc: 0.7852\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5138 - acc: 0.7556\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.4285 - acc: 0.8074\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5228 - acc: 0.7852\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4956 - acc: 0.8000\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.4125 - acc: 0.8000\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.3878 - acc: 0.8296\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4486 - acc: 0.7926\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5762 - acc: 0.6815\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5054 - acc: 0.7259\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.5631 - acc: 0.7259\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4835 - acc: 0.7481\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5195 - acc: 0.7333\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 176us/step - loss: 0.4491 - acc: 0.8148\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.6049 - acc: 0.7185\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4886 - acc: 0.7852\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 184us/step - loss: 0.5958 - acc: 0.7111\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5181 - acc: 0.7333\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4593 - acc: 0.7259\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4924 - acc: 0.8000\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5113 - acc: 0.7852\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4498 - acc: 0.8000\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4853 - acc: 0.8074\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5409 - acc: 0.7556\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4763 - acc: 0.7407\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5341 - acc: 0.7407\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.3669 - acc: 0.8370\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5251 - acc: 0.7259\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3685 - acc: 0.8815\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5104 - acc: 0.7407\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.4304 - acc: 0.7852\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3078 - acc: 0.8889\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 356us/step - loss: 0.6051 - acc: 0.7333\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 709us/step - loss: 0.4280 - acc: 0.8074\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 335us/step - loss: 0.3698 - acc: 0.8519\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 437us/step - loss: 0.4925 - acc: 0.7630\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 500us/step - loss: 0.4366 - acc: 0.7926\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 411us/step - loss: 0.4423 - acc: 0.8370\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 356us/step - loss: 0.4903 - acc: 0.8000\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 441us/step - loss: 0.6114 - acc: 0.8000\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.4998 - acc: 0.7926\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 452us/step - loss: 0.4596 - acc: 0.8296\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 518us/step - loss: 0.5098 - acc: 0.8000\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 566us/step - loss: 0.4571 - acc: 0.8000\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 467us/step - loss: 0.4633 - acc: 0.7926\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 456us/step - loss: 0.3638 - acc: 0.8667\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 360us/step - loss: 0.4570 - acc: 0.8148\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.5237 - acc: 0.7852\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4427 - acc: 0.8222\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.4276 - acc: 0.8000\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.3819 - acc: 0.8296\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.4096 - acc: 0.8222\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 430us/step - loss: 0.4429 - acc: 0.8074\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4042 - acc: 0.8444\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.3516 - acc: 0.8370\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.4659 - acc: 0.7481\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.3774 - acc: 0.8370\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4012 - acc: 0.8222\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.3881 - acc: 0.8370\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5099 - acc: 0.7630\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3273 - acc: 0.8444\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3060 - acc: 0.8593\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3591 - acc: 0.8222\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3721 - acc: 0.8074\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4155 - acc: 0.8222\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.4002 - acc: 0.8148\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3767 - acc: 0.8593\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3438 - acc: 0.8741\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.3864 - acc: 0.8519\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3368 - acc: 0.8667\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3915 - acc: 0.7926\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4262 - acc: 0.8444\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.4330 - acc: 0.8370\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3335 - acc: 0.8593\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4056 - acc: 0.8074\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4108 - acc: 0.8667\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3400 - acc: 0.8963\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.3445 - acc: 0.8741\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3516 - acc: 0.8889\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3563 - acc: 0.8519\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.3702 - acc: 0.8074\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.3032 - acc: 0.8741\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.3599 - acc: 0.8444\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.3326 - acc: 0.8519\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.3231 - acc: 0.8815\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.2779 - acc: 0.9037\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4322 - acc: 0.8074\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 0.3445 - acc: 0.8889\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3570 - acc: 0.8444\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4426 - acc: 0.8222\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4440 - acc: 0.8074\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.3309 - acc: 0.8815\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.2695 - acc: 0.8815\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.3829 - acc: 0.8222\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.3483 - acc: 0.8667\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4534 - acc: 0.7778\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3225 - acc: 0.8667\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.3650 - acc: 0.8741\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3410 - acc: 0.8741\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3263 - acc: 0.8741\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.2890 - acc: 0.8889\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3742 - acc: 0.8370\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3024 - acc: 0.8963\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.2605 - acc: 0.9037\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3470 - acc: 0.8667\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3474 - acc: 0.8889\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3742 - acc: 0.8667\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.3970 - acc: 0.8593\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.3598 - acc: 0.8296\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.3348 - acc: 0.8889\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3587 - acc: 0.8074\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.2881 - acc: 0.8741\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.4661 - acc: 0.8074\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.3850 - acc: 0.8593\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3518 - acc: 0.8074\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3593 - acc: 0.8667\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3715 - acc: 0.8519\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3763 - acc: 0.8444\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.3520 - acc: 0.8741\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3383 - acc: 0.8593\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.3863 - acc: 0.8148\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.2722 - acc: 0.9037\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.3749 - acc: 0.8444\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 257us/step - loss: 0.3629 - acc: 0.8741\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.5580 - acc: 0.600 - 0s 213us/step - loss: 0.3149 - acc: 0.8889\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.3613 - acc: 0.8296\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.2670 - acc: 0.8815\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3468 - acc: 0.8667\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3881 - acc: 0.8222\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.3766 - acc: 0.8296\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3423 - acc: 0.8444\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.2464 - acc: 0.9185\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.3309 - acc: 0.8519\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 448us/step - loss: 0.4176 - acc: 0.8370\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 356us/step - loss: 0.3483 - acc: 0.8444\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5006 - acc: 0.7926\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.3598 - acc: 0.8593\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3959 - acc: 0.8444\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.3820 - acc: 0.8296\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4476 - acc: 0.8222\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.2400 - acc: 0.9111\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3627 - acc: 0.8593\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1713 - acc: 0.3185\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 1.0843 - acc: 0.3926\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 1.0944 - acc: 0.3926\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 1.0582 - acc: 0.3778\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 345us/step - loss: 1.0054 - acc: 0.5259\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.9406 - acc: 0.5926\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.7648 - acc: 0.7111\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.6278 - acc: 0.7259\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.6368 - acc: 0.6519\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5711 - acc: 0.7630\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.6394 - acc: 0.6889\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.6410 - acc: 0.6741\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.6092 - acc: 0.6667\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5836 - acc: 0.6889\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.6094 - acc: 0.7111\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5611 - acc: 0.7259\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5638 - acc: 0.7333\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5651 - acc: 0.7333\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5624 - acc: 0.7185\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5410 - acc: 0.6963\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.5126 - acc: 0.7111\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5209 - acc: 0.7407\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4846 - acc: 0.7037\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5986 - acc: 0.7037\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4568 - acc: 0.8593\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4967 - acc: 0.7778\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4666 - acc: 0.8074\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4336 - acc: 0.8074\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5302 - acc: 0.7111\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.4248 - acc: 0.8000\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5232 - acc: 0.7630\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5470 - acc: 0.8222\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4664 - acc: 0.7852\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4553 - acc: 0.8148\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 492us/step - loss: 0.4963 - acc: 0.7704\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5303 - acc: 0.7778\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 507us/step - loss: 0.4638 - acc: 0.8444\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.4591 - acc: 0.7556\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5091 - acc: 0.8148\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4481 - acc: 0.8222\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.4964 - acc: 0.7778\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5201 - acc: 0.8074\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4233 - acc: 0.8222\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4832 - acc: 0.7778\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4675 - acc: 0.7704\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.4047 - acc: 0.7926\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.4997 - acc: 0.7852\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4359 - acc: 0.8000\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4598 - acc: 0.7926\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.4591 - acc: 0.7778\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4250 - acc: 0.8222\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5279 - acc: 0.7037\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5101 - acc: 0.7852\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.4112 - acc: 0.8370\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.3719 - acc: 0.8519\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.4285 - acc: 0.8222\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.4957 - acc: 0.8148\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.3803 - acc: 0.8000\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4490 - acc: 0.7926\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4733 - acc: 0.7852\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.4487 - acc: 0.8074\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.4098 - acc: 0.7852\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3912 - acc: 0.7852\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5337 - acc: 0.7259\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5031 - acc: 0.8074\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3851 - acc: 0.8667\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4878 - acc: 0.7778\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4617 - acc: 0.8148\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4527 - acc: 0.8148\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.4105 - acc: 0.8444\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 0.4048 - acc: 0.8519\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 202us/step - loss: 0.4045 - acc: 0.8519\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.4078 - acc: 0.8296\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.4065 - acc: 0.8296\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.4285 - acc: 0.7852\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.4004 - acc: 0.8000\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 364us/step - loss: 0.5332 - acc: 0.7630\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 367us/step - loss: 0.4674 - acc: 0.7852\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 349us/step - loss: 0.3780 - acc: 0.8519\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.3857 - acc: 0.8148\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 353us/step - loss: 0.4100 - acc: 0.8074\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.4610 - acc: 0.8148\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4472 - acc: 0.8148\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4906 - acc: 0.8000\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.3485 - acc: 0.8741\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4160 - acc: 0.8963\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.4100 - acc: 0.8444\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4308 - acc: 0.8741\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 338us/step - loss: 0.3637 - acc: 0.8815\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 360us/step - loss: 0.2925 - acc: 0.9259\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 371us/step - loss: 0.3412 - acc: 0.8370\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5261 - acc: 0.8593\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.3331 - acc: 0.8889\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.3599 - acc: 0.9259\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3580 - acc: 0.8963\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.2768 - acc: 0.8815\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 353us/step - loss: 0.2776 - acc: 0.8815\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.2997 - acc: 0.8741\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.3299 - acc: 0.8519\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.4339 - acc: 0.8667\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3872 - acc: 0.8667\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.2744 - acc: 0.8889\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4463 - acc: 0.8444\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.4530 - acc: 0.8370\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3157 - acc: 0.8815\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.2859 - acc: 0.8815\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4123 - acc: 0.8519\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3578 - acc: 0.8667\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3025 - acc: 0.9111\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4008 - acc: 0.8519\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3275 - acc: 0.8741\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.3251 - acc: 0.8963\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.3581 - acc: 0.8889\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3840 - acc: 0.8889\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.3095 - acc: 0.9185\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.3358 - acc: 0.8889\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.4088 - acc: 0.8444\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.2734 - acc: 0.9185\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.2988 - acc: 0.8889\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.2749 - acc: 0.9111\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.2557 - acc: 0.9407\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3547 - acc: 0.8667\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.3019 - acc: 0.8963\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4583 - acc: 0.8148\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.2930 - acc: 0.8963\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3275 - acc: 0.8815\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.2750 - acc: 0.8963\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3009 - acc: 0.8815\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 198us/step - loss: 0.2881 - acc: 0.8963\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3701 - acc: 0.8741\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.2811 - acc: 0.9259\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3032 - acc: 0.8963\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.2992 - acc: 0.9111\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.3358 - acc: 0.8889\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.4429 - acc: 0.8000\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3317 - acc: 0.8667\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3148 - acc: 0.8889\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.3439 - acc: 0.8889\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.3141 - acc: 0.9111\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.3615 - acc: 0.8667\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3136 - acc: 0.8741\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3375 - acc: 0.8815\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3754 - acc: 0.8444\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.3191 - acc: 0.8593\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 276us/step - loss: 0.3753 - acc: 0.8741\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3969 - acc: 0.8444\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.2845 - acc: 0.8963\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.3887 - acc: 0.8593\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.2546 - acc: 0.9111\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.2451 - acc: 0.9111\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.3259 - acc: 0.8815\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.3399 - acc: 0.8519\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.3294 - acc: 0.8519\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.2758 - acc: 0.8963\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.2291 - acc: 0.8667\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.3171 - acc: 0.9037\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.3370 - acc: 0.8889\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.2378 - acc: 0.9111\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.4521 - acc: 0.8148\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4149 - acc: 0.8444\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.3646 - acc: 0.8741\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.3800 - acc: 0.8519\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3530 - acc: 0.8667\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3209 - acc: 0.8815\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.2912 - acc: 0.8815\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.2500 - acc: 0.9037\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.2769 - acc: 0.9037\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.2356 - acc: 0.8963\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 195us/step - loss: 0.3406 - acc: 0.8815\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.3483 - acc: 0.8444\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.3233 - acc: 0.9111\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.3168 - acc: 0.8444\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.3252 - acc: 0.8741\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.3213 - acc: 0.8519\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.2875 - acc: 0.8815\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.3756 - acc: 0.8593\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.2536 - acc: 0.8889\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.2179 - acc: 0.9333\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.3509 - acc: 0.8519\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1898 - acc: 1.000 - 0s 243us/step - loss: 0.2675 - acc: 0.9111\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4203 - acc: 0.8148\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.2857 - acc: 0.8741\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.2791 - acc: 0.9037\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.4232 - acc: 0.8222\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.2506 - acc: 0.9259\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.3006 - acc: 0.8667\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 353us/step - loss: 0.3378 - acc: 0.8519\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.2000 - acc: 0.9259\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.2960 - acc: 0.8815\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.2405 - acc: 0.8815\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.3552 - acc: 0.8741\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.2989 - acc: 0.9037\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3662 - acc: 0.8741\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.3665 - acc: 0.8889\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4113 - acc: 0.8296\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.3003 - acc: 0.8741\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 217us/step - loss: 0.3349 - acc: 0.8741\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.2446 - acc: 0.9481\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3032 - acc: 0.8963\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.2624 - acc: 0.9185\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1472 - acc: 0.4370\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.9156 - acc: 0.5407\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.8465 - acc: 0.5852\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.7829 - acc: 0.6296\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.8424 - acc: 0.5852\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.7807 - acc: 0.5926\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.8040 - acc: 0.6370\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.7401 - acc: 0.6444\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.7375 - acc: 0.6444\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.7153 - acc: 0.7037\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.7788 - acc: 0.6370\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.7723 - acc: 0.7185\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.7319 - acc: 0.6741\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.6573 - acc: 0.6963\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.6832 - acc: 0.6815\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.7205 - acc: 0.7259\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.6544 - acc: 0.7556\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.7869 - acc: 0.6296\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.6992 - acc: 0.7037\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.6503 - acc: 0.7481\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.6286 - acc: 0.7259\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.7073 - acc: 0.7037\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.6655 - acc: 0.7037\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6145 - acc: 0.8148\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5862 - acc: 0.7926\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.6376 - acc: 0.7926\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6802 - acc: 0.7111\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.6369 - acc: 0.7259\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5493 - acc: 0.8074\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.6443 - acc: 0.7185\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.6141 - acc: 0.7556\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.6919 - acc: 0.6963\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.6348 - acc: 0.7407\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.7145 - acc: 0.7037\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.6833 - acc: 0.7407\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 342us/step - loss: 0.6678 - acc: 0.7481\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6919 - acc: 0.7111\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.7192 - acc: 0.6963\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5838 - acc: 0.7778\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.6863 - acc: 0.7259\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.6528 - acc: 0.7111\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5965 - acc: 0.7259\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.6094 - acc: 0.7556\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.6568 - acc: 0.7704\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.6200 - acc: 0.7630\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5448 - acc: 0.8296\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.5611 - acc: 0.7926\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.6938 - acc: 0.6889\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5484 - acc: 0.8074\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.5983 - acc: 0.7481\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5381 - acc: 0.8000\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.5109 - acc: 0.8148\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5475 - acc: 0.7704\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5813 - acc: 0.7852\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.5749 - acc: 0.7556\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5108 - acc: 0.8148\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.6802 - acc: 0.7259\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5094 - acc: 0.8074\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.5150 - acc: 0.8148\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5613 - acc: 0.7778\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.5113 - acc: 0.8074\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5731 - acc: 0.7926\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.6052 - acc: 0.7556\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.6058 - acc: 0.7630\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5605 - acc: 0.7481\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5887 - acc: 0.7407\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 342us/step - loss: 0.6609 - acc: 0.7037\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4877 - acc: 0.8222\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.5564 - acc: 0.7704\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 253us/step - loss: 0.6210 - acc: 0.7630\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.5239 - acc: 0.8296\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.6572 - acc: 0.7185\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5247 - acc: 0.7852\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 253us/step - loss: 0.5388 - acc: 0.7852\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5877 - acc: 0.7926\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.6532 - acc: 0.7333\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5465 - acc: 0.7778\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 243us/step - loss: 0.5882 - acc: 0.7481\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4844 - acc: 0.8296\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5114 - acc: 0.7852\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.6038 - acc: 0.7556\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.5443 - acc: 0.8000\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5536 - acc: 0.8148\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 191us/step - loss: 0.5192 - acc: 0.8074\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 169us/step - loss: 0.6508 - acc: 0.7407\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5434 - acc: 0.8074\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5743 - acc: 0.7852\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.6699 - acc: 0.7037\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.4043 - acc: 0.8667\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5301 - acc: 0.8222\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.6179 - acc: 0.7704\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.6303 - acc: 0.7481\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5418 - acc: 0.7704\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5391 - acc: 0.7852\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4978 - acc: 0.8148\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5657 - acc: 0.7926\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.6729 - acc: 0.7037\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5987 - acc: 0.7185\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.6351 - acc: 0.7185\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5354 - acc: 0.8074\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4748 - acc: 0.8000\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5707 - acc: 0.7852\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.6147 - acc: 0.7630\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5613 - acc: 0.7630\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.5047 - acc: 0.8222\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 209us/step - loss: 0.6259 - acc: 0.7630\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4744 - acc: 0.8222\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 235us/step - loss: 0.5187 - acc: 0.8148\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5314 - acc: 0.7926\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5860 - acc: 0.7481\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5029 - acc: 0.8000\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.4297 - acc: 0.8519\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.6267 - acc: 0.7333\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5334 - acc: 0.7704\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5512 - acc: 0.7630\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4476 - acc: 0.8222\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.6653 - acc: 0.7037\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5452 - acc: 0.7778\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5235 - acc: 0.8222\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4062 - acc: 0.8667\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5416 - acc: 0.7852\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.4626 - acc: 0.8296\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4717 - acc: 0.8296\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.5708 - acc: 0.7704\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.6153 - acc: 0.7852\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.4583 - acc: 0.8519\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.6275 - acc: 0.7630\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.6414 - acc: 0.7333\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.6143 - acc: 0.7407\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.5087 - acc: 0.8000\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.4658 - acc: 0.8296\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.6411 - acc: 0.6963\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4980 - acc: 0.8444\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5018 - acc: 0.8148\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4886 - acc: 0.8370\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.4867 - acc: 0.8148\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5480 - acc: 0.7852\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5172 - acc: 0.8148\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5808 - acc: 0.7556\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5710 - acc: 0.7704\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.5962 - acc: 0.7704\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5138 - acc: 0.8000\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5109 - acc: 0.8000\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5401 - acc: 0.7778\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5521 - acc: 0.7778\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.7519 - acc: 0.7259\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5764 - acc: 0.7852\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4554 - acc: 0.8444\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5117 - acc: 0.8148\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5867 - acc: 0.7704\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5273 - acc: 0.8000\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4729 - acc: 0.8370\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4447 - acc: 0.8222\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5687 - acc: 0.7704\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4830 - acc: 0.8222\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4798 - acc: 0.8370\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.4278 - acc: 0.8963\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5261 - acc: 0.7704\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5874 - acc: 0.7481\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5184 - acc: 0.7778\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5855 - acc: 0.7704\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.6515 - acc: 0.7259\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5202 - acc: 0.8148\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5443 - acc: 0.7704\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.4652 - acc: 0.8519\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.4618 - acc: 0.8148\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5305 - acc: 0.8000\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5107 - acc: 0.8074\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4764 - acc: 0.8222\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5393 - acc: 0.7778\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5323 - acc: 0.7704\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5033 - acc: 0.8000\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.5426 - acc: 0.8074\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.4386 - acc: 0.8519\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5133 - acc: 0.8074\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5415 - acc: 0.7926\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.3982 - acc: 0.8519\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5228 - acc: 0.8148\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4908 - acc: 0.8148\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 353us/step - loss: 0.4890 - acc: 0.7778\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4990 - acc: 0.8148\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3636 - acc: 0.8519\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.4757 - acc: 0.8222\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.6071 - acc: 0.7704\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5335 - acc: 0.7926\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5804 - acc: 0.7556\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5316 - acc: 0.7852\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.4652 - acc: 0.8370\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4819 - acc: 0.8000\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 276us/step - loss: 0.4782 - acc: 0.8519\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4042 - acc: 0.8370\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.4705 - acc: 0.8148\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.6009 - acc: 0.7630\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5295 - acc: 0.8000\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4269 - acc: 0.8370\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5239 - acc: 0.7778\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.4883 - acc: 0.7852\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5819 - acc: 0.7778\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5639 - acc: 0.7926\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.5113 - acc: 0.7926\n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.2487 - acc: 0.3481\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 1.1258 - acc: 0.2889\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 1.1181 - acc: 0.3333\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 1.1063 - acc: 0.3481\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 1.0971 - acc: 0.2889\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 1.1173 - acc: 0.3185\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 1.0957 - acc: 0.3407\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 1.1077 - acc: 0.3259\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 1.0932 - acc: 0.4000\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 1.1037 - acc: 0.3630\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 1.0701 - acc: 0.4000\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 1.1115 - acc: 0.3407\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 1.0730 - acc: 0.4296\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 1.0629 - acc: 0.4148\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 1.1182 - acc: 0.3185\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 1.0833 - acc: 0.3926\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 1.0699 - acc: 0.4519\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 1.1027 - acc: 0.3111\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 1.0771 - acc: 0.3926\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 1.0590 - acc: 0.4148\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 1.0430 - acc: 0.4222\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 1.0679 - acc: 0.4148\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 1.0635 - acc: 0.4000\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 353us/step - loss: 1.0450 - acc: 0.4296\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 1.0419 - acc: 0.4222\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 1.0444 - acc: 0.4074\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 1.0110 - acc: 0.4667\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 1.0461 - acc: 0.4074\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 1.0098 - acc: 0.4667\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 1.0180 - acc: 0.4593\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 1.0274 - acc: 0.4370\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 1.0266 - acc: 0.4222\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 1.0413 - acc: 0.4222\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 1.0237 - acc: 0.4444\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 338us/step - loss: 1.0218 - acc: 0.4667\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 1.0099 - acc: 0.4296\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.9942 - acc: 0.4593\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.9851 - acc: 0.4889\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 1.0060 - acc: 0.4741\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.9963 - acc: 0.4889\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 1.0030 - acc: 0.4444\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 1.0213 - acc: 0.4222\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 1.0181 - acc: 0.4370\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 1.0071 - acc: 0.4370\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 1.0230 - acc: 0.4222\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.9894 - acc: 0.4519\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.9964 - acc: 0.4370\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 1.0117 - acc: 0.4593\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.9986 - acc: 0.4593\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 1.0007 - acc: 0.4519\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.9774 - acc: 0.4741\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 1.0029 - acc: 0.4444\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.8675 - acc: 0.5630\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.7816 - acc: 0.6519\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.7005 - acc: 0.7185\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.6724 - acc: 0.7185\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.7353 - acc: 0.6667\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.6392 - acc: 0.6667\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 364us/step - loss: 0.6419 - acc: 0.6667\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 522us/step - loss: 0.6044 - acc: 0.6667 0s - loss: 0.6059 - acc: 0.672\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.6203 - acc: 0.6667\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.6817 - acc: 0.6815\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.7233 - acc: 0.6519\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.7079 - acc: 0.6593\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5699 - acc: 0.7259\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5743 - acc: 0.7185\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5200 - acc: 0.7556\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5777 - acc: 0.6889\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5900 - acc: 0.7407\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5717 - acc: 0.6741\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5393 - acc: 0.7185\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 250us/step - loss: 0.6022 - acc: 0.6815\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6342 - acc: 0.6444\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5551 - acc: 0.7037\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.6860 - acc: 0.7111\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5143 - acc: 0.7556\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5647 - acc: 0.7407\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5439 - acc: 0.6815\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5865 - acc: 0.6519\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5815 - acc: 0.7704\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5224 - acc: 0.7333\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5752 - acc: 0.7185\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.6113 - acc: 0.6889\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6453 - acc: 0.6889\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5643 - acc: 0.6889\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.6333 - acc: 0.7111\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.6417 - acc: 0.7185\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5856 - acc: 0.6963\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5593 - acc: 0.7481\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5528 - acc: 0.7333\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.5747 - acc: 0.7704\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5628 - acc: 0.7259\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5867 - acc: 0.7037\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.5514 - acc: 0.7037\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4883 - acc: 0.7407\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.7365 - acc: 0.6296\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.6064 - acc: 0.7111\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.5449 - acc: 0.7556\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5772 - acc: 0.7556\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5748 - acc: 0.7037\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5592 - acc: 0.7333\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.7826 - acc: 0.6222\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5699 - acc: 0.7185\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5060 - acc: 0.7259\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5456 - acc: 0.7111\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5253 - acc: 0.7259\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.5775 - acc: 0.7556\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5925 - acc: 0.7333\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.6498 - acc: 0.6741\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5086 - acc: 0.7185\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4973 - acc: 0.7852\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6668 - acc: 0.6519\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6046 - acc: 0.6889\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6075 - acc: 0.6963\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.5800 - acc: 0.7407\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.6080 - acc: 0.7259\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5922 - acc: 0.6593\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.6585 - acc: 0.6370\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.6360 - acc: 0.7185\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5615 - acc: 0.7481\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5516 - acc: 0.7407\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5659 - acc: 0.6667\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5771 - acc: 0.7185\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5083 - acc: 0.7111\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.5458 - acc: 0.7333\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4858 - acc: 0.7778\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 367us/step - loss: 0.6136 - acc: 0.6889\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5845 - acc: 0.7407\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4463 - acc: 0.7630\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.4851 - acc: 0.7704\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.6257 - acc: 0.6741\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5695 - acc: 0.7704\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5663 - acc: 0.6741\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5262 - acc: 0.7111\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4723 - acc: 0.7481\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.6175 - acc: 0.7481\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5220 - acc: 0.7259\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5877 - acc: 0.6815\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4543 - acc: 0.7630\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5710 - acc: 0.7481\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.4649 - acc: 0.7481\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5727 - acc: 0.7481\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5682 - acc: 0.6815\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.5160 - acc: 0.7259\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5928 - acc: 0.7407\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.5708 - acc: 0.7111\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5992 - acc: 0.6593\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5022 - acc: 0.7852\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5248 - acc: 0.7333\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5433 - acc: 0.7333\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5590 - acc: 0.7630\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5244 - acc: 0.7259\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4993 - acc: 0.7333\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.4759 - acc: 0.7630\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 386us/step - loss: 0.5728 - acc: 0.6815\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.4697 - acc: 0.7556\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4936 - acc: 0.6889\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5798 - acc: 0.6593\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5047 - acc: 0.7481\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4942 - acc: 0.7556\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.4699 - acc: 0.7407\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5463 - acc: 0.7259\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5258 - acc: 0.7259\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.4921 - acc: 0.7556\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.6054 - acc: 0.7259\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.6297 - acc: 0.7111\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5949 - acc: 0.7333\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5650 - acc: 0.7037\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5714 - acc: 0.7481\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5557 - acc: 0.7259\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5839 - acc: 0.7185\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.4713 - acc: 0.7407\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5513 - acc: 0.7259\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.5418 - acc: 0.7111\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.6018 - acc: 0.7111\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5738 - acc: 0.7407\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5655 - acc: 0.7630\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.5865 - acc: 0.7259\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.6284 - acc: 0.7111\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.6067 - acc: 0.7037\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5051 - acc: 0.7704\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6103 - acc: 0.7704\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5564 - acc: 0.7333\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4751 - acc: 0.7333\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.5889 - acc: 0.7185\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4499 - acc: 0.7926\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.5434 - acc: 0.7556\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.6880 - acc: 0.6815\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 371us/step - loss: 0.5011 - acc: 0.7333\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.6199 - acc: 0.7111\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4464 - acc: 0.7926\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5205 - acc: 0.7037\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5218 - acc: 0.7852\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.5836 - acc: 0.7333\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4860 - acc: 0.7556\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.6135 - acc: 0.7481\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5680 - acc: 0.7185\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5006 - acc: 0.7556\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5428 - acc: 0.7556\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5963 - acc: 0.7407\n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.0819 - acc: 0.2963\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 221us/step - loss: 0.9929 - acc: 0.5630\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.9265 - acc: 0.5481\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.8545 - acc: 0.6000\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.8524 - acc: 0.5704\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.8136 - acc: 0.6074\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.7490 - acc: 0.6519\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.7148 - acc: 0.6370\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.6586 - acc: 0.6444\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.6992 - acc: 0.6000\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.7011 - acc: 0.6593\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.6103 - acc: 0.7037\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.6557 - acc: 0.7259\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5732 - acc: 0.7407\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 342us/step - loss: 0.6264 - acc: 0.6815\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 367us/step - loss: 0.5473 - acc: 0.7481\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.6867 - acc: 0.6963\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.6075 - acc: 0.6741\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5993 - acc: 0.7407\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 220us/step - loss: 0.6438 - acc: 0.7852\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 275us/step - loss: 0.5573 - acc: 0.7333\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6431 - acc: 0.6815\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5821 - acc: 0.7333\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5798 - acc: 0.7481\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5189 - acc: 0.7185\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5156 - acc: 0.7556\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5987 - acc: 0.7185\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6222 - acc: 0.7111\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5699 - acc: 0.7481\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5653 - acc: 0.7704\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5251 - acc: 0.7704\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5496 - acc: 0.7704\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5742 - acc: 0.7259\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4831 - acc: 0.7852\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5275 - acc: 0.7704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.6358 - acc: 0.7481\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5592 - acc: 0.7407\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4527 - acc: 0.8222\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.4734 - acc: 0.7704\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5820 - acc: 0.7481\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.6733 - acc: 0.6963\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 338us/step - loss: 0.4388 - acc: 0.8370\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 345us/step - loss: 0.4306 - acc: 0.8519\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6341 - acc: 0.7185\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5349 - acc: 0.7556\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.6154 - acc: 0.7407\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.4870 - acc: 0.7926\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5371 - acc: 0.7778\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.4956 - acc: 0.7926\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4556 - acc: 0.8074\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.4563 - acc: 0.7704\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3989 - acc: 0.8074\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.5454 - acc: 0.7333\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5326 - acc: 0.7556\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.6414 - acc: 0.6296\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.6381 - acc: 0.6667\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.4654 - acc: 0.7630\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4529 - acc: 0.7926\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.4783 - acc: 0.7778\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4761 - acc: 0.8000\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 342us/step - loss: 0.5555 - acc: 0.7333\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4574 - acc: 0.7481\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.5514 - acc: 0.7185\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4614 - acc: 0.7704\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.4525 - acc: 0.7704\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5089 - acc: 0.7926\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5230 - acc: 0.8074\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 338us/step - loss: 0.4856 - acc: 0.7926\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 353us/step - loss: 0.5915 - acc: 0.7333\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 349us/step - loss: 0.5371 - acc: 0.7407\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5813 - acc: 0.7185\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.7745 - acc: 0.6444\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5178 - acc: 0.7259\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.5753 - acc: 0.7481\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4740 - acc: 0.7778\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.4241 - acc: 0.8000\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5142 - acc: 0.7481\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.4565 - acc: 0.7778\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.4856 - acc: 0.7852\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.4526 - acc: 0.7926\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.4914 - acc: 0.7926\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4262 - acc: 0.7630\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.5859 - acc: 0.6963\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.4188 - acc: 0.8444\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.4825 - acc: 0.7926\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5750 - acc: 0.7333\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 243us/step - loss: 0.5151 - acc: 0.7407\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.4296 - acc: 0.8074\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4134 - acc: 0.8000\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4180 - acc: 0.7556\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5591 - acc: 0.7407\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5114 - acc: 0.7704\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.3937 - acc: 0.8444\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.4926 - acc: 0.7778\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.6545 - acc: 0.6148\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.6858 - acc: 0.6370\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3724 - acc: 0.8296\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.5201 - acc: 0.7778\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4741 - acc: 0.8000\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.3701 - acc: 0.8519\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4821 - acc: 0.7556\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.3917 - acc: 0.8148\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4259 - acc: 0.8074\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.4560 - acc: 0.7630\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5481 - acc: 0.7556\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.4233 - acc: 0.7778\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.4612 - acc: 0.7778\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5633 - acc: 0.7852\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.4906 - acc: 0.8000\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.4903 - acc: 0.8000\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 243us/step - loss: 0.4264 - acc: 0.8074\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4622 - acc: 0.8074\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.6200 - acc: 0.6815\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.4764 - acc: 0.7556\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5402 - acc: 0.6963\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4736 - acc: 0.7481\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5831 - acc: 0.7407\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5242 - acc: 0.7630\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 239us/step - loss: 0.4816 - acc: 0.8296\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4057 - acc: 0.8296\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.5161 - acc: 0.7630\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4370 - acc: 0.8074\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.4510 - acc: 0.7704\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5090 - acc: 0.8074\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5292 - acc: 0.7556\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.4862 - acc: 0.7852\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 386us/step - loss: 0.6593 - acc: 0.6444\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 382us/step - loss: 0.6186 - acc: 0.6222\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.5814 - acc: 0.7111\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5071 - acc: 0.7481\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 338us/step - loss: 0.3834 - acc: 0.8222\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.7351 - acc: 0.6593\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.4701 - acc: 0.7704\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5063 - acc: 0.7926\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.4672 - acc: 0.8222\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.4861 - acc: 0.7926\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4382 - acc: 0.7852\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.4150 - acc: 0.8000\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.6338 - acc: 0.6593\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.4117 - acc: 0.7926\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.4714 - acc: 0.7704\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.4343 - acc: 0.8000\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4437 - acc: 0.7852\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.3983 - acc: 0.8296\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4139 - acc: 0.8296\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 338us/step - loss: 0.4276 - acc: 0.8148\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4916 - acc: 0.7556\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 342us/step - loss: 0.4517 - acc: 0.7556\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.4534 - acc: 0.7852\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 364us/step - loss: 0.4462 - acc: 0.7630\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.4541 - acc: 0.7852\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5437 - acc: 0.7259\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.4395 - acc: 0.7778\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.4995 - acc: 0.7630\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3785 - acc: 0.8444\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 0.4943 - acc: 0.7333\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4806 - acc: 0.8000\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.3804 - acc: 0.8074\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4699 - acc: 0.7556\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3196 - acc: 0.8593\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.3442 - acc: 0.8370\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.4035 - acc: 0.8074\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.4363 - acc: 0.8000\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 378us/step - loss: 0.4040 - acc: 0.8222\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 371us/step - loss: 0.4012 - acc: 0.8148\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.3737 - acc: 0.8074\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4951 - acc: 0.7630\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.4822 - acc: 0.7481\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 275us/step - loss: 0.4257 - acc: 0.7778\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.3822 - acc: 0.8000\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.4133 - acc: 0.8148\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.3458 - acc: 0.8519\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.3785 - acc: 0.8148\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.3925 - acc: 0.8148\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 228us/step - loss: 0.4443 - acc: 0.8222\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.3753 - acc: 0.8815\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.3434 - acc: 0.8370\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.3188 - acc: 0.8667\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.4118 - acc: 0.8074\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3773 - acc: 0.8222\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.4044 - acc: 0.7778\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.3400 - acc: 0.8593\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.4261 - acc: 0.8148\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.3893 - acc: 0.8222\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.3341 - acc: 0.8444\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4444 - acc: 0.7704\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.3952 - acc: 0.8296\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5211 - acc: 0.7481\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.4337 - acc: 0.7926\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.4404 - acc: 0.7926\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.3685 - acc: 0.8296\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.3384 - acc: 0.8296\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5112 - acc: 0.7630\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3338 - acc: 0.8519\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3644 - acc: 0.8519\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.4121 - acc: 0.7852\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.3576 - acc: 0.8370\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.3849 - acc: 0.8370\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.3207 - acc: 0.8667\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 261us/step - loss: 0.3976 - acc: 0.8222\n",
      "15/15 [==============================] - 0s 9ms/step\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.3225 - acc: 0.4148\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 1.0866 - acc: 0.3852\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 1.0779 - acc: 0.4000\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 1.0592 - acc: 0.5407\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 1.0122 - acc: 0.5704\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.9680 - acc: 0.5407\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.8808 - acc: 0.5259\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.8401 - acc: 0.5926\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.7165 - acc: 0.6741\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.6947 - acc: 0.6444\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.7213 - acc: 0.6963\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.7100 - acc: 0.6074\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5930 - acc: 0.6444\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.7218 - acc: 0.6296\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5785 - acc: 0.6815\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.6978 - acc: 0.5704\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 327us/step - loss: 0.6180 - acc: 0.6593\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.7260 - acc: 0.6370\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.6159 - acc: 0.6000\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.5907 - acc: 0.6444\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.6404 - acc: 0.6444\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.6388 - acc: 0.6519\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5898 - acc: 0.6000\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 286us/step - loss: 0.5699 - acc: 0.7407\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 231us/step - loss: 0.5890 - acc: 0.7185\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6165 - acc: 0.6741\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.6067 - acc: 0.6815\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.6390 - acc: 0.6815\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.6026 - acc: 0.6815\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.6350 - acc: 0.6222\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.6160 - acc: 0.6444\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5663 - acc: 0.6519\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.6791 - acc: 0.6370\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.6339 - acc: 0.7481\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5892 - acc: 0.7037\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5572 - acc: 0.8000\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.6298 - acc: 0.7185\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5670 - acc: 0.7926\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5341 - acc: 0.7259\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5896 - acc: 0.7407\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 342us/step - loss: 0.5921 - acc: 0.7037\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 275us/step - loss: 0.6848 - acc: 0.7111\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5748 - acc: 0.7926\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 297us/step - loss: 0.5285 - acc: 0.7704\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.6569 - acc: 0.7630\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5767 - acc: 0.7333\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.4898 - acc: 0.8000\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5389 - acc: 0.7704\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 367us/step - loss: 0.5109 - acc: 0.8074\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5951 - acc: 0.7778\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5043 - acc: 0.7556\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.6292 - acc: 0.6741\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5204 - acc: 0.7852\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 345us/step - loss: 0.7372 - acc: 0.6741\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 463us/step - loss: 0.5506 - acc: 0.7556\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5369 - acc: 0.7481\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.5053 - acc: 0.7852\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5571 - acc: 0.7704\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5928 - acc: 0.7852\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.6707 - acc: 0.7481\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.8226 - acc: 0.6741\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 467us/step - loss: 0.5978 - acc: 0.7852\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 992us/step - loss: 0.6099 - acc: 0.7481\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 481us/step - loss: 0.5604 - acc: 0.7556\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 206us/step - loss: 0.6743 - acc: 0.8074\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6060 - acc: 0.7259\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5661 - acc: 0.7481\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.4894 - acc: 0.8000\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5259 - acc: 0.8148\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.6600 - acc: 0.7926\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5485 - acc: 0.8000\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4859 - acc: 0.7704\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.6042 - acc: 0.7556\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.4550 - acc: 0.8296\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.6523 - acc: 0.7333\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.7241 - acc: 0.7111\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5541 - acc: 0.7852\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.7263 - acc: 0.6222\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.6490 - acc: 0.7037\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5013 - acc: 0.7704\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5844 - acc: 0.6444\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 603us/step - loss: 0.5146 - acc: 0.7407\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.4842 - acc: 0.755 - 0s 643us/step - loss: 0.5370 - acc: 0.7407\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 772us/step - loss: 0.5750 - acc: 0.6963\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.5227 - acc: 0.6815\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.5184 - acc: 0.6963\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5451 - acc: 0.6963\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.6327 - acc: 0.6593\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.5873 - acc: 0.6963\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 485us/step - loss: 0.4575 - acc: 0.7333\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6123 - acc: 0.7185\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 599us/step - loss: 0.5210 - acc: 0.6889\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5305 - acc: 0.6889\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5600 - acc: 0.7481\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5970 - acc: 0.6519\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.6361 - acc: 0.6519\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.6108 - acc: 0.6296\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.6522 - acc: 0.6296\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 503us/step - loss: 0.5723 - acc: 0.6815\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.6368 - acc: 0.6296\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5553 - acc: 0.6889\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.5506 - acc: 0.6593\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5696 - acc: 0.6889\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5447 - acc: 0.7407\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5898 - acc: 0.6741\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5224 - acc: 0.7259\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5567 - acc: 0.6963\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5379 - acc: 0.7037\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 242us/step - loss: 0.5543 - acc: 0.6593\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 283us/step - loss: 0.5778 - acc: 0.6963\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.5580 - acc: 0.6000\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5259 - acc: 0.6963\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.5733 - acc: 0.7407\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5478 - acc: 0.6963\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5067 - acc: 0.6889\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5645 - acc: 0.6889\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5202 - acc: 0.6815\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 246us/step - loss: 0.5523 - acc: 0.6815\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 265us/step - loss: 0.6188 - acc: 0.6000\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.6000 - acc: 0.6148\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.6914 - acc: 0.6741\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.4704 - acc: 0.6815\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.5598 - acc: 0.6296\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5498 - acc: 0.6815\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.5653 - acc: 0.6963\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.6887 - acc: 0.6296\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5816 - acc: 0.6444\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 338us/step - loss: 0.5024 - acc: 0.7037\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.4735 - acc: 0.7630\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4585 - acc: 0.7037\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.5155 - acc: 0.7556\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.5579 - acc: 0.6370\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5377 - acc: 0.7333\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 378us/step - loss: 0.5819 - acc: 0.6889\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.6621 - acc: 0.7037\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.4890 - acc: 0.7333\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5708 - acc: 0.6667\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.5372 - acc: 0.6815\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5765 - acc: 0.6370\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.6337 - acc: 0.6741\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5530 - acc: 0.6741\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.4980 - acc: 0.6815\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5751 - acc: 0.6815\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.6153 - acc: 0.7630\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.4807 - acc: 0.7185\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.5327 - acc: 0.7111\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.6351 - acc: 0.6889\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5416 - acc: 0.6889\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6600 - acc: 0.6519\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5373 - acc: 0.6963\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 268us/step - loss: 0.5801 - acc: 0.6963\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.6211 - acc: 0.7259\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.4977 - acc: 0.7407\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.5879 - acc: 0.6889\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 309us/step - loss: 0.5357 - acc: 0.6741\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5022 - acc: 0.7111\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5025 - acc: 0.7111\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.4847 - acc: 0.7259\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.5951 - acc: 0.6370\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.5926 - acc: 0.6963\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.5945 - acc: 0.7556\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5227 - acc: 0.7259\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 257us/step - loss: 0.4899 - acc: 0.7333\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 264us/step - loss: 0.4709 - acc: 0.7481\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.6333 - acc: 0.7111\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.6543 - acc: 0.7111\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.5743 - acc: 0.7259\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.5657 - acc: 0.6889\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 320us/step - loss: 0.6446 - acc: 0.6519\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 279us/step - loss: 0.5474 - acc: 0.7259\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 276us/step - loss: 0.4539 - acc: 0.7926\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5288 - acc: 0.7630\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 254us/step - loss: 0.6454 - acc: 0.6370\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 338us/step - loss: 0.5278 - acc: 0.7111\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 213us/step - loss: 0.5358 - acc: 0.7556\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4927 - acc: 0.7704\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.4550 - acc: 0.7333\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5155 - acc: 0.7333\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.4266 - acc: 0.7926\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 261us/step - loss: 0.4619 - acc: 0.8222\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.5010 - acc: 0.7481\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 272us/step - loss: 0.5458 - acc: 0.7704\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.4631 - acc: 0.7852\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.5557 - acc: 0.8370\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.4970 - acc: 0.7407\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5062 - acc: 0.7852\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.5161 - acc: 0.7704\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.5313 - acc: 0.7778\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.6551 - acc: 0.7037\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 250us/step - loss: 0.4913 - acc: 0.7852\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 287us/step - loss: 0.4734 - acc: 0.8000\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.5201 - acc: 0.7704\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.4488 - acc: 0.8222\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.4610 - acc: 0.8000\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4328 - acc: 0.8148\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.4087 - acc: 0.8519\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.5261 - acc: 0.7778\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 224us/step - loss: 0.5046 - acc: 0.7778\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.5189 - acc: 0.7259\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 345us/step - loss: 0.4178 - acc: 0.8222\n",
      "15/15 [==============================] - 0s 9ms/step\n",
      "Accuracy: 86.00% (0.11)\n"
     ]
    }
   ],
   "source": [
    "# Keras——Dropout\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 导入数据\n",
    "dataset = datasets.load_iris()\n",
    "x = dataset.data\n",
    "Y = dataset.target\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# 构建模型函数\n",
    "def create_model(init='glorot_uniform'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    # 输入层使用dropout\n",
    "    model.add(Dropout(rate=0.2, input_shape=(4,)))\n",
    "    model.add(Dense(units=4, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
    "    '''\n",
    "    model = Sequnential()\n",
    "    隐藏层使用dropout\n",
    "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init, kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(units=6, activation='relu', kernel_initializer=init, kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
    "    '''\n",
    "    # 定义Dropout\n",
    "    sgd = SGD(lr=0.01, momentum=0.8, decay=0.0, nesterov=False)\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=200, batch_size=5, verbose=1)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, x, Y, cv=kfold)\n",
    "print('Accuracy: %.2f%% (%.2f)' % (results.mean()*100, results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.8887 - acc: 0.5400\n",
      "Epoch 2/200\n",
      "150/150 [==============================] - 0s 324us/step - loss: 0.5004 - acc: 0.6733\n",
      "Epoch 3/200\n",
      "150/150 [==============================] - 0s 387us/step - loss: 0.4959 - acc: 0.6533\n",
      "Epoch 4/200\n",
      "150/150 [==============================] - 0s 387us/step - loss: 0.4705 - acc: 0.7000\n",
      "Epoch 5/200\n",
      "150/150 [==============================] - 0s 427us/step - loss: 0.4758 - acc: 0.6533\n",
      "Epoch 6/200\n",
      "150/150 [==============================] - 0s 506us/step - loss: 0.4793 - acc: 0.6133\n",
      "Epoch 7/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.4774 - acc: 0.6600\n",
      "Epoch 8/200\n",
      "150/150 [==============================] - 0s 446us/step - loss: 0.4992 - acc: 0.6467\n",
      "Epoch 9/200\n",
      "150/150 [==============================] - 0s 334us/step - loss: 0.4811 - acc: 0.6267\n",
      "Epoch 10/200\n",
      "150/150 [==============================] - 0s 466us/step - loss: 0.4773 - acc: 0.6000\n",
      "Epoch 11/200\n",
      "150/150 [==============================] - 0s 506us/step - loss: 0.4732 - acc: 0.6400\n",
      "Epoch 12/200\n",
      "150/150 [==============================] - 0s 499us/step - loss: 0.4749 - acc: 0.6933\n",
      "Epoch 13/200\n",
      "150/150 [==============================] - 0s 400us/step - loss: 0.4906 - acc: 0.6467\n",
      "Epoch 14/200\n",
      "150/150 [==============================] - 0s 516us/step - loss: 0.4760 - acc: 0.6533\n",
      "Epoch 15/200\n",
      "150/150 [==============================] - 0s 443us/step - loss: 0.4703 - acc: 0.6667\n",
      "Epoch 16/200\n",
      "150/150 [==============================] - 0s 453us/step - loss: 0.4713 - acc: 0.6733\n",
      "Epoch 17/200\n",
      "150/150 [==============================] - 0s 423us/step - loss: 0.4712 - acc: 0.6333\n",
      "Epoch 18/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.4706 - acc: 0.6133\n",
      "Epoch 19/200\n",
      "150/150 [==============================] - 0s 331us/step - loss: 0.4697 - acc: 0.6067\n",
      "Epoch 20/200\n",
      "150/150 [==============================] - 0s 397us/step - loss: 0.4700 - acc: 0.6200\n",
      "Epoch 21/200\n",
      "150/150 [==============================] - 0s 341us/step - loss: 0.4774 - acc: 0.6200\n",
      "Epoch 22/200\n",
      "150/150 [==============================] - 0s 410us/step - loss: 0.4659 - acc: 0.6800\n",
      "Epoch 23/200\n",
      "150/150 [==============================] - 0s 407us/step - loss: 0.4764 - acc: 0.6600\n",
      "Epoch 24/200\n",
      "150/150 [==============================] - 0s 331us/step - loss: 0.4670 - acc: 0.6067\n",
      "Epoch 25/200\n",
      "150/150 [==============================] - 0s 440us/step - loss: 0.4679 - acc: 0.6667\n",
      "Epoch 26/200\n",
      "150/150 [==============================] - 0s 536us/step - loss: 0.4706 - acc: 0.6667\n",
      "Epoch 27/200\n",
      "150/150 [==============================] - 0s 360us/step - loss: 0.4657 - acc: 0.6867\n",
      "Epoch 28/200\n",
      "150/150 [==============================] - 0s 433us/step - loss: 0.4682 - acc: 0.6067\n",
      "Epoch 29/200\n",
      "150/150 [==============================] - 0s 552us/step - loss: 0.4670 - acc: 0.6667\n",
      "Epoch 30/200\n",
      "150/150 [==============================] - 0s 539us/step - loss: 0.4685 - acc: 0.6600\n",
      "Epoch 31/200\n",
      "150/150 [==============================] - 0s 549us/step - loss: 0.4640 - acc: 0.6667\n",
      "Epoch 32/200\n",
      "150/150 [==============================] - 0s 536us/step - loss: 0.4672 - acc: 0.6667\n",
      "Epoch 33/200\n",
      "150/150 [==============================] - 0s 344us/step - loss: 0.4654 - acc: 0.6733\n",
      "Epoch 34/200\n",
      "150/150 [==============================] - 0s 403us/step - loss: 0.4676 - acc: 0.6133\n",
      "Epoch 35/200\n",
      "150/150 [==============================] - 0s 374us/step - loss: 0.4649 - acc: 0.6467\n",
      "Epoch 36/200\n",
      "150/150 [==============================] - 0s 364us/step - loss: 0.4680 - acc: 0.6400\n",
      "Epoch 37/200\n",
      "150/150 [==============================] - 0s 364us/step - loss: 0.4636 - acc: 0.6867\n",
      "Epoch 38/200\n",
      "150/150 [==============================] - 0s 334us/step - loss: 0.4659 - acc: 0.6667\n",
      "Epoch 39/200\n",
      "150/150 [==============================] - 0s 321us/step - loss: 0.4662 - acc: 0.6667\n",
      "Epoch 40/200\n",
      "150/150 [==============================] - 0s 565us/step - loss: 0.4664 - acc: 0.6200\n",
      "Epoch 41/200\n",
      "150/150 [==============================] - 0s 509us/step - loss: 0.4660 - acc: 0.6333\n",
      "Epoch 42/200\n",
      "150/150 [==============================] - 0s 529us/step - loss: 0.4650 - acc: 0.6200 0s - loss: 0.4622 - acc: 0.609\n",
      "Epoch 43/200\n",
      "150/150 [==============================] - 0s 440us/step - loss: 0.4653 - acc: 0.6533\n",
      "Epoch 44/200\n",
      "150/150 [==============================] - 0s 532us/step - loss: 0.4687 - acc: 0.6667\n",
      "Epoch 45/200\n",
      "150/150 [==============================] - 0s 436us/step - loss: 0.4648 - acc: 0.6467\n",
      "Epoch 46/200\n",
      "150/150 [==============================] - 0s 317us/step - loss: 0.4667 - acc: 0.6333\n",
      "Epoch 47/200\n",
      "150/150 [==============================] - 0s 337us/step - loss: 0.4650 - acc: 0.6467\n",
      "Epoch 48/200\n",
      "150/150 [==============================] - 0s 532us/step - loss: 0.4654 - acc: 0.6133\n",
      "Epoch 49/200\n",
      "150/150 [==============================] - 0s 400us/step - loss: 0.4674 - acc: 0.6667\n",
      "Epoch 50/200\n",
      "150/150 [==============================] - 0s 284us/step - loss: 0.4658 - acc: 0.6600\n",
      "Epoch 51/200\n",
      "150/150 [==============================] - 0s 440us/step - loss: 0.4655 - acc: 0.6600\n",
      "Epoch 52/200\n",
      "150/150 [==============================] - 0s 341us/step - loss: 0.4661 - acc: 0.6200\n",
      "Epoch 53/200\n",
      "150/150 [==============================] - 0s 433us/step - loss: 0.4646 - acc: 0.6400\n",
      "Epoch 54/200\n",
      "150/150 [==============================] - 0s 420us/step - loss: 0.4652 - acc: 0.6667\n",
      "Epoch 55/200\n",
      "150/150 [==============================] - 0s 519us/step - loss: 0.4680 - acc: 0.6600\n",
      "Epoch 56/200\n",
      "150/150 [==============================] - 0s 351us/step - loss: 0.4630 - acc: 0.6667\n",
      "Epoch 57/200\n",
      "150/150 [==============================] - 0s 622us/step - loss: 0.4644 - acc: 0.6667\n",
      "Epoch 58/200\n",
      "150/150 [==============================] - 0s 314us/step - loss: 0.4671 - acc: 0.6200\n",
      "Epoch 59/200\n",
      "150/150 [==============================] - 0s 327us/step - loss: 0.4647 - acc: 0.6200\n",
      "Epoch 60/200\n",
      "150/150 [==============================] - 0s 357us/step - loss: 0.4648 - acc: 0.6667\n",
      "Epoch 61/200\n",
      "150/150 [==============================] - 0s 284us/step - loss: 0.4643 - acc: 0.6667\n",
      "Epoch 62/200\n",
      "150/150 [==============================] - 0s 377us/step - loss: 0.4642 - acc: 0.6067\n",
      "Epoch 63/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.4655 - acc: 0.6467\n",
      "Epoch 64/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.4644 - acc: 0.6667\n",
      "Epoch 65/200\n",
      "150/150 [==============================] - 0s 384us/step - loss: 0.4641 - acc: 0.6600\n",
      "Epoch 66/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.4644 - acc: 0.6400\n",
      "Epoch 67/200\n",
      "150/150 [==============================] - 0s 278us/step - loss: 0.4639 - acc: 0.6267\n",
      "Epoch 68/200\n",
      "150/150 [==============================] - 0s 304us/step - loss: 0.4656 - acc: 0.6667\n",
      "Epoch 69/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.4648 - acc: 0.6467\n",
      "Epoch 70/200\n",
      "150/150 [==============================] - 0s 294us/step - loss: 0.4650 - acc: 0.6400\n",
      "Epoch 71/200\n",
      "150/150 [==============================] - 0s 344us/step - loss: 0.4649 - acc: 0.6333\n",
      "Epoch 72/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.4641 - acc: 0.6333\n",
      "Epoch 73/200\n",
      "150/150 [==============================] - 0s 317us/step - loss: 0.4648 - acc: 0.6667\n",
      "Epoch 74/200\n",
      "150/150 [==============================] - 0s 308us/step - loss: 0.4648 - acc: 0.5800\n",
      "Epoch 75/200\n",
      "150/150 [==============================] - 0s 337us/step - loss: 0.4669 - acc: 0.6200\n",
      "Epoch 76/200\n",
      "150/150 [==============================] - 0s 324us/step - loss: 0.4640 - acc: 0.6733\n",
      "Epoch 77/200\n",
      "150/150 [==============================] - 0s 400us/step - loss: 0.4641 - acc: 0.6133\n",
      "Epoch 78/200\n",
      "150/150 [==============================] - 0s 321us/step - loss: 0.4645 - acc: 0.6333\n",
      "Epoch 79/200\n",
      "150/150 [==============================] - 0s 317us/step - loss: 0.4638 - acc: 0.6667\n",
      "Epoch 80/200\n",
      "150/150 [==============================] - 0s 304us/step - loss: 0.4651 - acc: 0.6133\n",
      "Epoch 81/200\n",
      "150/150 [==============================] - 0s 344us/step - loss: 0.4646 - acc: 0.6667\n",
      "Epoch 82/200\n",
      "150/150 [==============================] - 0s 255us/step - loss: 0.4644 - acc: 0.6400\n",
      "Epoch 83/200\n",
      "150/150 [==============================] - 0s 268us/step - loss: 0.4654 - acc: 0.6133\n",
      "Epoch 84/200\n",
      "150/150 [==============================] - 0s 327us/step - loss: 0.4647 - acc: 0.6400\n",
      "Epoch 85/200\n",
      "150/150 [==============================] - 0s 304us/step - loss: 0.4652 - acc: 0.6667\n",
      "Epoch 86/200\n",
      "150/150 [==============================] - 0s 327us/step - loss: 0.4652 - acc: 0.5733\n",
      "Epoch 87/200\n",
      "150/150 [==============================] - 0s 321us/step - loss: 0.4645 - acc: 0.6333\n",
      "Epoch 88/200\n",
      "150/150 [==============================] - 0s 304us/step - loss: 0.4654 - acc: 0.6000\n",
      "Epoch 89/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4646 - acc: 0.6000\n",
      "Epoch 90/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.4641 - acc: 0.6200\n",
      "Epoch 91/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.4666 - acc: 0.6200\n",
      "Epoch 92/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4640 - acc: 0.6133\n",
      "Epoch 93/200\n",
      "150/150 [==============================] - 0s 364us/step - loss: 0.4642 - acc: 0.6400\n",
      "Epoch 94/200\n",
      "150/150 [==============================] - 0s 387us/step - loss: 0.4644 - acc: 0.6467\n",
      "Epoch 95/200\n",
      "150/150 [==============================] - 0s 427us/step - loss: 0.4642 - acc: 0.6333\n",
      "Epoch 96/200\n",
      "150/150 [==============================] - 0s 384us/step - loss: 0.4639 - acc: 0.6667\n",
      "Epoch 97/200\n",
      "150/150 [==============================] - 0s 324us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 98/200\n",
      "150/150 [==============================] - 0s 334us/step - loss: 0.4645 - acc: 0.6400\n",
      "Epoch 99/200\n",
      "150/150 [==============================] - 0s 390us/step - loss: 0.4638 - acc: 0.6667\n",
      "Epoch 100/200\n",
      "150/150 [==============================] - 0s 268us/step - loss: 0.4635 - acc: 0.6667\n",
      "Epoch 101/200\n",
      "150/150 [==============================] - 0s 278us/step - loss: 0.4645 - acc: 0.6467\n",
      "Epoch 102/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.4646 - acc: 0.6133\n",
      "Epoch 103/200\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.4640 - acc: 0.6400\n",
      "Epoch 104/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.4652 - acc: 0.6200\n",
      "Epoch 105/200\n",
      "150/150 [==============================] - 0s 274us/step - loss: 0.4652 - acc: 0.6467\n",
      "Epoch 106/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.4647 - acc: 0.6400\n",
      "Epoch 107/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.4652 - acc: 0.6667\n",
      "Epoch 108/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.4633 - acc: 0.6733\n",
      "Epoch 109/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.4640 - acc: 0.6667\n",
      "Epoch 110/200\n",
      "150/150 [==============================] - 0s 251us/step - loss: 0.4645 - acc: 0.6400\n",
      "Epoch 111/200\n",
      "150/150 [==============================] - 0s 288us/step - loss: 0.4635 - acc: 0.6667\n",
      "Epoch 112/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.4661 - acc: 0.6667\n",
      "Epoch 113/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.4630 - acc: 0.6667\n",
      "Epoch 114/200\n",
      "150/150 [==============================] - 0s 284us/step - loss: 0.4642 - acc: 0.6600\n",
      "Epoch 115/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.4685 - acc: 0.5800\n",
      "Epoch 116/200\n",
      "150/150 [==============================] - 0s 255us/step - loss: 0.4632 - acc: 0.6667\n",
      "Epoch 117/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.4648 - acc: 0.5933\n",
      "Epoch 118/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.4665 - acc: 0.6667\n",
      "Epoch 119/200\n",
      "150/150 [==============================] - 0s 198us/step - loss: 0.4651 - acc: 0.6600\n",
      "Epoch 120/200\n",
      "150/150 [==============================] - 0s 195us/step - loss: 0.4636 - acc: 0.6533\n",
      "Epoch 121/200\n",
      "150/150 [==============================] - 0s 271us/step - loss: 0.4637 - acc: 0.6133\n",
      "Epoch 122/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4636 - acc: 0.5600\n",
      "Epoch 123/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.4643 - acc: 0.6600\n",
      "Epoch 124/200\n",
      "150/150 [==============================] - 0s 264us/step - loss: 0.4644 - acc: 0.6200\n",
      "Epoch 125/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4636 - acc: 0.6667\n",
      "Epoch 126/200\n",
      "150/150 [==============================] - 0s 205us/step - loss: 0.4635 - acc: 0.6600\n",
      "Epoch 127/200\n",
      "150/150 [==============================] - 0s 195us/step - loss: 0.4639 - acc: 0.6333\n",
      "Epoch 128/200\n",
      "150/150 [==============================] - 0s 304us/step - loss: 0.4640 - acc: 0.6267\n",
      "Epoch 129/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.4638 - acc: 0.6067\n",
      "Epoch 130/200\n",
      "150/150 [==============================] - 0s 195us/step - loss: 0.4645 - acc: 0.6267\n",
      "Epoch 131/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4635 - acc: 0.6200\n",
      "Epoch 132/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 133/200\n",
      "150/150 [==============================] - 0s 255us/step - loss: 0.4638 - acc: 0.6467\n",
      "Epoch 134/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.4640 - acc: 0.6667\n",
      "Epoch 135/200\n",
      "150/150 [==============================] - 0s 284us/step - loss: 0.4635 - acc: 0.6267\n",
      "Epoch 136/200\n",
      "150/150 [==============================] - 0s 218us/step - loss: 0.4638 - acc: 0.6533\n",
      "Epoch 137/200\n",
      "150/150 [==============================] - 0s 218us/step - loss: 0.4639 - acc: 0.6400\n",
      "Epoch 138/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.4648 - acc: 0.6667\n",
      "Epoch 139/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.4639 - acc: 0.6333\n",
      "Epoch 140/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.4638 - acc: 0.6467\n",
      "Epoch 141/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.4634 - acc: 0.6267\n",
      "Epoch 142/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.4636 - acc: 0.6400\n",
      "Epoch 143/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4640 - acc: 0.6600\n",
      "Epoch 144/200\n",
      "150/150 [==============================] - 0s 268us/step - loss: 0.4657 - acc: 0.6000\n",
      "Epoch 145/200\n",
      "150/150 [==============================] - 0s 294us/step - loss: 0.4651 - acc: 0.6400\n",
      "Epoch 146/200\n",
      "150/150 [==============================] - 0s 331us/step - loss: 0.4641 - acc: 0.6333\n",
      "Epoch 147/200\n",
      "150/150 [==============================] - 0s 215us/step - loss: 0.4643 - acc: 0.6200\n",
      "Epoch 148/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.4637 - acc: 0.6267\n",
      "Epoch 149/200\n",
      "150/150 [==============================] - 0s 265us/step - loss: 0.4641 - acc: 0.6667\n",
      "Epoch 150/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.4637 - acc: 0.6533\n",
      "Epoch 151/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.4633 - acc: 0.6667\n",
      "Epoch 152/200\n",
      "150/150 [==============================] - 0s 291us/step - loss: 0.4646 - acc: 0.6467\n",
      "Epoch 153/200\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.4633 - acc: 0.6667\n",
      "Epoch 154/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.4636 - acc: 0.6733\n",
      "Epoch 155/200\n",
      "150/150 [==============================] - 0s 251us/step - loss: 0.4635 - acc: 0.6667\n",
      "Epoch 156/200\n",
      "150/150 [==============================] - 0s 407us/step - loss: 0.4654 - acc: 0.5933\n",
      "Epoch 157/200\n",
      "150/150 [==============================] - 0s 807us/step - loss: 0.4635 - acc: 0.6467\n",
      "Epoch 158/200\n",
      "150/150 [==============================] - 0s 734us/step - loss: 0.4636 - acc: 0.6667\n",
      "Epoch 159/200\n",
      "150/150 [==============================] - 0s 585us/step - loss: 0.4636 - acc: 0.6667\n",
      "Epoch 160/200\n",
      "150/150 [==============================] - 0s 592us/step - loss: 0.4643 - acc: 0.6667\n",
      "Epoch 161/200\n",
      "150/150 [==============================] - 0s 476us/step - loss: 0.4636 - acc: 0.6667\n",
      "Epoch 162/200\n",
      "150/150 [==============================] - 0s 284us/step - loss: 0.4633 - acc: 0.6467\n",
      "Epoch 163/200\n",
      "150/150 [==============================] - 0s 228us/step - loss: 0.4637 - acc: 0.6533\n",
      "Epoch 164/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.4638 - acc: 0.6667\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 202us/step - loss: 0.4640 - acc: 0.5867\n",
      "Epoch 166/200\n",
      "150/150 [==============================] - 0s 380us/step - loss: 0.4636 - acc: 0.6267\n",
      "Epoch 167/200\n",
      "150/150 [==============================] - 0s 566us/step - loss: 0.4649 - acc: 0.6200\n",
      "Epoch 168/200\n",
      "150/150 [==============================] - 0s 913us/step - loss: 0.4636 - acc: 0.6667\n",
      "Epoch 169/200\n",
      "150/150 [==============================] - 0s 711us/step - loss: 0.4640 - acc: 0.6400\n",
      "Epoch 170/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4635 - acc: 0.6400\n",
      "Epoch 171/200\n",
      "150/150 [==============================] - 0s 274us/step - loss: 0.4639 - acc: 0.6667\n",
      "Epoch 172/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.4635 - acc: 0.6667\n",
      "Epoch 173/200\n",
      "150/150 [==============================] - 0s 255us/step - loss: 0.4637 - acc: 0.6333\n",
      "Epoch 174/200\n",
      "150/150 [==============================] - 0s 278us/step - loss: 0.4641 - acc: 0.6067\n",
      "Epoch 175/200\n",
      "150/150 [==============================] - 0s 205us/step - loss: 0.4635 - acc: 0.6467\n",
      "Epoch 176/200\n",
      "150/150 [==============================] - 0s 404us/step - loss: 0.4646 - acc: 0.6533\n",
      "Epoch 177/200\n",
      "150/150 [==============================] - 0s 903us/step - loss: 0.4635 - acc: 0.6067\n",
      "Epoch 178/200\n",
      "150/150 [==============================] - 0s 632us/step - loss: 0.4639 - acc: 0.6667\n",
      "Epoch 179/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.4633 - acc: 0.6400\n",
      "Epoch 180/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.4634 - acc: 0.6667\n",
      "Epoch 181/200\n",
      "150/150 [==============================] - 0s 218us/step - loss: 0.4640 - acc: 0.6667\n",
      "Epoch 182/200\n",
      "150/150 [==============================] - 0s 278us/step - loss: 0.4642 - acc: 0.6467\n",
      "Epoch 183/200\n",
      "150/150 [==============================] - 0s 251us/step - loss: 0.4635 - acc: 0.6267\n",
      "Epoch 184/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.4634 - acc: 0.6667\n",
      "Epoch 185/200\n",
      "150/150 [==============================] - 0s 228us/step - loss: 0.4640 - acc: 0.6400\n",
      "Epoch 186/200\n",
      "150/150 [==============================] - 0s 526us/step - loss: 0.4639 - acc: 0.6400\n",
      "Epoch 187/200\n",
      "150/150 [==============================] - 0s 932us/step - loss: 0.4635 - acc: 0.6667\n",
      "Epoch 188/200\n",
      "150/150 [==============================] - 0s 433us/step - loss: 0.4634 - acc: 0.6533\n",
      "Epoch 189/200\n",
      "150/150 [==============================] - 0s 291us/step - loss: 0.4635 - acc: 0.6200\n",
      "Epoch 190/200\n",
      "150/150 [==============================] - 0s 268us/step - loss: 0.4638 - acc: 0.6267\n",
      "Epoch 191/200\n",
      "150/150 [==============================] - 0s 218us/step - loss: 0.4641 - acc: 0.6133\n",
      "Epoch 192/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4634 - acc: 0.6667\n",
      "Epoch 193/200\n",
      "150/150 [==============================] - 0s 265us/step - loss: 0.4634 - acc: 0.6267\n",
      "Epoch 194/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.4634 - acc: 0.6400\n",
      "Epoch 195/200\n",
      "150/150 [==============================] - 0s 509us/step - loss: 0.4639 - acc: 0.6267\n",
      "Epoch 196/200\n",
      "150/150 [==============================] - 0s 810us/step - loss: 0.4634 - acc: 0.6267\n",
      "Epoch 197/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.4639 - acc: 0.6333\n",
      "Epoch 198/200\n",
      "150/150 [==============================] - 0s 288us/step - loss: 0.4635 - acc: 0.6600\n",
      "Epoch 199/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4633 - acc: 0.6400\n",
      "Epoch 200/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.4640 - acc: 0.6333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25436f55dc8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keras——学习率衰减\n",
    "# 学习率线性衰减\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 导入数据\n",
    "dataset = datasets.load_iris()\n",
    "x = dataset.data\n",
    "Y = dataset.target\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# 构建模型函数\n",
    "def create_model(init='glorot_uniform'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init))\n",
    "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
    "    #模型优化\n",
    "    learningRate = 0.1\n",
    "    momentum = 0.9\n",
    "    decay_rate = 0.005\n",
    "    sgd = SGD(lr=learningRate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "epochs = 200\n",
    "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=5, verbose=1)\n",
    "model.fit(x, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.8559 - acc: 0.5333\n",
      "Epoch 2/200\n",
      "150/150 [==============================] - 0s 327us/step - loss: 0.5040 - acc: 0.6533\n",
      "Epoch 3/200\n",
      "150/150 [==============================] - 0s 317us/step - loss: 0.5671 - acc: 0.6467\n",
      "Epoch 4/200\n",
      "150/150 [==============================] - 0s 443us/step - loss: 0.4735 - acc: 0.6800\n",
      "Epoch 5/200\n",
      "150/150 [==============================] - 0s 489us/step - loss: 0.4777 - acc: 0.6600\n",
      "Epoch 6/200\n",
      "150/150 [==============================] - 0s 503us/step - loss: 0.4813 - acc: 0.6133\n",
      "Epoch 7/200\n",
      "150/150 [==============================] - 0s 496us/step - loss: 0.4788 - acc: 0.6533\n",
      "Epoch 8/200\n",
      "150/150 [==============================] - 0s 470us/step - loss: 0.5052 - acc: 0.6533\n",
      "Epoch 9/200\n",
      "150/150 [==============================] - 0s 476us/step - loss: 0.4884 - acc: 0.6400\n",
      "Epoch 10/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.4808 - acc: 0.6000\n",
      "Epoch 11/200\n",
      "150/150 [==============================] - 0s 493us/step - loss: 0.4759 - acc: 0.6533\n",
      "Epoch 12/200\n",
      "150/150 [==============================] - 0s 473us/step - loss: 0.4736 - acc: 0.6867\n",
      "Epoch 13/200\n",
      "150/150 [==============================] - 0s 473us/step - loss: 0.4947 - acc: 0.6667\n",
      "Epoch 14/200\n",
      "150/150 [==============================] - 0s 489us/step - loss: 0.4776 - acc: 0.6400\n",
      "Epoch 15/200\n",
      "150/150 [==============================] - 0s 509us/step - loss: 0.4695 - acc: 0.6667\n",
      "Epoch 16/200\n",
      "150/150 [==============================] - 0s 360us/step - loss: 0.4718 - acc: 0.6600\n",
      "Epoch 17/200\n",
      "150/150 [==============================] - 0s 354us/step - loss: 0.4718 - acc: 0.6333\n",
      "Epoch 18/200\n",
      "150/150 [==============================] - 0s 529us/step - loss: 0.4708 - acc: 0.5933\n",
      "Epoch 19/200\n",
      "150/150 [==============================] - 0s 387us/step - loss: 0.4695 - acc: 0.6067\n",
      "Epoch 20/200\n",
      "150/150 [==============================] - 0s 314us/step - loss: 0.4697 - acc: 0.6200\n",
      "Epoch 21/200\n",
      "150/150 [==============================] - 0s 456us/step - loss: 0.4765 - acc: 0.6333\n",
      "Epoch 22/200\n",
      "150/150 [==============================] - 0s 433us/step - loss: 0.4656 - acc: 0.6867\n",
      "Epoch 23/200\n",
      "150/150 [==============================] - 0s 499us/step - loss: 0.4750 - acc: 0.6533\n",
      "Epoch 24/200\n",
      "150/150 [==============================] - 0s 374us/step - loss: 0.4661 - acc: 0.6267\n",
      "Epoch 25/200\n",
      "150/150 [==============================] - 0s 599us/step - loss: 0.4672 - acc: 0.6667\n",
      "Epoch 26/200\n",
      "150/150 [==============================] - 0s 572us/step - loss: 0.4693 - acc: 0.6667\n",
      "Epoch 27/200\n",
      "150/150 [==============================] - 0s 463us/step - loss: 0.4648 - acc: 0.6800\n",
      "Epoch 28/200\n",
      "150/150 [==============================] - 0s 407us/step - loss: 0.4670 - acc: 0.6667\n",
      "Epoch 29/200\n",
      "150/150 [==============================] - 0s 470us/step - loss: 0.4661 - acc: 0.6667\n",
      "Epoch 30/200\n",
      "150/150 [==============================] - 0s 380us/step - loss: 0.4671 - acc: 0.6867\n",
      "Epoch 31/200\n",
      "150/150 [==============================] - 0s 440us/step - loss: 0.4640 - acc: 0.6733\n",
      "Epoch 32/200\n",
      "150/150 [==============================] - 0s 413us/step - loss: 0.4662 - acc: 0.6667\n",
      "Epoch 33/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.4646 - acc: 0.6467\n",
      "Epoch 34/200\n",
      "150/150 [==============================] - 0s 460us/step - loss: 0.4657 - acc: 0.6000\n",
      "Epoch 35/200\n",
      "150/150 [==============================] - 0s 456us/step - loss: 0.4644 - acc: 0.6467\n",
      "Epoch 36/200\n",
      "150/150 [==============================] - 0s 281us/step - loss: 0.4661 - acc: 0.6400\n",
      "Epoch 37/200\n",
      "150/150 [==============================] - 0s 493us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 38/200\n",
      "150/150 [==============================] - 0s 506us/step - loss: 0.4647 - acc: 0.6667\n",
      "Epoch 39/200\n",
      "150/150 [==============================] - 0s 327us/step - loss: 0.4649 - acc: 0.6667\n",
      "Epoch 40/200\n",
      "150/150 [==============================] - 0s 288us/step - loss: 0.4648 - acc: 0.6067\n",
      "Epoch 41/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.4646 - acc: 0.6400\n",
      "Epoch 42/200\n",
      "150/150 [==============================] - 0s 463us/step - loss: 0.4642 - acc: 0.6800\n",
      "Epoch 43/200\n",
      "150/150 [==============================] - 0s 321us/step - loss: 0.4645 - acc: 0.6667\n",
      "Epoch 44/200\n",
      "150/150 [==============================] - 0s 294us/step - loss: 0.4655 - acc: 0.5933\n",
      "Epoch 45/200\n",
      "150/150 [==============================] - 0s 446us/step - loss: 0.4641 - acc: 0.6533\n",
      "Epoch 46/200\n",
      "150/150 [==============================] - 0s 493us/step - loss: 0.4647 - acc: 0.6333\n",
      "Epoch 47/200\n",
      "150/150 [==============================] - 0s 393us/step - loss: 0.4642 - acc: 0.6400\n",
      "Epoch 48/200\n",
      "150/150 [==============================] - 0s 433us/step - loss: 0.4642 - acc: 0.6133\n",
      "Epoch 49/200\n",
      "150/150 [==============================] - 0s 489us/step - loss: 0.4650 - acc: 0.6667\n",
      "Epoch 50/200\n",
      "150/150 [==============================] - 0s 344us/step - loss: 0.4642 - acc: 0.6600\n",
      "Epoch 51/200\n",
      "150/150 [==============================] - 0s 311us/step - loss: 0.4642 - acc: 0.6667\n",
      "Epoch 52/200\n",
      "150/150 [==============================] - 0s 423us/step - loss: 0.4643 - acc: 0.6200\n",
      "Epoch 53/200\n",
      "150/150 [==============================] - 0s 344us/step - loss: 0.4639 - acc: 0.6400\n",
      "Epoch 54/200\n",
      "150/150 [==============================] - 0s 420us/step - loss: 0.4641 - acc: 0.6667\n",
      "Epoch 55/200\n",
      "150/150 [==============================] - 0s 374us/step - loss: 0.4646 - acc: 0.6400\n",
      "Epoch 56/200\n",
      "150/150 [==============================] - 0s 483us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 57/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.4638 - acc: 0.6600\n",
      "Epoch 58/200\n",
      "150/150 [==============================] - 0s 331us/step - loss: 0.4642 - acc: 0.6400\n",
      "Epoch 59/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.4639 - acc: 0.6667\n",
      "Epoch 60/200\n",
      "150/150 [==============================] - 0s 291us/step - loss: 0.4639 - acc: 0.5733\n",
      "Epoch 61/200\n",
      "150/150 [==============================] - 0s 357us/step - loss: 0.4638 - acc: 0.6667\n",
      "Epoch 62/200\n",
      "150/150 [==============================] - 0s 311us/step - loss: 0.4638 - acc: 0.6667\n",
      "Epoch 63/200\n",
      "150/150 [==============================] - 0s 367us/step - loss: 0.4640 - acc: 0.5867\n",
      "Epoch 64/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.4638 - acc: 0.6667\n",
      "Epoch 65/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.4638 - acc: 0.6667\n",
      "Epoch 66/200\n",
      "150/150 [==============================] - 0s 367us/step - loss: 0.4638 - acc: 0.6667\n",
      "Epoch 67/200\n",
      "150/150 [==============================] - 0s 291us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 68/200\n",
      "150/150 [==============================] - 0s 341us/step - loss: 0.4639 - acc: 0.6333\n",
      "Epoch 69/200\n",
      "150/150 [==============================] - 0s 344us/step - loss: 0.4638 - acc: 0.6600\n",
      "Epoch 70/200\n",
      "150/150 [==============================] - 0s 384us/step - loss: 0.4638 - acc: 0.6333\n",
      "Epoch 71/200\n",
      "150/150 [==============================] - 0s 344us/step - loss: 0.4638 - acc: 0.6333\n",
      "Epoch 72/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 73/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.4638 - acc: 0.6533\n",
      "Epoch 74/200\n",
      "150/150 [==============================] - 0s 357us/step - loss: 0.4638 - acc: 0.5867\n",
      "Epoch 75/200\n",
      "150/150 [==============================] - 0s 334us/step - loss: 0.4639 - acc: 0.6200\n",
      "Epoch 76/200\n",
      "150/150 [==============================] - 0s 308us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 77/200\n",
      "150/150 [==============================] - 0s 321us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 78/200\n",
      "150/150 [==============================] - 0s 274us/step - loss: 0.4637 - acc: 0.6000\n",
      "Epoch 79/200\n",
      "150/150 [==============================] - 0s 324us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 80/200\n",
      "150/150 [==============================] - 0s 331us/step - loss: 0.4638 - acc: 0.5933\n",
      "Epoch 81/200\n",
      "150/150 [==============================] - 0s 317us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 82/200\n",
      "150/150 [==============================] - 0s 638us/step - loss: 0.4637 - acc: 0.6200\n",
      "Epoch 83/200\n",
      "150/150 [==============================] - 0s 641us/step - loss: 0.4638 - acc: 0.6667\n",
      "Epoch 84/200\n",
      "150/150 [==============================] - 0s 321us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 85/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.4637 - acc: 0.6200\n",
      "Epoch 86/200\n",
      "150/150 [==============================] - 0s 265us/step - loss: 0.4637 - acc: 0.6400\n",
      "Epoch 87/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.4637 - acc: 0.6333\n",
      "Epoch 88/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 89/200\n",
      "150/150 [==============================] - 0s 274us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 90/200\n",
      "150/150 [==============================] - 0s 331us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 91/200\n",
      "150/150 [==============================] - 0s 331us/step - loss: 0.4638 - acc: 0.6067\n",
      "Epoch 92/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 93/200\n",
      "150/150 [==============================] - 0s 255us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 94/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 95/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 96/200\n",
      "150/150 [==============================] - 0s 268us/step - loss: 0.4637 - acc: 0.6333\n",
      "Epoch 97/200\n",
      "150/150 [==============================] - 0s 308us/step - loss: 0.4637 - acc: 0.6400\n",
      "Epoch 98/200\n",
      "150/150 [==============================] - 0s 301us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 99/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 100/200\n",
      "150/150 [==============================] - 0s 331us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 101/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 102/200\n",
      "150/150 [==============================] - 0s 301us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 103/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 104/200\n",
      "150/150 [==============================] - 0s 255us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 105/200\n",
      "150/150 [==============================] - 0s 265us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 106/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 107/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 108/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 109/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 110/200\n",
      "150/150 [==============================] - 0s 317us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 111/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 112/200\n",
      "150/150 [==============================] - 0s 327us/step - loss: 0.4637 - acc: 0.6067\n",
      "Epoch 113/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 114/200\n",
      "150/150 [==============================] - 0s 251us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 115/200\n",
      "150/150 [==============================] - 0s 546us/step - loss: 0.4637 - acc: 0.5867\n",
      "Epoch 116/200\n",
      "150/150 [==============================] - 0s 324us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 117/200\n",
      "150/150 [==============================] - 0s 251us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 118/200\n",
      "150/150 [==============================] - 0s 331us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 119/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 120/200\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 121/200\n",
      "150/150 [==============================] - 0s 271us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 122/200\n",
      "150/150 [==============================] - 0s 453us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 123/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 124/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 125/200\n",
      "150/150 [==============================] - 0s 317us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 126/200\n",
      "150/150 [==============================] - 0s 301us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 127/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 128/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 129/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 130/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 131/200\n",
      "150/150 [==============================] - 0s 268us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 132/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 133/200\n",
      "150/150 [==============================] - 0s 232us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 134/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 135/200\n",
      "150/150 [==============================] - 0s 255us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 136/200\n",
      "150/150 [==============================] - 0s 162us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 137/200\n",
      "150/150 [==============================] - 0s 175us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 138/200\n",
      "150/150 [==============================] - 0s 417us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 139/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 140/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 141/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 142/200\n",
      "150/150 [==============================] - 0s 221us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 143/200\n",
      "150/150 [==============================] - 0s 268us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 144/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 145/200\n",
      "150/150 [==============================] - 0s 274us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 146/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 147/200\n",
      "150/150 [==============================] - 0s 274us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 148/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 149/200\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 150/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 151/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 152/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 153/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 154/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 155/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 156/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 157/200\n",
      "150/150 [==============================] - 0s 288us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 158/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 159/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 160/200\n",
      "150/150 [==============================] - 0s 268us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 161/200\n",
      "150/150 [==============================] - 0s 192us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 162/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 163/200\n",
      "150/150 [==============================] - 0s 288us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 164/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 255us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 166/200\n",
      "150/150 [==============================] - 0s 251us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 167/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 168/200\n",
      "150/150 [==============================] - 0s 278us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 169/200\n",
      "150/150 [==============================] - 0s 228us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 170/200\n",
      "150/150 [==============================] - 0s 278us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 171/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 172/200\n",
      "150/150 [==============================] - 0s 278us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 173/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 174/200\n",
      "150/150 [==============================] - 0s 337us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 175/200\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 176/200\n",
      "150/150 [==============================] - 0s 274us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 177/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 178/200\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 179/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 180/200\n",
      "150/150 [==============================] - 0s 271us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 181/200\n",
      "150/150 [==============================] - 0s 251us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 182/200\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 183/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 184/200\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 185/200\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 186/200\n",
      "150/150 [==============================] - 0s 268us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 187/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 188/200\n",
      "150/150 [==============================] - 0s 185us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 189/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 190/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 191/200\n",
      "150/150 [==============================] - 0s 274us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 192/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 193/200\n",
      "150/150 [==============================] - 0s 321us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 194/200\n",
      "150/150 [==============================] - 0s 513us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 195/200\n",
      "150/150 [==============================] - 0s 522us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 196/200\n",
      "150/150 [==============================] - 0s 311us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 197/200\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 198/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 199/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.4637 - acc: 0.6667\n",
      "Epoch 200/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.4637 - acc: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x254382c7348>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学习率指数衰减\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from math import pow, floor\n",
    "# 导入数据\n",
    "dataset = datasets.load_iris()\n",
    "x = dataset.data\n",
    "Y = dataset.target\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# 计算学习率\n",
    "def step_decay(epoch):\n",
    "    init_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10\n",
    "    lrate = init_lrate * pow(drop, floor(1 + epoch) / epochs_drop)\n",
    "    return lrate\n",
    "# 构建模型函数\n",
    "def create_model(init='glorot_uniform'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init))\n",
    "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
    "    #模型优化\n",
    "    learningRate = 0.1\n",
    "    momentum = 0.9\n",
    "    decay_rate = 0.0\n",
    "    sgd = SGD(lr=learningRate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "epochs = 200\n",
    "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=5, verbose=1, callbacks=[lrate])\n",
    "model.fit(x, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 1.0141 - acc: 0.4000\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.9718 - acc: 0.4750\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.9392 - acc: 0.5500\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.9055 - acc: 0.5833\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.8717 - acc: 0.5833\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.8306 - acc: 0.6000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.7886 - acc: 0.5500\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.7531 - acc: 0.5000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.7268 - acc: 0.5250\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.7055 - acc: 0.7750\n",
      "Base acc: 80.00%\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.8118 - acc: 0.7333\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.8026 - acc: 0.7333\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.7964 - acc: 0.7333\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.7913 - acc: 0.7333\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.7886 - acc: 0.7667\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.7835 - acc: 0.7667\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.7786 - acc: 0.8333\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.7746 - acc: 0.8667\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.7703 - acc: 0.8667\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.7655 - acc: 0.8667\n",
      "Increment acc: 90.00%\n"
     ]
    }
   ],
   "source": [
    "# Keras——模型增量更新\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# 导入数据\n",
    "dataset = datasets.load_iris()\n",
    "x = dataset.data\n",
    "Y = dataset.target\n",
    "x_train, x_increment, Y_train, Y_increment = train_test_split(x, Y, test_size=0.2, random_state=seed)\n",
    "# 将标签转换成分类编码\n",
    "Y_train_labels = to_categorical(Y_train, num_classes=3)\n",
    "# 构建模型函数\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init))\n",
    "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "# 构建模型\n",
    "model = create_model()\n",
    "model.fit(x_train, Y_train_labels, epochs=10, batch_size=5, verbose=2)\n",
    "scores = model.evaluate(x_train, Y_train_labels, verbose=0)\n",
    "print('Base %s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n",
    "\n",
    "# 模型保存成Json文件\n",
    "current_path = r'C:/Users/Lenovo/Desktop/data/models/'\n",
    "model_json = model.to_json()\n",
    "with open(current_path+'model.increment.json', 'w') as file:\n",
    "    file.write(model_json)\n",
    "# 保存模型的权重值\n",
    "model.save_weights(current_path+'model.increment.json.h5')\n",
    "\n",
    "# 从Json加载模型\n",
    "with open(current_path+'model.increment.json', 'r') as file:\n",
    "    model_json = file.read()\n",
    "# 加载模型\n",
    "new_model = model_from_json(model_json)\n",
    "new_model.load_weights(current_path+'model.increment.json.h5')\n",
    "# 编译模型\n",
    "new_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# 增量训练模型\n",
    "# 将标签转换成分类编码\n",
    "Y_increment_labels = to_categorical(Y_increment, num_classes=3)\n",
    "new_model.fit(x_increment, Y_increment_labels, epochs=10, batch_size=5, verbose=2)\n",
    "scores = new_model.evaluate(x_increment, Y_increment_labels, verbose=0)\n",
    "print('Increment %s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/150\n",
      "614/614 [==============================] - 1s 2ms/step - loss: 3.8979 - acc: 0.6417 - val_loss: 1.9774 - val_acc: 0.5844\n",
      "Epoch 2/150\n",
      "614/614 [==============================] - 0s 191us/step - loss: 1.1657 - acc: 0.5391 - val_loss: 0.7960 - val_acc: 0.6558\n",
      "Epoch 3/150\n",
      "614/614 [==============================] - 0s 172us/step - loss: 0.7796 - acc: 0.6417 - val_loss: 0.8530 - val_acc: 0.6429\n",
      "Epoch 4/150\n",
      "614/614 [==============================] - 0s 202us/step - loss: 0.7278 - acc: 0.6629 - val_loss: 0.7112 - val_acc: 0.7078\n",
      "Epoch 5/150\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.7241 - acc: 0.6564 - val_loss: 0.7170 - val_acc: 0.6104\n",
      "Epoch 6/150\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.6871 - acc: 0.6629 - val_loss: 0.7602 - val_acc: 0.6299\n",
      "Epoch 7/150\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.6686 - acc: 0.6808 - val_loss: 0.6692 - val_acc: 0.6818\n",
      "Epoch 8/150\n",
      "614/614 [==============================] - 0s 265us/step - loss: 0.6461 - acc: 0.6743 - val_loss: 0.6636 - val_acc: 0.6558\n",
      "Epoch 9/150\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.6453 - acc: 0.6824 - val_loss: 0.6587 - val_acc: 0.6494\n",
      "Epoch 10/150\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.6243 - acc: 0.6824 - val_loss: 0.6497 - val_acc: 0.6688\n",
      "Epoch 11/150\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.6124 - acc: 0.7003 - val_loss: 0.6718 - val_acc: 0.6623\n",
      "Epoch 12/150\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.6064 - acc: 0.7166 - val_loss: 0.6462 - val_acc: 0.6623\n",
      "Epoch 13/150\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.6055 - acc: 0.6971 - val_loss: 0.6529 - val_acc: 0.6429\n",
      "Epoch 14/150\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.6266 - acc: 0.6759 - val_loss: 0.6956 - val_acc: 0.5844\n",
      "Epoch 15/150\n",
      "614/614 [==============================] - 0s 305us/step - loss: 0.6145 - acc: 0.6938 - val_loss: 0.6456 - val_acc: 0.6753\n",
      "Epoch 16/150\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.5986 - acc: 0.6906 - val_loss: 0.6432 - val_acc: 0.6558\n",
      "Epoch 17/150\n",
      "614/614 [==============================] - 0s 210us/step - loss: 0.6070 - acc: 0.6938 - val_loss: 0.6295 - val_acc: 0.6753\n",
      "Epoch 18/150\n",
      "614/614 [==============================] - 0s 206us/step - loss: 0.5935 - acc: 0.6971 - val_loss: 0.6280 - val_acc: 0.6753\n",
      "Epoch 19/150\n",
      "614/614 [==============================] - 0s 190us/step - loss: 0.5868 - acc: 0.7134 - val_loss: 0.6428 - val_acc: 0.6558\n",
      "Epoch 20/150\n",
      "614/614 [==============================] - 0s 193us/step - loss: 0.5911 - acc: 0.7003 - val_loss: 0.6678 - val_acc: 0.6429\n",
      "Epoch 21/150\n",
      "614/614 [==============================] - 0s 194us/step - loss: 0.5747 - acc: 0.7134 - val_loss: 0.7203 - val_acc: 0.6558\n",
      "Epoch 22/150\n",
      "614/614 [==============================] - 0s 210us/step - loss: 0.5767 - acc: 0.7199 - val_loss: 0.6985 - val_acc: 0.5844\n",
      "Epoch 23/150\n",
      "614/614 [==============================] - 0s 200us/step - loss: 0.5762 - acc: 0.7199 - val_loss: 0.6442 - val_acc: 0.6883\n",
      "Epoch 24/150\n",
      "614/614 [==============================] - 0s 194us/step - loss: 0.5833 - acc: 0.7036 - val_loss: 0.6475 - val_acc: 0.6494\n",
      "Epoch 25/150\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.5780 - acc: 0.7215 - val_loss: 0.6666 - val_acc: 0.5844\n",
      "Epoch 26/150\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.5959 - acc: 0.6954 - val_loss: 0.6290 - val_acc: 0.6948\n",
      "Epoch 27/150\n",
      "614/614 [==============================] - 0s 251us/step - loss: 0.5941 - acc: 0.7003 - val_loss: 0.6440 - val_acc: 0.6818\n",
      "Epoch 28/150\n",
      "614/614 [==============================] - 0s 262us/step - loss: 0.5740 - acc: 0.7085 - val_loss: 0.6360 - val_acc: 0.6688\n",
      "Epoch 29/150\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.5712 - acc: 0.7215 - val_loss: 0.6177 - val_acc: 0.6753\n",
      "Epoch 30/150\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.5518 - acc: 0.7378 - val_loss: 0.7064 - val_acc: 0.6169\n",
      "Epoch 31/150\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.5612 - acc: 0.7280 - val_loss: 0.6160 - val_acc: 0.6558\n",
      "Epoch 32/150\n",
      "614/614 [==============================] - 0s 292us/step - loss: 0.5576 - acc: 0.7231 - val_loss: 0.6122 - val_acc: 0.6883\n",
      "Epoch 33/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.5581 - acc: 0.7264 - val_loss: 0.6048 - val_acc: 0.6883\n",
      "Epoch 34/150\n",
      "614/614 [==============================] - 0s 262us/step - loss: 0.5473 - acc: 0.7345 - val_loss: 0.6509 - val_acc: 0.6623\n",
      "Epoch 35/150\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.5498 - acc: 0.7264 - val_loss: 0.6589 - val_acc: 0.6883\n",
      "Epoch 36/150\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.5716 - acc: 0.7101 - val_loss: 0.6037 - val_acc: 0.7143\n",
      "Epoch 37/150\n",
      "614/614 [==============================] - 0s 266us/step - loss: 0.5462 - acc: 0.7264 - val_loss: 0.5874 - val_acc: 0.6948\n",
      "Epoch 38/150\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.5479 - acc: 0.7378 - val_loss: 0.6349 - val_acc: 0.6883\n",
      "Epoch 39/150\n",
      "614/614 [==============================] - 0s 201us/step - loss: 0.5495 - acc: 0.7182 - val_loss: 0.5951 - val_acc: 0.7013\n",
      "Epoch 40/150\n",
      "614/614 [==============================] - 0s 189us/step - loss: 0.5414 - acc: 0.7296 - val_loss: 0.6072 - val_acc: 0.6753\n",
      "Epoch 41/150\n",
      "614/614 [==============================] - 0s 206us/step - loss: 0.5400 - acc: 0.7410 - val_loss: 0.5913 - val_acc: 0.7208\n",
      "Epoch 42/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.5355 - acc: 0.7362 - val_loss: 0.5981 - val_acc: 0.7078\n",
      "Epoch 43/150\n",
      "614/614 [==============================] - 0s 204us/step - loss: 0.5406 - acc: 0.7264 - val_loss: 0.5849 - val_acc: 0.7013\n",
      "Epoch 44/150\n",
      "614/614 [==============================] - 0s 201us/step - loss: 0.5431 - acc: 0.7231 - val_loss: 0.5889 - val_acc: 0.6883\n",
      "Epoch 45/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.5492 - acc: 0.7345 - val_loss: 0.5968 - val_acc: 0.7078\n",
      "Epoch 46/150\n",
      "614/614 [==============================] - 0s 170us/step - loss: 0.5614 - acc: 0.7150 - val_loss: 0.5771 - val_acc: 0.7273\n",
      "Epoch 47/150\n",
      "614/614 [==============================] - 0s 200us/step - loss: 0.5442 - acc: 0.7280 - val_loss: 0.6730 - val_acc: 0.6169\n",
      "Epoch 48/150\n",
      "614/614 [==============================] - 0s 178us/step - loss: 0.5369 - acc: 0.7410 - val_loss: 0.5842 - val_acc: 0.7403\n",
      "Epoch 49/150\n",
      "614/614 [==============================] - 0s 176us/step - loss: 0.5243 - acc: 0.7329 - val_loss: 0.5766 - val_acc: 0.7468\n",
      "Epoch 50/150\n",
      "614/614 [==============================] - 0s 183us/step - loss: 0.5433 - acc: 0.7329 - val_loss: 0.5839 - val_acc: 0.7273\n",
      "Epoch 51/150\n",
      "614/614 [==============================] - 0s 189us/step - loss: 0.5215 - acc: 0.7296 - val_loss: 0.6629 - val_acc: 0.6948\n",
      "Epoch 52/150\n",
      "614/614 [==============================] - 0s 187us/step - loss: 0.5202 - acc: 0.7443 - val_loss: 0.5994 - val_acc: 0.7143\n",
      "Epoch 53/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.5297 - acc: 0.7280 - val_loss: 0.5606 - val_acc: 0.7338\n",
      "Epoch 54/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.5176 - acc: 0.7427 - val_loss: 0.5778 - val_acc: 0.7078\n",
      "Epoch 55/150\n",
      "614/614 [==============================] - 0s 152us/step - loss: 0.5178 - acc: 0.7443 - val_loss: 0.5511 - val_acc: 0.7208\n",
      "Epoch 56/150\n",
      "614/614 [==============================] - 0s 257us/step - loss: 0.5230 - acc: 0.7410 - val_loss: 0.5805 - val_acc: 0.7078\n",
      "Epoch 57/150\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.5443 - acc: 0.7182 - val_loss: 0.6023 - val_acc: 0.6494\n",
      "Epoch 58/150\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.5316 - acc: 0.7280 - val_loss: 0.5528 - val_acc: 0.7532\n",
      "Epoch 59/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.5226 - acc: 0.7378 - val_loss: 0.5666 - val_acc: 0.7273\n",
      "Epoch 60/150\n",
      "614/614 [==============================] - 0s 190us/step - loss: 0.5176 - acc: 0.7410 - val_loss: 0.5464 - val_acc: 0.7662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.5151 - acc: 0.7573 - val_loss: 0.5612 - val_acc: 0.7273\n",
      "Epoch 62/150\n",
      "614/614 [==============================] - 0s 166us/step - loss: 0.5075 - acc: 0.7427 - val_loss: 0.5566 - val_acc: 0.7273\n",
      "Epoch 63/150\n",
      "614/614 [==============================] - 0s 157us/step - loss: 0.5026 - acc: 0.7541 - val_loss: 0.5670 - val_acc: 0.7143\n",
      "Epoch 64/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.5274 - acc: 0.7459 - val_loss: 0.5729 - val_acc: 0.7208\n",
      "Epoch 65/150\n",
      "614/614 [==============================] - 0s 199us/step - loss: 0.5011 - acc: 0.7606 - val_loss: 0.5568 - val_acc: 0.7532\n",
      "Epoch 66/150\n",
      "614/614 [==============================] - 0s 175us/step - loss: 0.5182 - acc: 0.7427 - val_loss: 0.6050 - val_acc: 0.7078\n",
      "Epoch 67/150\n",
      "614/614 [==============================] - 0s 153us/step - loss: 0.5107 - acc: 0.7345 - val_loss: 0.5606 - val_acc: 0.7143\n",
      "Epoch 68/150\n",
      "614/614 [==============================] - 0s 169us/step - loss: 0.5248 - acc: 0.7280 - val_loss: 0.6236 - val_acc: 0.6753\n",
      "Epoch 69/150\n",
      "614/614 [==============================] - 0s 154us/step - loss: 0.5182 - acc: 0.7410 - val_loss: 0.5452 - val_acc: 0.7597\n",
      "Epoch 70/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.5135 - acc: 0.7410 - val_loss: 0.5589 - val_acc: 0.7403\n",
      "Epoch 71/150\n",
      "614/614 [==============================] - 0s 201us/step - loss: 0.5164 - acc: 0.7541 - val_loss: 0.5644 - val_acc: 0.7208\n",
      "Epoch 72/150\n",
      "614/614 [==============================] - 0s 192us/step - loss: 0.5149 - acc: 0.7573 - val_loss: 0.6008 - val_acc: 0.7013\n",
      "Epoch 73/150\n",
      "614/614 [==============================] - 0s 212us/step - loss: 0.5245 - acc: 0.7459 - val_loss: 0.5501 - val_acc: 0.7338\n",
      "Epoch 74/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4983 - acc: 0.7329 - val_loss: 0.5613 - val_acc: 0.7403\n",
      "Epoch 75/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.5104 - acc: 0.7476 - val_loss: 0.5589 - val_acc: 0.7338\n",
      "Epoch 76/150\n",
      "614/614 [==============================] - 0s 170us/step - loss: 0.5049 - acc: 0.7459 - val_loss: 0.5514 - val_acc: 0.7468\n",
      "Epoch 77/150\n",
      "614/614 [==============================] - 0s 166us/step - loss: 0.5014 - acc: 0.7459 - val_loss: 0.5609 - val_acc: 0.7273\n",
      "Epoch 78/150\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.4957 - acc: 0.7590 - val_loss: 0.5366 - val_acc: 0.7532\n",
      "Epoch 79/150\n",
      "614/614 [==============================] - 0s 147us/step - loss: 0.5150 - acc: 0.7410 - val_loss: 0.5481 - val_acc: 0.7273\n",
      "Epoch 80/150\n",
      "614/614 [==============================] - 0s 196us/step - loss: 0.5103 - acc: 0.7345 - val_loss: 0.5937 - val_acc: 0.7143\n",
      "Epoch 81/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.5113 - acc: 0.7410 - val_loss: 0.5654 - val_acc: 0.7273\n",
      "Epoch 82/150\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.5056 - acc: 0.7541 - val_loss: 0.6358 - val_acc: 0.6688\n",
      "Epoch 83/150\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.5058 - acc: 0.7443 - val_loss: 0.5612 - val_acc: 0.7143\n",
      "Epoch 84/150\n",
      "614/614 [==============================] - 0s 178us/step - loss: 0.4963 - acc: 0.7476 - val_loss: 0.5493 - val_acc: 0.7143\n",
      "Epoch 85/150\n",
      "614/614 [==============================] - 0s 270us/step - loss: 0.5137 - acc: 0.7362 - val_loss: 0.6171 - val_acc: 0.6688\n",
      "Epoch 86/150\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.4999 - acc: 0.7704 - val_loss: 0.5525 - val_acc: 0.7403\n",
      "Epoch 87/150\n",
      "614/614 [==============================] - 0s 529us/step - loss: 0.4910 - acc: 0.7590 - val_loss: 0.5723 - val_acc: 0.7078\n",
      "Epoch 88/150\n",
      "614/614 [==============================] - 0s 299us/step - loss: 0.5014 - acc: 0.7590 - val_loss: 0.5464 - val_acc: 0.7208\n",
      "Epoch 89/150\n",
      "614/614 [==============================] - 0s 277us/step - loss: 0.5001 - acc: 0.7508 - val_loss: 0.5913 - val_acc: 0.6948\n",
      "Epoch 90/150\n",
      "614/614 [==============================] - 0s 184us/step - loss: 0.5079 - acc: 0.7590 - val_loss: 0.5386 - val_acc: 0.7468\n",
      "Epoch 91/150\n",
      "614/614 [==============================] - 0s 272us/step - loss: 0.4929 - acc: 0.7687 - val_loss: 0.5376 - val_acc: 0.7403\n",
      "Epoch 92/150\n",
      "614/614 [==============================] - 0s 322us/step - loss: 0.4944 - acc: 0.7508 - val_loss: 0.5375 - val_acc: 0.7468\n",
      "Epoch 93/150\n",
      "614/614 [==============================] - 0s 200us/step - loss: 0.4979 - acc: 0.7492 - val_loss: 0.5577 - val_acc: 0.7208\n",
      "Epoch 94/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.5046 - acc: 0.7769 - val_loss: 0.5852 - val_acc: 0.7143\n",
      "Epoch 95/150\n",
      "614/614 [==============================] - 0s 324us/step - loss: 0.5240 - acc: 0.7508 - val_loss: 0.6105 - val_acc: 0.7078\n",
      "Epoch 96/150\n",
      "614/614 [==============================] - 0s 295us/step - loss: 0.4967 - acc: 0.7427 - val_loss: 0.5985 - val_acc: 0.6818\n",
      "Epoch 97/150\n",
      "614/614 [==============================] - 0s 320us/step - loss: 0.5095 - acc: 0.7394 - val_loss: 0.5320 - val_acc: 0.7468\n",
      "Epoch 98/150\n",
      "614/614 [==============================] - 0s 305us/step - loss: 0.4939 - acc: 0.7671 - val_loss: 0.6177 - val_acc: 0.6948\n",
      "Epoch 99/150\n",
      "614/614 [==============================] - 0s 286us/step - loss: 0.5079 - acc: 0.7443 - val_loss: 0.5996 - val_acc: 0.6818\n",
      "Epoch 100/150\n",
      "614/614 [==============================] - 0s 183us/step - loss: 0.5044 - acc: 0.7541 - val_loss: 0.5616 - val_acc: 0.7597\n",
      "Epoch 101/150\n",
      "614/614 [==============================] - 0s 177us/step - loss: 0.5163 - acc: 0.7394 - val_loss: 0.5665 - val_acc: 0.7078\n",
      "Epoch 102/150\n",
      "614/614 [==============================] - 0s 175us/step - loss: 0.4974 - acc: 0.7671 - val_loss: 0.5513 - val_acc: 0.7208\n",
      "Epoch 103/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.4794 - acc: 0.7638 - val_loss: 0.5297 - val_acc: 0.7338\n",
      "Epoch 104/150\n",
      "614/614 [==============================] - 0s 182us/step - loss: 0.4900 - acc: 0.7687 - val_loss: 0.5575 - val_acc: 0.7273\n",
      "Epoch 105/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.4913 - acc: 0.7541 - val_loss: 0.5486 - val_acc: 0.7273\n",
      "Epoch 106/150\n",
      "614/614 [==============================] - 0s 191us/step - loss: 0.4840 - acc: 0.7752 - val_loss: 0.5349 - val_acc: 0.7792\n",
      "Epoch 107/150\n",
      "614/614 [==============================] - 0s 181us/step - loss: 0.4929 - acc: 0.7573 - val_loss: 0.5625 - val_acc: 0.7013\n",
      "Epoch 108/150\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.4852 - acc: 0.7655 - val_loss: 0.5341 - val_acc: 0.7273\n",
      "Epoch 109/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4861 - acc: 0.7671 - val_loss: 0.5295 - val_acc: 0.7662\n",
      "Epoch 110/150\n",
      "614/614 [==============================] - 0s 168us/step - loss: 0.5071 - acc: 0.7492 - val_loss: 0.5297 - val_acc: 0.7792\n",
      "Epoch 111/150\n",
      "614/614 [==============================] - 0s 262us/step - loss: 0.4924 - acc: 0.7573 - val_loss: 0.5618 - val_acc: 0.7662\n",
      "Epoch 112/150\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.5050 - acc: 0.7557 - val_loss: 0.5418 - val_acc: 0.7273\n",
      "Epoch 113/150\n",
      "614/614 [==============================] - 0s 195us/step - loss: 0.4831 - acc: 0.7785 - val_loss: 0.5575 - val_acc: 0.7662\n",
      "Epoch 114/150\n",
      "614/614 [==============================] - 0s 378us/step - loss: 0.5116 - acc: 0.7606 - val_loss: 0.5933 - val_acc: 0.7338\n",
      "Epoch 115/150\n",
      "614/614 [==============================] - 0s 409us/step - loss: 0.4977 - acc: 0.7638 - val_loss: 0.5463 - val_acc: 0.7597\n",
      "Epoch 116/150\n",
      "614/614 [==============================] - 0s 199us/step - loss: 0.4919 - acc: 0.7736 - val_loss: 0.5474 - val_acc: 0.7273\n",
      "Epoch 117/150\n",
      "614/614 [==============================] - 0s 183us/step - loss: 0.4830 - acc: 0.7704 - val_loss: 0.6219 - val_acc: 0.6948\n",
      "Epoch 118/150\n",
      "614/614 [==============================] - 0s 209us/step - loss: 0.4817 - acc: 0.7736 - val_loss: 0.5432 - val_acc: 0.7208\n",
      "Epoch 119/150\n",
      "614/614 [==============================] - 0s 192us/step - loss: 0.4834 - acc: 0.7769 - val_loss: 0.5524 - val_acc: 0.6948\n",
      "Epoch 120/150\n",
      "614/614 [==============================] - 0s 209us/step - loss: 0.4741 - acc: 0.7752 - val_loss: 0.5445 - val_acc: 0.7143\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 179us/step - loss: 0.4781 - acc: 0.7752 - val_loss: 0.5404 - val_acc: 0.7273\n",
      "Epoch 122/150\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.4794 - acc: 0.775 - 0s 193us/step - loss: 0.4754 - acc: 0.7769 - val_loss: 0.6043 - val_acc: 0.6818\n",
      "Epoch 123/150\n",
      "614/614 [==============================] - 0s 171us/step - loss: 0.4740 - acc: 0.7752 - val_loss: 0.5416 - val_acc: 0.7792\n",
      "Epoch 124/150\n",
      "614/614 [==============================] - 0s 175us/step - loss: 0.4782 - acc: 0.7785 - val_loss: 0.5384 - val_acc: 0.7338\n",
      "Epoch 125/150\n",
      "614/614 [==============================] - 0s 181us/step - loss: 0.4727 - acc: 0.7866 - val_loss: 0.5440 - val_acc: 0.7597\n",
      "Epoch 126/150\n",
      "614/614 [==============================] - 0s 347us/step - loss: 0.4828 - acc: 0.7573 - val_loss: 0.5480 - val_acc: 0.7403\n",
      "Epoch 127/150\n",
      "614/614 [==============================] - 0s 431us/step - loss: 0.4748 - acc: 0.7720 - val_loss: 0.5385 - val_acc: 0.7403\n",
      "Epoch 128/150\n",
      "614/614 [==============================] - 0s 283us/step - loss: 0.4763 - acc: 0.7704 - val_loss: 0.5419 - val_acc: 0.7078\n",
      "Epoch 129/150\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.4919 - acc: 0.7752 - val_loss: 0.5270 - val_acc: 0.7597\n",
      "Epoch 130/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.4889 - acc: 0.7557 - val_loss: 0.5794 - val_acc: 0.7013\n",
      "Epoch 131/150\n",
      "614/614 [==============================] - 0s 204us/step - loss: 0.4722 - acc: 0.7964 - val_loss: 0.5536 - val_acc: 0.7597\n",
      "Epoch 132/150\n",
      "614/614 [==============================] - 0s 204us/step - loss: 0.4841 - acc: 0.7606 - val_loss: 0.5566 - val_acc: 0.7338\n",
      "Epoch 133/150\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.4791 - acc: 0.7720 - val_loss: 0.5915 - val_acc: 0.7013\n",
      "Epoch 134/150\n",
      "614/614 [==============================] - 0s 183us/step - loss: 0.4854 - acc: 0.7704 - val_loss: 0.5387 - val_acc: 0.7468\n",
      "Epoch 135/150\n",
      "614/614 [==============================] - 0s 184us/step - loss: 0.4954 - acc: 0.7606 - val_loss: 0.5906 - val_acc: 0.7403\n",
      "Epoch 136/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.4805 - acc: 0.7557 - val_loss: 0.5175 - val_acc: 0.7468\n",
      "Epoch 137/150\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.4740 - acc: 0.7752 - val_loss: 0.5231 - val_acc: 0.7727\n",
      "Epoch 138/150\n",
      "614/614 [==============================] - 0s 185us/step - loss: 0.4707 - acc: 0.7752 - val_loss: 0.5344 - val_acc: 0.7338\n",
      "Epoch 139/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.4717 - acc: 0.7769 - val_loss: 0.5542 - val_acc: 0.7662\n",
      "Epoch 140/150\n",
      "614/614 [==============================] - 0s 268us/step - loss: 0.4789 - acc: 0.7590 - val_loss: 0.5473 - val_acc: 0.7792\n",
      "Epoch 141/150\n",
      "614/614 [==============================] - 0s 189us/step - loss: 0.4749 - acc: 0.7769 - val_loss: 0.5651 - val_acc: 0.7208\n",
      "Epoch 142/150\n",
      "614/614 [==============================] - 0s 204us/step - loss: 0.4734 - acc: 0.7769 - val_loss: 0.5638 - val_acc: 0.7273\n",
      "Epoch 143/150\n",
      "614/614 [==============================] - 0s 187us/step - loss: 0.4724 - acc: 0.7606 - val_loss: 0.5366 - val_acc: 0.7922\n",
      "Epoch 144/150\n",
      "614/614 [==============================] - 0s 186us/step - loss: 0.4826 - acc: 0.7622 - val_loss: 0.5217 - val_acc: 0.7403\n",
      "Epoch 145/150\n",
      "614/614 [==============================] - 0s 180us/step - loss: 0.4780 - acc: 0.7704 - val_loss: 0.5384 - val_acc: 0.7338\n",
      "Epoch 146/150\n",
      "614/614 [==============================] - 0s 204us/step - loss: 0.4612 - acc: 0.7948 - val_loss: 0.5851 - val_acc: 0.7208\n",
      "Epoch 147/150\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.4678 - acc: 0.7801 - val_loss: 0.5434 - val_acc: 0.7922\n",
      "Epoch 148/150\n",
      "614/614 [==============================] - 0s 262us/step - loss: 0.4691 - acc: 0.7736 - val_loss: 0.5167 - val_acc: 0.7338\n",
      "Epoch 149/150\n",
      "614/614 [==============================] - 0s 206us/step - loss: 0.4786 - acc: 0.7818 - val_loss: 0.5873 - val_acc: 0.7338\n",
      "Epoch 150/150\n",
      "614/614 [==============================] - 0s 189us/step - loss: 0.4657 - acc: 0.7769 - val_loss: 0.5411 - val_acc: 0.7403\n",
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/150\n",
      "614/614 [==============================] - 0s 182us/step - loss: 0.5004 - acc: 0.7590 - val_loss: 0.4548 - val_acc: 0.8506\n",
      "Epoch 2/150\n",
      "614/614 [==============================] - 0s 207us/step - loss: 0.4894 - acc: 0.7638 - val_loss: 0.4620 - val_acc: 0.8312\n",
      "Epoch 3/150\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.4882 - acc: 0.7622 - val_loss: 0.4582 - val_acc: 0.8506\n",
      "Epoch 4/150\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.5065 - acc: 0.7492 - val_loss: 0.4896 - val_acc: 0.7792\n",
      "Epoch 5/150\n",
      "614/614 [==============================] - 0s 261us/step - loss: 0.4830 - acc: 0.7638 - val_loss: 0.4599 - val_acc: 0.8312\n",
      "Epoch 6/150\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.4842 - acc: 0.7638 - val_loss: 0.4905 - val_acc: 0.7792\n",
      "Epoch 7/150\n",
      "614/614 [==============================] - 0s 196us/step - loss: 0.4880 - acc: 0.7752 - val_loss: 0.4820 - val_acc: 0.7922\n",
      "Epoch 8/150\n",
      "614/614 [==============================] - 0s 210us/step - loss: 0.4794 - acc: 0.7769 - val_loss: 0.4866 - val_acc: 0.7727\n",
      "Epoch 9/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.4968 - acc: 0.7524 - val_loss: 0.5936 - val_acc: 0.7597\n",
      "Epoch 10/150\n",
      "614/614 [==============================] - 0s 180us/step - loss: 0.4963 - acc: 0.7459 - val_loss: 0.4608 - val_acc: 0.8247\n",
      "Epoch 11/150\n",
      "614/614 [==============================] - 0s 166us/step - loss: 0.4780 - acc: 0.7687 - val_loss: 0.4697 - val_acc: 0.8312\n",
      "Epoch 12/150\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.4719 - acc: 0.7818 - val_loss: 0.4796 - val_acc: 0.8117\n",
      "Epoch 13/150\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.4926 - acc: 0.7622 - val_loss: 0.4893 - val_acc: 0.7792\n",
      "Epoch 14/150\n",
      "614/614 [==============================] - 0s 195us/step - loss: 0.4883 - acc: 0.7524 - val_loss: 0.4790 - val_acc: 0.8117\n",
      "Epoch 15/150\n",
      "614/614 [==============================] - 0s 180us/step - loss: 0.4753 - acc: 0.7752 - val_loss: 0.4793 - val_acc: 0.8247\n",
      "Epoch 16/150\n",
      "614/614 [==============================] - 0s 170us/step - loss: 0.4764 - acc: 0.7687 - val_loss: 0.4556 - val_acc: 0.8377\n",
      "Epoch 17/150\n",
      "614/614 [==============================] - 0s 196us/step - loss: 0.4975 - acc: 0.7378 - val_loss: 0.4841 - val_acc: 0.8247\n",
      "Epoch 18/150\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.4942 - acc: 0.7443 - val_loss: 0.4630 - val_acc: 0.8571\n",
      "Epoch 19/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.4733 - acc: 0.7720 - val_loss: 0.5195 - val_acc: 0.7403\n",
      "Epoch 20/150\n",
      "614/614 [==============================] - 0s 178us/step - loss: 0.4823 - acc: 0.7492 - val_loss: 0.4907 - val_acc: 0.8312\n",
      "Epoch 21/150\n",
      "614/614 [==============================] - 0s 184us/step - loss: 0.4830 - acc: 0.7752 - val_loss: 0.4816 - val_acc: 0.8312\n",
      "Epoch 22/150\n",
      "614/614 [==============================] - 0s 166us/step - loss: 0.4895 - acc: 0.7704 - val_loss: 0.4704 - val_acc: 0.8377\n",
      "Epoch 23/150\n",
      "614/614 [==============================] - 0s 168us/step - loss: 0.4840 - acc: 0.7687 - val_loss: 0.4910 - val_acc: 0.7987\n",
      "Epoch 24/150\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.4901 - acc: 0.7606 - val_loss: 0.4888 - val_acc: 0.7922\n",
      "Epoch 25/150\n",
      "614/614 [==============================] - 0s 180us/step - loss: 0.4826 - acc: 0.7638 - val_loss: 0.5033 - val_acc: 0.7987\n",
      "Epoch 26/150\n",
      "614/614 [==============================] - 0s 184us/step - loss: 0.4923 - acc: 0.7508 - val_loss: 0.4772 - val_acc: 0.8247\n",
      "Epoch 27/150\n",
      "614/614 [==============================] - 0s 183us/step - loss: 0.4813 - acc: 0.7769 - val_loss: 0.4860 - val_acc: 0.7857\n",
      "Epoch 28/150\n",
      "614/614 [==============================] - 0s 178us/step - loss: 0.4756 - acc: 0.7687 - val_loss: 0.4840 - val_acc: 0.8117\n",
      "Epoch 29/150\n",
      "614/614 [==============================] - 0s 182us/step - loss: 0.4818 - acc: 0.7720 - val_loss: 0.4860 - val_acc: 0.8182\n",
      "Epoch 30/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 182us/step - loss: 0.4698 - acc: 0.7801 - val_loss: 0.4902 - val_acc: 0.7922\n",
      "Epoch 31/150\n",
      "614/614 [==============================] - 0s 173us/step - loss: 0.4788 - acc: 0.7834 - val_loss: 0.4820 - val_acc: 0.8182\n",
      "Epoch 32/150\n",
      "614/614 [==============================] - 0s 177us/step - loss: 0.4720 - acc: 0.7736 - val_loss: 0.4987 - val_acc: 0.7792\n",
      "Epoch 33/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.4796 - acc: 0.7687 - val_loss: 0.4723 - val_acc: 0.7922\n",
      "Epoch 34/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4735 - acc: 0.7671 - val_loss: 0.5652 - val_acc: 0.7078\n",
      "Epoch 35/150\n",
      "614/614 [==============================] - 0s 169us/step - loss: 0.4842 - acc: 0.7671 - val_loss: 0.5017 - val_acc: 0.7922\n",
      "Epoch 36/150\n",
      "614/614 [==============================] - 0s 170us/step - loss: 0.4773 - acc: 0.7638 - val_loss: 0.4974 - val_acc: 0.7792\n",
      "Epoch 37/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.4580 - acc: 0.7769 - val_loss: 0.4855 - val_acc: 0.8182\n",
      "Epoch 38/150\n",
      "614/614 [==============================] - 0s 176us/step - loss: 0.4767 - acc: 0.7606 - val_loss: 0.4673 - val_acc: 0.8117\n",
      "Epoch 39/150\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.4746 - acc: 0.7655 - val_loss: 0.4764 - val_acc: 0.8182\n",
      "Epoch 40/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4546 - acc: 0.7801 - val_loss: 0.4767 - val_acc: 0.8052\n",
      "Epoch 41/150\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.4637 - acc: 0.7752 - val_loss: 0.4866 - val_acc: 0.8377\n",
      "Epoch 42/150\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.4694 - acc: 0.7638 - val_loss: 0.4935 - val_acc: 0.7857\n",
      "Epoch 43/150\n",
      "614/614 [==============================] - 0s 209us/step - loss: 0.4877 - acc: 0.7606 - val_loss: 0.4873 - val_acc: 0.8182\n",
      "Epoch 44/150\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.4765 - acc: 0.7557 - val_loss: 0.4808 - val_acc: 0.7922\n",
      "Epoch 45/150\n",
      "614/614 [==============================] - 0s 212us/step - loss: 0.4617 - acc: 0.7720 - val_loss: 0.5038 - val_acc: 0.7532\n",
      "Epoch 46/150\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.4664 - acc: 0.7638 - val_loss: 0.4778 - val_acc: 0.8247\n",
      "Epoch 47/150\n",
      "614/614 [==============================] - 0s 193us/step - loss: 0.4625 - acc: 0.7720 - val_loss: 0.4896 - val_acc: 0.7792\n",
      "Epoch 48/150\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.4624 - acc: 0.7736 - val_loss: 0.4761 - val_acc: 0.8247\n",
      "Epoch 49/150\n",
      "614/614 [==============================] - 0s 202us/step - loss: 0.4832 - acc: 0.7704 - val_loss: 0.5095 - val_acc: 0.7792\n",
      "Epoch 50/150\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.4668 - acc: 0.7752 - val_loss: 0.4791 - val_acc: 0.8442\n",
      "Epoch 51/150\n",
      "614/614 [==============================] - 0s 195us/step - loss: 0.4603 - acc: 0.7785 - val_loss: 0.4830 - val_acc: 0.7857\n",
      "Epoch 52/150\n",
      "614/614 [==============================] - 0s 330us/step - loss: 0.4585 - acc: 0.7818 - val_loss: 0.4911 - val_acc: 0.8052\n",
      "Epoch 53/150\n",
      "614/614 [==============================] - 0s 183us/step - loss: 0.4687 - acc: 0.7655 - val_loss: 0.4724 - val_acc: 0.8312\n",
      "Epoch 54/150\n",
      "614/614 [==============================] - 0s 167us/step - loss: 0.4656 - acc: 0.7801 - val_loss: 0.4972 - val_acc: 0.7597\n",
      "Epoch 55/150\n",
      "614/614 [==============================] - 0s 170us/step - loss: 0.4679 - acc: 0.7769 - val_loss: 0.4917 - val_acc: 0.8052\n",
      "Epoch 56/150\n",
      "614/614 [==============================] - 0s 183us/step - loss: 0.4691 - acc: 0.7655 - val_loss: 0.4836 - val_acc: 0.8117\n",
      "Epoch 57/150\n",
      "614/614 [==============================] - 0s 186us/step - loss: 0.4644 - acc: 0.7687 - val_loss: 0.5143 - val_acc: 0.7857\n",
      "Epoch 58/150\n",
      "614/614 [==============================] - 0s 260us/step - loss: 0.4669 - acc: 0.7720 - val_loss: 0.4894 - val_acc: 0.8377\n",
      "Epoch 59/150\n",
      "614/614 [==============================] - 0s 203us/step - loss: 0.4522 - acc: 0.7818 - val_loss: 0.4836 - val_acc: 0.8377\n",
      "Epoch 60/150\n",
      "614/614 [==============================] - 0s 184us/step - loss: 0.4761 - acc: 0.7769 - val_loss: 0.4637 - val_acc: 0.8377\n",
      "Epoch 61/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.4556 - acc: 0.7752 - val_loss: 0.4718 - val_acc: 0.8506\n",
      "Epoch 62/150\n",
      "614/614 [==============================] - 0s 167us/step - loss: 0.4715 - acc: 0.7785 - val_loss: 0.4772 - val_acc: 0.8182\n",
      "Epoch 63/150\n",
      "614/614 [==============================] - 0s 205us/step - loss: 0.4629 - acc: 0.7720 - val_loss: 0.4774 - val_acc: 0.8506\n",
      "Epoch 64/150\n",
      "614/614 [==============================] - 0s 183us/step - loss: 0.4632 - acc: 0.7752 - val_loss: 0.4840 - val_acc: 0.8182\n",
      "Epoch 65/150\n",
      "614/614 [==============================] - 0s 170us/step - loss: 0.4693 - acc: 0.7492 - val_loss: 0.4760 - val_acc: 0.8312\n",
      "Epoch 66/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.4558 - acc: 0.7704 - val_loss: 0.4805 - val_acc: 0.7727\n",
      "Epoch 67/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.4637 - acc: 0.7704 - val_loss: 0.4701 - val_acc: 0.8247\n",
      "Epoch 68/150\n",
      "614/614 [==============================] - 0s 177us/step - loss: 0.4689 - acc: 0.7752 - val_loss: 0.4805 - val_acc: 0.8182\n",
      "Epoch 69/150\n",
      "614/614 [==============================] - 0s 173us/step - loss: 0.4606 - acc: 0.7671 - val_loss: 0.4863 - val_acc: 0.7792\n",
      "Epoch 70/150\n",
      "614/614 [==============================] - 0s 195us/step - loss: 0.4695 - acc: 0.7671 - val_loss: 0.4957 - val_acc: 0.8182\n",
      "Epoch 71/150\n",
      "614/614 [==============================] - 0s 187us/step - loss: 0.4797 - acc: 0.7704 - val_loss: 0.4831 - val_acc: 0.7922\n",
      "Epoch 72/150\n",
      "614/614 [==============================] - 0s 190us/step - loss: 0.4577 - acc: 0.7704 - val_loss: 0.4765 - val_acc: 0.7987\n",
      "Epoch 73/150\n",
      "614/614 [==============================] - 0s 186us/step - loss: 0.4640 - acc: 0.7769 - val_loss: 0.4914 - val_acc: 0.8247\n",
      "Epoch 74/150\n",
      "614/614 [==============================] - 0s 173us/step - loss: 0.4486 - acc: 0.7752 - val_loss: 0.4874 - val_acc: 0.8312\n",
      "Epoch 75/150\n",
      "614/614 [==============================] - 0s 178us/step - loss: 0.4663 - acc: 0.7687 - val_loss: 0.4906 - val_acc: 0.8312\n",
      "Epoch 76/150\n",
      "614/614 [==============================] - 0s 197us/step - loss: 0.4649 - acc: 0.7671 - val_loss: 0.4880 - val_acc: 0.8182\n",
      "Epoch 77/150\n",
      "614/614 [==============================] - 0s 188us/step - loss: 0.4654 - acc: 0.7736 - val_loss: 0.4780 - val_acc: 0.8312\n",
      "Epoch 78/150\n",
      "614/614 [==============================] - 0s 177us/step - loss: 0.4775 - acc: 0.7671 - val_loss: 0.4721 - val_acc: 0.8312\n",
      "Epoch 79/150\n",
      "614/614 [==============================] - 0s 186us/step - loss: 0.4543 - acc: 0.7964 - val_loss: 0.5760 - val_acc: 0.7208\n",
      "Epoch 80/150\n",
      "614/614 [==============================] - 0s 175us/step - loss: 0.4763 - acc: 0.7524 - val_loss: 0.4909 - val_acc: 0.7727\n",
      "Epoch 81/150\n",
      "614/614 [==============================] - 0s 190us/step - loss: 0.4682 - acc: 0.7752 - val_loss: 0.5375 - val_acc: 0.7208\n",
      "Epoch 82/150\n",
      "614/614 [==============================] - 0s 173us/step - loss: 0.4720 - acc: 0.7541 - val_loss: 0.6223 - val_acc: 0.6948\n",
      "Epoch 83/150\n",
      "614/614 [==============================] - 0s 171us/step - loss: 0.4548 - acc: 0.7638 - val_loss: 0.4715 - val_acc: 0.8377\n",
      "Epoch 84/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.4597 - acc: 0.7850 - val_loss: 0.4774 - val_acc: 0.7792\n",
      "Epoch 85/150\n",
      "614/614 [==============================] - 0s 168us/step - loss: 0.4638 - acc: 0.7704 - val_loss: 0.4866 - val_acc: 0.8117\n",
      "Epoch 86/150\n",
      "614/614 [==============================] - 0s 175us/step - loss: 0.4545 - acc: 0.7834 - val_loss: 0.4995 - val_acc: 0.7727\n",
      "Epoch 87/150\n",
      "614/614 [==============================] - 0s 172us/step - loss: 0.4591 - acc: 0.7850 - val_loss: 0.4836 - val_acc: 0.8117\n",
      "Epoch 88/150\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.4418 - acc: 0.7818 - val_loss: 0.4928 - val_acc: 0.8182\n",
      "Epoch 89/150\n",
      "614/614 [==============================] - 0s 175us/step - loss: 0.4560 - acc: 0.7687 - val_loss: 0.4886 - val_acc: 0.8117\n",
      "Epoch 90/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 218us/step - loss: 0.4483 - acc: 0.7801 - val_loss: 0.4943 - val_acc: 0.7922\n",
      "Epoch 91/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.4491 - acc: 0.7785 - val_loss: 0.5014 - val_acc: 0.7727\n",
      "Epoch 92/150\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.4512 - acc: 0.7850 - val_loss: 0.4939 - val_acc: 0.8247\n",
      "Epoch 93/150\n",
      "614/614 [==============================] - 0s 253us/step - loss: 0.4507 - acc: 0.7850 - val_loss: 0.5421 - val_acc: 0.7273\n",
      "Epoch 94/150\n",
      "614/614 [==============================] - 0s 204us/step - loss: 0.4656 - acc: 0.7818 - val_loss: 0.4768 - val_acc: 0.8247\n",
      "Epoch 95/150\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.4450 - acc: 0.7818 - val_loss: 0.5076 - val_acc: 0.7727\n",
      "Epoch 96/150\n",
      "614/614 [==============================] - 0s 209us/step - loss: 0.4522 - acc: 0.7834 - val_loss: 0.4783 - val_acc: 0.8052\n",
      "Epoch 97/150\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.4502 - acc: 0.7915 - val_loss: 0.4850 - val_acc: 0.8247\n",
      "Epoch 98/150\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.4514 - acc: 0.7801 - val_loss: 0.5021 - val_acc: 0.7792\n",
      "Epoch 99/150\n",
      "614/614 [==============================] - 0s 199us/step - loss: 0.4625 - acc: 0.7736 - val_loss: 0.5064 - val_acc: 0.7922\n",
      "Epoch 100/150\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.4503 - acc: 0.7915 - val_loss: 0.5770 - val_acc: 0.7143\n",
      "Epoch 101/150\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.4734 - acc: 0.7655 - val_loss: 0.5025 - val_acc: 0.7727\n",
      "Epoch 102/150\n",
      "614/614 [==============================] - 0s 258us/step - loss: 0.4509 - acc: 0.7801 - val_loss: 0.4913 - val_acc: 0.8117\n",
      "Epoch 103/150\n",
      "614/614 [==============================] - 0s 257us/step - loss: 0.4511 - acc: 0.7932 - val_loss: 0.5607 - val_acc: 0.7273\n",
      "Epoch 104/150\n",
      "614/614 [==============================] - 0s 253us/step - loss: 0.4576 - acc: 0.7736 - val_loss: 0.4911 - val_acc: 0.7922\n",
      "Epoch 105/150\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.4575 - acc: 0.7769 - val_loss: 0.4873 - val_acc: 0.8117\n",
      "Epoch 106/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.4507 - acc: 0.7736 - val_loss: 0.4923 - val_acc: 0.8247\n",
      "Epoch 107/150\n",
      "614/614 [==============================] - 0s 176us/step - loss: 0.4540 - acc: 0.7801 - val_loss: 0.5187 - val_acc: 0.8052\n",
      "Epoch 108/150\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.4545 - acc: 0.7752 - val_loss: 0.4844 - val_acc: 0.8247\n",
      "Epoch 109/150\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.4580 - acc: 0.7736 - val_loss: 0.4835 - val_acc: 0.8636\n",
      "Epoch 110/150\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.4657 - acc: 0.7752 - val_loss: 0.4868 - val_acc: 0.8442\n",
      "Epoch 111/150\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.4581 - acc: 0.7606 - val_loss: 0.4998 - val_acc: 0.7662\n",
      "Epoch 112/150\n",
      "614/614 [==============================] - 0s 255us/step - loss: 0.4468 - acc: 0.7818 - val_loss: 0.4932 - val_acc: 0.7727\n",
      "Epoch 113/150\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.4510 - acc: 0.7883 - val_loss: 0.4874 - val_acc: 0.8247\n",
      "Epoch 114/150\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.4548 - acc: 0.7834 - val_loss: 0.5197 - val_acc: 0.7597\n",
      "Epoch 115/150\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.4526 - acc: 0.7948 - val_loss: 0.4871 - val_acc: 0.8182\n",
      "Epoch 116/150\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.4435 - acc: 0.7850 - val_loss: 0.4959 - val_acc: 0.8312\n",
      "Epoch 117/150\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.4485 - acc: 0.7704 - val_loss: 0.5493 - val_acc: 0.7403\n",
      "Epoch 118/150\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.4513 - acc: 0.7785 - val_loss: 0.5274 - val_acc: 0.7987\n",
      "Epoch 119/150\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.4505 - acc: 0.7704 - val_loss: 0.5020 - val_acc: 0.7792\n",
      "Epoch 120/150\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.4484 - acc: 0.7704 - val_loss: 0.4840 - val_acc: 0.8117\n",
      "Epoch 121/150\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.4428 - acc: 0.7850 - val_loss: 0.4986 - val_acc: 0.8442\n",
      "Epoch 122/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.4497 - acc: 0.7801 - val_loss: 0.4987 - val_acc: 0.7792\n",
      "Epoch 123/150\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.4419 - acc: 0.8013 - val_loss: 0.5029 - val_acc: 0.8312\n",
      "Epoch 124/150\n",
      "614/614 [==============================] - 0s 191us/step - loss: 0.4572 - acc: 0.7687 - val_loss: 0.5277 - val_acc: 0.7468\n",
      "Epoch 125/150\n",
      "614/614 [==============================] - 0s 173us/step - loss: 0.4523 - acc: 0.7704 - val_loss: 0.5027 - val_acc: 0.8377\n",
      "Epoch 126/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4380 - acc: 0.8029 - val_loss: 0.5007 - val_acc: 0.7857\n",
      "Epoch 127/150\n",
      "614/614 [==============================] - 0s 199us/step - loss: 0.4583 - acc: 0.7850 - val_loss: 0.4967 - val_acc: 0.8377\n",
      "Epoch 128/150\n",
      "614/614 [==============================] - 0s 168us/step - loss: 0.4428 - acc: 0.8013 - val_loss: 0.5273 - val_acc: 0.7922\n",
      "Epoch 129/150\n",
      "614/614 [==============================] - 0s 191us/step - loss: 0.4433 - acc: 0.7801 - val_loss: 0.5059 - val_acc: 0.7792\n",
      "Epoch 130/150\n",
      "614/614 [==============================] - 0s 171us/step - loss: 0.4501 - acc: 0.7883 - val_loss: 0.5381 - val_acc: 0.7208\n",
      "Epoch 131/150\n",
      "614/614 [==============================] - 0s 184us/step - loss: 0.4502 - acc: 0.7850 - val_loss: 0.4971 - val_acc: 0.7922\n",
      "Epoch 132/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.4578 - acc: 0.7801 - val_loss: 0.5001 - val_acc: 0.8117\n",
      "Epoch 133/150\n",
      "614/614 [==============================] - 0s 177us/step - loss: 0.4648 - acc: 0.7785 - val_loss: 0.5260 - val_acc: 0.7597\n",
      "Epoch 134/150\n",
      "614/614 [==============================] - 0s 197us/step - loss: 0.4528 - acc: 0.7866 - val_loss: 0.4897 - val_acc: 0.8312\n",
      "Epoch 135/150\n",
      "614/614 [==============================] - 0s 178us/step - loss: 0.4375 - acc: 0.7899 - val_loss: 0.4978 - val_acc: 0.8312\n",
      "Epoch 136/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.4429 - acc: 0.7801 - val_loss: 0.5018 - val_acc: 0.7792\n",
      "Epoch 137/150\n",
      "614/614 [==============================] - 0s 183us/step - loss: 0.4456 - acc: 0.7899 - val_loss: 0.5282 - val_acc: 0.7857\n",
      "Epoch 138/150\n",
      "614/614 [==============================] - 0s 178us/step - loss: 0.4455 - acc: 0.7801 - val_loss: 0.5054 - val_acc: 0.8182\n",
      "Epoch 139/150\n",
      "614/614 [==============================] - 0s 193us/step - loss: 0.4403 - acc: 0.7850 - val_loss: 0.5107 - val_acc: 0.8182\n",
      "Epoch 140/150\n",
      "614/614 [==============================] - 0s 185us/step - loss: 0.4598 - acc: 0.8013 - val_loss: 0.5306 - val_acc: 0.8052\n",
      "Epoch 141/150\n",
      "614/614 [==============================] - 0s 167us/step - loss: 0.4457 - acc: 0.7736 - val_loss: 0.4976 - val_acc: 0.8377\n",
      "Epoch 142/150\n",
      "614/614 [==============================] - 0s 182us/step - loss: 0.4584 - acc: 0.7997 - val_loss: 0.4826 - val_acc: 0.7922\n",
      "Epoch 143/150\n",
      "614/614 [==============================] - 0s 188us/step - loss: 0.4560 - acc: 0.7638 - val_loss: 0.5008 - val_acc: 0.8377\n",
      "Epoch 144/150\n",
      "614/614 [==============================] - 0s 170us/step - loss: 0.4420 - acc: 0.7915 - val_loss: 0.5049 - val_acc: 0.7857\n",
      "Epoch 145/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.4436 - acc: 0.7769 - val_loss: 0.5049 - val_acc: 0.7857\n",
      "Epoch 146/150\n",
      "614/614 [==============================] - 0s 174us/step - loss: 0.4433 - acc: 0.7720 - val_loss: 0.5272 - val_acc: 0.8247\n",
      "Epoch 147/150\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.4523 - acc: 0.7736 - val_loss: 0.5244 - val_acc: 0.7662\n",
      "Epoch 148/150\n",
      "614/614 [==============================] - 0s 165us/step - loss: 0.4384 - acc: 0.7866 - val_loss: 0.5839 - val_acc: 0.7143\n",
      "Epoch 149/150\n",
      "614/614 [==============================] - 0s 172us/step - loss: 0.4403 - acc: 0.7752 - val_loss: 0.4919 - val_acc: 0.8247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/150\n",
      "614/614 [==============================] - 0s 183us/step - loss: 0.4643 - acc: 0.7785 - val_loss: 0.5296 - val_acc: 0.7727\n",
      "Epoch 1/150\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 4.7034 - acc: 0.4747\n",
      "Epoch 2/150\n",
      "691/691 [==============================] - 0s 151us/step - loss: 1.1734 - acc: 0.6252\n",
      "Epoch 3/150\n",
      "691/691 [==============================] - 0s 153us/step - loss: 0.9808 - acc: 0.6194\n",
      "Epoch 4/150\n",
      "691/691 [==============================] - 0s 131us/step - loss: 0.8653 - acc: 0.6310\n",
      "Epoch 5/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.7520 - acc: 0.6281\n",
      "Epoch 6/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 0.7191 - acc: 0.6382\n",
      "Epoch 7/150\n",
      "691/691 [==============================] - 0s 240us/step - loss: 0.6930 - acc: 0.6483\n",
      "Epoch 8/150\n",
      "691/691 [==============================] - 0s 245us/step - loss: 0.7004 - acc: 0.6527\n",
      "Epoch 9/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 0.6731 - acc: 0.6411\n",
      "Epoch 10/150\n",
      "691/691 [==============================] - 0s 255us/step - loss: 0.6693 - acc: 0.6498\n",
      "Epoch 11/150\n",
      "691/691 [==============================] - 0s 200us/step - loss: 0.6636 - acc: 0.6440\n",
      "Epoch 12/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.6489 - acc: 0.6628\n",
      "Epoch 13/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.6489 - acc: 0.6599\n",
      "Epoch 14/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.6372 - acc: 0.6700\n",
      "Epoch 15/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.6467 - acc: 0.6802\n",
      "Epoch 16/150\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.6312 - acc: 0.666 - 0s 251us/step - loss: 0.6303 - acc: 0.6671\n",
      "Epoch 17/150\n",
      "691/691 [==============================] - 0s 204us/step - loss: 0.6216 - acc: 0.6845\n",
      "Epoch 18/150\n",
      "691/691 [==============================] - 0s 183us/step - loss: 0.6270 - acc: 0.6715\n",
      "Epoch 19/150\n",
      "691/691 [==============================] - 0s 245us/step - loss: 0.6289 - acc: 0.6744\n",
      "Epoch 20/150\n",
      "691/691 [==============================] - 0s 211us/step - loss: 0.6201 - acc: 0.6758\n",
      "Epoch 21/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.6055 - acc: 0.6845\n",
      "Epoch 22/150\n",
      "691/691 [==============================] - 0s 154us/step - loss: 0.6050 - acc: 0.6874\n",
      "Epoch 23/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5966 - acc: 0.6874\n",
      "Epoch 24/150\n",
      "691/691 [==============================] - 0s 211us/step - loss: 0.6083 - acc: 0.6773\n",
      "Epoch 25/150\n",
      "691/691 [==============================] - 0s 217us/step - loss: 0.5953 - acc: 0.6729\n",
      "Epoch 26/150\n",
      "691/691 [==============================] - 0s 245us/step - loss: 0.5881 - acc: 0.6918\n",
      "Epoch 27/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.5946 - acc: 0.6787\n",
      "Epoch 28/150\n",
      "691/691 [==============================] - 0s 176us/step - loss: 0.5872 - acc: 0.6975\n",
      "Epoch 29/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.5898 - acc: 0.6932\n",
      "Epoch 30/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.5818 - acc: 0.6946\n",
      "Epoch 31/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5792 - acc: 0.7077\n",
      "Epoch 32/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 0.5821 - acc: 0.6831\n",
      "Epoch 33/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 0.5759 - acc: 0.6946\n",
      "Epoch 34/150\n",
      "691/691 [==============================] - 0s 226us/step - loss: 0.5762 - acc: 0.6903\n",
      "Epoch 35/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5826 - acc: 0.6758\n",
      "Epoch 36/150\n",
      "691/691 [==============================] - 0s 157us/step - loss: 0.5722 - acc: 0.6932\n",
      "Epoch 37/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.5700 - acc: 0.7091\n",
      "Epoch 38/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.5717 - acc: 0.7091\n",
      "Epoch 39/150\n",
      "691/691 [==============================] - 0s 156us/step - loss: 0.5853 - acc: 0.6729\n",
      "Epoch 40/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5702 - acc: 0.7077\n",
      "Epoch 41/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 0.5723 - acc: 0.7033\n",
      "Epoch 42/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.5641 - acc: 0.7149\n",
      "Epoch 43/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5616 - acc: 0.7149\n",
      "Epoch 44/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5588 - acc: 0.7106\n",
      "Epoch 45/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.5634 - acc: 0.7120\n",
      "Epoch 46/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5595 - acc: 0.7135\n",
      "Epoch 47/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5584 - acc: 0.7207\n",
      "Epoch 48/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.5619 - acc: 0.7062\n",
      "Epoch 49/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5530 - acc: 0.7106\n",
      "Epoch 50/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.5650 - acc: 0.7048\n",
      "Epoch 51/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5518 - acc: 0.7149\n",
      "Epoch 52/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.5486 - acc: 0.7265\n",
      "Epoch 53/150\n",
      "691/691 [==============================] - 0s 150us/step - loss: 0.5440 - acc: 0.7221\n",
      "Epoch 54/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5544 - acc: 0.7352\n",
      "Epoch 55/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5436 - acc: 0.7294\n",
      "Epoch 56/150\n",
      "691/691 [==============================] - 0s 149us/step - loss: 0.5453 - acc: 0.7236\n",
      "Epoch 57/150\n",
      "691/691 [==============================] - 0s 146us/step - loss: 0.5391 - acc: 0.7250\n",
      "Epoch 58/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.5510 - acc: 0.7192\n",
      "Epoch 59/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5374 - acc: 0.7221\n",
      "Epoch 60/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.5434 - acc: 0.7192\n",
      "Epoch 61/150\n",
      "691/691 [==============================] - 0s 149us/step - loss: 0.5361 - acc: 0.7279\n",
      "Epoch 62/150\n",
      "691/691 [==============================] - 0s 154us/step - loss: 0.5283 - acc: 0.7308\n",
      "Epoch 63/150\n",
      "691/691 [==============================] - 0s 157us/step - loss: 0.5329 - acc: 0.7294\n",
      "Epoch 64/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5280 - acc: 0.7308\n",
      "Epoch 65/150\n",
      "691/691 [==============================] - 0s 153us/step - loss: 0.5394 - acc: 0.7279\n",
      "Epoch 66/150\n",
      "691/691 [==============================] - 0s 146us/step - loss: 0.5346 - acc: 0.7438\n",
      "Epoch 67/150\n",
      "691/691 [==============================] - 0s 154us/step - loss: 0.5583 - acc: 0.7265\n",
      "Epoch 68/150\n",
      "691/691 [==============================] - 0s 145us/step - loss: 0.5291 - acc: 0.7337\n",
      "Epoch 69/150\n",
      "691/691 [==============================] - 0s 151us/step - loss: 0.5250 - acc: 0.7323\n",
      "Epoch 70/150\n",
      "691/691 [==============================] - 0s 146us/step - loss: 0.5336 - acc: 0.7279\n",
      "Epoch 71/150\n",
      "691/691 [==============================] - 0s 157us/step - loss: 0.5171 - acc: 0.7569\n",
      "Epoch 72/150\n",
      "691/691 [==============================] - 0s 151us/step - loss: 0.5254 - acc: 0.7337\n",
      "Epoch 73/150\n",
      "691/691 [==============================] - 0s 158us/step - loss: 0.5326 - acc: 0.7453\n",
      "Epoch 74/150\n",
      "691/691 [==============================] - 0s 156us/step - loss: 0.5204 - acc: 0.7438\n",
      "Epoch 75/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5334 - acc: 0.7236\n",
      "Epoch 76/150\n",
      "691/691 [==============================] - 0s 155us/step - loss: 0.5197 - acc: 0.7381\n",
      "Epoch 77/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5247 - acc: 0.7554\n",
      "Epoch 78/150\n",
      "691/691 [==============================] - 0s 139us/step - loss: 0.5133 - acc: 0.7453\n",
      "Epoch 79/150\n",
      "691/691 [==============================] - 0s 156us/step - loss: 0.5258 - acc: 0.7279\n",
      "Epoch 80/150\n",
      "691/691 [==============================] - 0s 143us/step - loss: 0.5292 - acc: 0.7511\n",
      "Epoch 81/150\n",
      "691/691 [==============================] - 0s 155us/step - loss: 0.5260 - acc: 0.7467\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 154us/step - loss: 0.5149 - acc: 0.7265\n",
      "Epoch 83/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5274 - acc: 0.7294\n",
      "Epoch 84/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 0.5135 - acc: 0.7366\n",
      "Epoch 85/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.5113 - acc: 0.7482\n",
      "Epoch 86/150\n",
      "691/691 [==============================] - 0s 185us/step - loss: 0.5110 - acc: 0.7395\n",
      "Epoch 87/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.5127 - acc: 0.7453\n",
      "Epoch 88/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5175 - acc: 0.7410\n",
      "Epoch 89/150\n",
      "691/691 [==============================] - 0s 156us/step - loss: 0.5279 - acc: 0.7352\n",
      "Epoch 90/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.5147 - acc: 0.7410\n",
      "Epoch 91/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5320 - acc: 0.7265\n",
      "Epoch 92/150\n",
      "691/691 [==============================] - 0s 149us/step - loss: 0.5083 - acc: 0.7381\n",
      "Epoch 93/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5161 - acc: 0.7366\n",
      "Epoch 94/150\n",
      "691/691 [==============================] - 0s 241us/step - loss: 0.5089 - acc: 0.7438\n",
      "Epoch 95/150\n",
      "691/691 [==============================] - 0s 217us/step - loss: 0.5138 - acc: 0.7438\n",
      "Epoch 96/150\n",
      "691/691 [==============================] - 0s 257us/step - loss: 0.5191 - acc: 0.7381\n",
      "Epoch 97/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.5221 - acc: 0.7525\n",
      "Epoch 98/150\n",
      "691/691 [==============================] - 0s 213us/step - loss: 0.5204 - acc: 0.7395\n",
      "Epoch 99/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5148 - acc: 0.7424\n",
      "Epoch 100/150\n",
      "691/691 [==============================] - 0s 200us/step - loss: 0.5126 - acc: 0.7453\n",
      "Epoch 101/150\n",
      "691/691 [==============================] - 0s 249us/step - loss: 0.5102 - acc: 0.7453\n",
      "Epoch 102/150\n",
      "691/691 [==============================] - 0s 192us/step - loss: 0.5113 - acc: 0.7511\n",
      "Epoch 103/150\n",
      "691/691 [==============================] - 0s 254us/step - loss: 0.5117 - acc: 0.7395\n",
      "Epoch 104/150\n",
      "691/691 [==============================] - 0s 191us/step - loss: 0.5095 - acc: 0.7395\n",
      "Epoch 105/150\n",
      "691/691 [==============================] - 0s 245us/step - loss: 0.5085 - acc: 0.7496\n",
      "Epoch 106/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.5095 - acc: 0.7410\n",
      "Epoch 107/150\n",
      "691/691 [==============================] - 0s 191us/step - loss: 0.5120 - acc: 0.7612\n",
      "Epoch 108/150\n",
      "691/691 [==============================] - 0s 247us/step - loss: 0.5038 - acc: 0.7438\n",
      "Epoch 109/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 0.5037 - acc: 0.7540\n",
      "Epoch 110/150\n",
      "691/691 [==============================] - 0s 230us/step - loss: 0.5082 - acc: 0.7424\n",
      "Epoch 111/150\n",
      "691/691 [==============================] - 0s 206us/step - loss: 0.5047 - acc: 0.7395\n",
      "Epoch 112/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5043 - acc: 0.7482\n",
      "Epoch 113/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5042 - acc: 0.7554\n",
      "Epoch 114/150\n",
      "691/691 [==============================] - 0s 255us/step - loss: 0.5003 - acc: 0.7496\n",
      "Epoch 115/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.5020 - acc: 0.7467\n",
      "Epoch 116/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.4942 - acc: 0.7598\n",
      "Epoch 117/150\n",
      "691/691 [==============================] - 0s 249us/step - loss: 0.4932 - acc: 0.7496 0s - loss: 0.4777 - acc: 0.76\n",
      "Epoch 118/150\n",
      "691/691 [==============================] - 0s 213us/step - loss: 0.4944 - acc: 0.7554\n",
      "Epoch 119/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.4997 - acc: 0.7670\n",
      "Epoch 120/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.4892 - acc: 0.7554\n",
      "Epoch 121/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.4924 - acc: 0.7410\n",
      "Epoch 122/150\n",
      "691/691 [==============================] - 0s 204us/step - loss: 0.4931 - acc: 0.7540\n",
      "Epoch 123/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 0.4975 - acc: 0.7511\n",
      "Epoch 124/150\n",
      "691/691 [==============================] - 0s 243us/step - loss: 0.5184 - acc: 0.7337\n",
      "Epoch 125/150\n",
      "691/691 [==============================] - 0s 193us/step - loss: 0.5063 - acc: 0.7496\n",
      "Epoch 126/150\n",
      "691/691 [==============================] - 0s 233us/step - loss: 0.4935 - acc: 0.7525\n",
      "Epoch 127/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.4954 - acc: 0.7641\n",
      "Epoch 128/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.4944 - acc: 0.7453\n",
      "Epoch 129/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.4909 - acc: 0.7482\n",
      "Epoch 130/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.4939 - acc: 0.7554\n",
      "Epoch 131/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5010 - acc: 0.7482\n",
      "Epoch 132/150\n",
      "691/691 [==============================] - 0s 142us/step - loss: 0.4852 - acc: 0.7540\n",
      "Epoch 133/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 0.5027 - acc: 0.7525\n",
      "Epoch 134/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.4941 - acc: 0.7569\n",
      "Epoch 135/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.4909 - acc: 0.7438\n",
      "Epoch 136/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.4892 - acc: 0.7525\n",
      "Epoch 137/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.4933 - acc: 0.7569 0s - loss: 0.4926 - acc: 0.77\n",
      "Epoch 138/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.4921 - acc: 0.7554\n",
      "Epoch 139/150\n",
      "691/691 [==============================] - 0s 158us/step - loss: 0.4843 - acc: 0.7598\n",
      "Epoch 140/150\n",
      "691/691 [==============================] - 0s 149us/step - loss: 0.4896 - acc: 0.7569\n",
      "Epoch 141/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.4910 - acc: 0.7540\n",
      "Epoch 142/150\n",
      "691/691 [==============================] - 0s 154us/step - loss: 0.4839 - acc: 0.7540\n",
      "Epoch 143/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.4929 - acc: 0.7627\n",
      "Epoch 144/150\n",
      "691/691 [==============================] - 0s 146us/step - loss: 0.4996 - acc: 0.7641\n",
      "Epoch 145/150\n",
      "691/691 [==============================] - 0s 137us/step - loss: 0.4882 - acc: 0.7612\n",
      "Epoch 146/150\n",
      "691/691 [==============================] - 0s 146us/step - loss: 0.4808 - acc: 0.7800\n",
      "Epoch 147/150\n",
      "691/691 [==============================] - 0s 154us/step - loss: 0.4883 - acc: 0.7554\n",
      "Epoch 148/150\n",
      "691/691 [==============================] - 0s 147us/step - loss: 0.4863 - acc: 0.7627\n",
      "Epoch 149/150\n",
      "691/691 [==============================] - 0s 149us/step - loss: 0.4789 - acc: 0.7685\n",
      "Epoch 150/150\n",
      "691/691 [==============================] - 0s 153us/step - loss: 0.4879 - acc: 0.7569\n",
      "acc: 76.62%\n",
      "Epoch 1/150\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 2/150\n",
      "691/691 [==============================] - 0s 154us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 3/150\n",
      "691/691 [==============================] - 0s 135us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 4/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 5/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 6/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 7/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 8/150\n",
      "691/691 [==============================] - 0s 157us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 9/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 10/150\n",
      "691/691 [==============================] - 0s 156us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 11/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 12/150\n",
      "691/691 [==============================] - 0s 151us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 13/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 172us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 14/150\n",
      "691/691 [==============================] - 0s 156us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 15/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 16/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 17/150\n",
      "691/691 [==============================] - 0s 157us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 18/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 19/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 20/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 21/150\n",
      "691/691 [==============================] - 0s 257us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 22/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 23/150\n",
      "691/691 [==============================] - 0s 239us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 24/150\n",
      "691/691 [==============================] - 0s 216us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 25/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 26/150\n",
      "691/691 [==============================] - 0s 248us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 27/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 28/150\n",
      "691/691 [==============================] - 0s 192us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 29/150\n",
      "691/691 [==============================] - 0s 251us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 30/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 31/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 32/150\n",
      "691/691 [==============================] - 0s 158us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 33/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 5.6215 - acc: 0.6512 0s - loss: 5.5939 - acc: 0.65\n",
      "Epoch 34/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 35/150\n",
      "691/691 [==============================] - 0s 251us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 36/150\n",
      "691/691 [==============================] - 0s 240us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 37/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 38/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 39/150\n",
      "691/691 [==============================] - 0s 146us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 40/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 41/150\n",
      "691/691 [==============================] - 0s 256us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 42/150\n",
      "691/691 [==============================] - 0s 200us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 43/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 44/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 45/150\n",
      "691/691 [==============================] - 0s 241us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 46/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 47/150\n",
      "691/691 [==============================] - 0s 198us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 48/150\n",
      "691/691 [==============================] - 0s 210us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 49/150\n",
      "691/691 [==============================] - 0s 218us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 50/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 51/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 52/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 53/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 54/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 55/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 56/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 57/150\n",
      "691/691 [==============================] - 0s 239us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 58/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 59/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 60/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 61/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 62/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 63/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 64/150\n",
      "691/691 [==============================] - 0s 191us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 65/150\n",
      "691/691 [==============================] - 0s 178us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 66/150\n",
      "691/691 [==============================] - 0s 183us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 67/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 68/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 69/150\n",
      "691/691 [==============================] - 0s 158us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 70/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 71/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 72/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 73/150\n",
      "691/691 [==============================] - 0s 154us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 74/150\n",
      "691/691 [==============================] - 0s 178us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 75/150\n",
      "691/691 [==============================] - 0s 158us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 76/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 77/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 78/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 79/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 80/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 81/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 82/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 83/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 84/150\n",
      "691/691 [==============================] - 0s 157us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 85/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 86/150\n",
      "691/691 [==============================] - 0s 155us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 87/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 88/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 89/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 90/150\n",
      "691/691 [==============================] - 0s 153us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 91/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 92/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 93/150\n",
      "691/691 [==============================] - 0s 153us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 94/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 95/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 166us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 96/150\n",
      "691/691 [==============================] - 0s 231us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 97/150\n",
      "691/691 [==============================] - 0s 251us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 98/150\n",
      "691/691 [==============================] - 0s 253us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 99/150\n",
      "691/691 [==============================] - 0s 190us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 100/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 101/150\n",
      "691/691 [==============================] - 0s 176us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 102/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 103/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 104/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 105/150\n",
      "691/691 [==============================] - 0s 156us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 106/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 107/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 108/150\n",
      "691/691 [==============================] - 0s 235us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 109/150\n",
      "691/691 [==============================] - 0s 220us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 110/150\n",
      "691/691 [==============================] - 0s 237us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 111/150\n",
      "691/691 [==============================] - 0s 215us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 112/150\n",
      "691/691 [==============================] - 0s 253us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 113/150\n",
      "691/691 [==============================] - ETA: 0s - loss: 5.6297 - acc: 0.650 - 0s 230us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 114/150\n",
      "691/691 [==============================] - 0s 238us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 115/150\n",
      "691/691 [==============================] - 0s 221us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 116/150\n",
      "691/691 [==============================] - 0s 229us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 117/150\n",
      "691/691 [==============================] - 0s 237us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 118/150\n",
      "691/691 [==============================] - 0s 257us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 119/150\n",
      "691/691 [==============================] - 0s 233us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 120/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 121/150\n",
      "691/691 [==============================] - 0s 217us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 122/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 123/150\n",
      "691/691 [==============================] - 0s 266us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 124/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 125/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 126/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 127/150\n",
      "691/691 [==============================] - 0s 214us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 128/150\n",
      "691/691 [==============================] - 0s 238us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 129/150\n",
      "691/691 [==============================] - 0s 220us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 130/150\n",
      "691/691 [==============================] - 0s 248us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 131/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 132/150\n",
      "691/691 [==============================] - 0s 235us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 133/150\n",
      "691/691 [==============================] - 0s 210us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 134/150\n",
      "691/691 [==============================] - 0s 218us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 135/150\n",
      "691/691 [==============================] - 0s 215us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 136/150\n",
      "691/691 [==============================] - 0s 252us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 137/150\n",
      "691/691 [==============================] - 0s 210us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 138/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 139/150\n",
      "691/691 [==============================] - 0s 242us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 140/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 141/150\n",
      "691/691 [==============================] - 0s 220us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 142/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 143/150\n",
      "691/691 [==============================] - 0s 265us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 144/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 145/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 146/150\n",
      "691/691 [==============================] - 0s 253us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 147/150\n",
      "691/691 [==============================] - 0s 192us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 148/150\n",
      "691/691 [==============================] - 0s 198us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 149/150\n",
      "691/691 [==============================] - 0s 251us/step - loss: 5.6215 - acc: 0.6512\n",
      "Epoch 150/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 5.6215 - acc: 0.6512\n",
      "acc: 64.94%\n",
      "Epoch 1/150\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 3.7170 - acc: 0.6440\n",
      "Epoch 2/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 3.2769 - acc: 0.6266\n",
      "Epoch 3/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 3.1937 - acc: 0.6151\n",
      "Epoch 4/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 3.0957 - acc: 0.6310\n",
      "Epoch 5/150\n",
      "691/691 [==============================] - 0s 190us/step - loss: 2.6340 - acc: 0.6093\n",
      "Epoch 6/150\n",
      "691/691 [==============================] - 0s 209us/step - loss: 1.2725 - acc: 0.6107\n",
      "Epoch 7/150\n",
      "691/691 [==============================] - 0s 203us/step - loss: 0.6694 - acc: 0.6700\n",
      "Epoch 8/150\n",
      "691/691 [==============================] - 0s 213us/step - loss: 0.6487 - acc: 0.6686\n",
      "Epoch 9/150\n",
      "691/691 [==============================] - 0s 199us/step - loss: 0.6363 - acc: 0.6715\n",
      "Epoch 10/150\n",
      "691/691 [==============================] - 0s 204us/step - loss: 0.6217 - acc: 0.6787\n",
      "Epoch 11/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.6155 - acc: 0.6889\n",
      "Epoch 12/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 0.6088 - acc: 0.6874\n",
      "Epoch 13/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 0.6028 - acc: 0.6903\n",
      "Epoch 14/150\n",
      "691/691 [==============================] - 0s 193us/step - loss: 0.6024 - acc: 0.6975\n",
      "Epoch 15/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.6068 - acc: 0.6918\n",
      "Epoch 16/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 0.6020 - acc: 0.6874\n",
      "Epoch 17/150\n",
      "691/691 [==============================] - 0s 215us/step - loss: 0.5939 - acc: 0.6918\n",
      "Epoch 18/150\n",
      "691/691 [==============================] - 0s 237us/step - loss: 0.5997 - acc: 0.6845\n",
      "Epoch 19/150\n",
      "691/691 [==============================] - 0s 239us/step - loss: 0.5801 - acc: 0.7091\n",
      "Epoch 20/150\n",
      "691/691 [==============================] - 0s 199us/step - loss: 0.6021 - acc: 0.6889\n",
      "Epoch 21/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 0.5847 - acc: 0.7164\n",
      "Epoch 22/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.5926 - acc: 0.6946\n",
      "Epoch 23/150\n",
      "691/691 [==============================] - 0s 245us/step - loss: 0.5938 - acc: 0.7135\n",
      "Epoch 24/150\n",
      "691/691 [==============================] - 0s 275us/step - loss: 0.5839 - acc: 0.7236\n",
      "Epoch 25/150\n",
      "691/691 [==============================] - 0s 204us/step - loss: 0.5747 - acc: 0.7048\n",
      "Epoch 26/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.5687 - acc: 0.7135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.5680 - acc: 0.7120\n",
      "Epoch 28/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5783 - acc: 0.7091\n",
      "Epoch 29/150\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.5678 - acc: 0.722 - 0s 160us/step - loss: 0.5701 - acc: 0.7207\n",
      "Epoch 30/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.5673 - acc: 0.7120\n",
      "Epoch 31/150\n",
      "691/691 [==============================] - 0s 342us/step - loss: 0.5843 - acc: 0.7164 0s - loss: 0.6161 - acc: 0.69\n",
      "Epoch 32/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5599 - acc: 0.7178\n",
      "Epoch 33/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5642 - acc: 0.7207\n",
      "Epoch 34/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5654 - acc: 0.7033\n",
      "Epoch 35/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5727 - acc: 0.7106\n",
      "Epoch 36/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.5556 - acc: 0.7352\n",
      "Epoch 37/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.5620 - acc: 0.7265\n",
      "Epoch 38/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5579 - acc: 0.7207\n",
      "Epoch 39/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.5624 - acc: 0.7221\n",
      "Epoch 40/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.5514 - acc: 0.7207\n",
      "Epoch 41/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5612 - acc: 0.7294\n",
      "Epoch 42/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.5732 - acc: 0.7033\n",
      "Epoch 43/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5533 - acc: 0.7265\n",
      "Epoch 44/150\n",
      "691/691 [==============================] - 0s 319us/step - loss: 0.5500 - acc: 0.7323\n",
      "Epoch 45/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 0.5439 - acc: 0.7366\n",
      "Epoch 46/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5523 - acc: 0.7135\n",
      "Epoch 47/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5554 - acc: 0.7236\n",
      "Epoch 48/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.5440 - acc: 0.7366\n",
      "Epoch 49/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5530 - acc: 0.7019\n",
      "Epoch 50/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.5416 - acc: 0.7178\n",
      "Epoch 51/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 0.5497 - acc: 0.7265\n",
      "Epoch 52/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.5463 - acc: 0.7381\n",
      "Epoch 53/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5469 - acc: 0.7207\n",
      "Epoch 54/150\n",
      "691/691 [==============================] - 0s 203us/step - loss: 0.5373 - acc: 0.7337\n",
      "Epoch 55/150\n",
      "691/691 [==============================] - 0s 213us/step - loss: 0.5361 - acc: 0.7337\n",
      "Epoch 56/150\n",
      "691/691 [==============================] - 0s 194us/step - loss: 0.5327 - acc: 0.7424\n",
      "Epoch 57/150\n",
      "691/691 [==============================] - 0s 192us/step - loss: 0.5288 - acc: 0.7366\n",
      "Epoch 58/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 0.5282 - acc: 0.7352\n",
      "Epoch 59/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.5259 - acc: 0.7265\n",
      "Epoch 60/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 0.5325 - acc: 0.7337\n",
      "Epoch 61/150\n",
      "691/691 [==============================] - 0s 155us/step - loss: 0.5290 - acc: 0.7250\n",
      "Epoch 62/150\n",
      "691/691 [==============================] - 0s 139us/step - loss: 0.5234 - acc: 0.7395\n",
      "Epoch 63/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5364 - acc: 0.7424\n",
      "Epoch 64/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.5297 - acc: 0.7352\n",
      "Epoch 65/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.5201 - acc: 0.7308\n",
      "Epoch 66/150\n",
      "691/691 [==============================] - 0s 152us/step - loss: 0.5218 - acc: 0.7438\n",
      "Epoch 67/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 0.5189 - acc: 0.7395\n",
      "Epoch 68/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5193 - acc: 0.7381\n",
      "Epoch 69/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5483 - acc: 0.7352\n",
      "Epoch 70/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 0.5132 - acc: 0.7525\n",
      "Epoch 71/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5188 - acc: 0.7453\n",
      "Epoch 72/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.5216 - acc: 0.7366\n",
      "Epoch 73/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 0.5182 - acc: 0.7467\n",
      "Epoch 74/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5255 - acc: 0.7554\n",
      "Epoch 75/150\n",
      "691/691 [==============================] - 0s 220us/step - loss: 0.5135 - acc: 0.7410\n",
      "Epoch 76/150\n",
      "691/691 [==============================] - 0s 269us/step - loss: 0.5114 - acc: 0.7438\n",
      "Epoch 77/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5191 - acc: 0.7467\n",
      "Epoch 78/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.5098 - acc: 0.7381\n",
      "Epoch 79/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 0.5162 - acc: 0.7467\n",
      "Epoch 80/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5134 - acc: 0.7583\n",
      "Epoch 81/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 0.5204 - acc: 0.7381\n",
      "Epoch 82/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5052 - acc: 0.7496\n",
      "Epoch 83/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.5073 - acc: 0.7670\n",
      "Epoch 84/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.5249 - acc: 0.7525\n",
      "Epoch 85/150\n",
      "691/691 [==============================] - 0s 209us/step - loss: 0.5064 - acc: 0.7496\n",
      "Epoch 86/150\n",
      "691/691 [==============================] - 0s 289us/step - loss: 0.5156 - acc: 0.7438\n",
      "Epoch 87/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 0.5153 - acc: 0.7554\n",
      "Epoch 88/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.4988 - acc: 0.7641\n",
      "Epoch 89/150\n",
      "691/691 [==============================] - 0s 188us/step - loss: 0.5102 - acc: 0.7366\n",
      "Epoch 90/150\n",
      "691/691 [==============================] - 0s 176us/step - loss: 0.5058 - acc: 0.7511\n",
      "Epoch 91/150\n",
      "691/691 [==============================] - 0s 149us/step - loss: 0.5029 - acc: 0.7453\n",
      "Epoch 92/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.4960 - acc: 0.7786\n",
      "Epoch 93/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5071 - acc: 0.7554\n",
      "Epoch 94/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5493 - acc: 0.7366\n",
      "Epoch 95/150\n",
      "691/691 [==============================] - 0s 176us/step - loss: 0.5239 - acc: 0.7236\n",
      "Epoch 96/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5097 - acc: 0.7583\n",
      "Epoch 97/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5023 - acc: 0.7670\n",
      "Epoch 98/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 0.5021 - acc: 0.7627\n",
      "Epoch 99/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.4955 - acc: 0.7496\n",
      "Epoch 100/150\n",
      "691/691 [==============================] - 0s 154us/step - loss: 0.5101 - acc: 0.7467\n",
      "Epoch 101/150\n",
      "691/691 [==============================] - 0s 156us/step - loss: 0.4923 - acc: 0.7496\n",
      "Epoch 102/150\n",
      "691/691 [==============================] - 0s 149us/step - loss: 0.4928 - acc: 0.7540\n",
      "Epoch 103/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.4983 - acc: 0.7496\n",
      "Epoch 104/150\n",
      "691/691 [==============================] - 0s 151us/step - loss: 0.5058 - acc: 0.7424\n",
      "Epoch 105/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 0.4941 - acc: 0.7583\n",
      "Epoch 106/150\n",
      "691/691 [==============================] - 0s 148us/step - loss: 0.5059 - acc: 0.7438\n",
      "Epoch 107/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 0.5071 - acc: 0.7612\n",
      "Epoch 108/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.4927 - acc: 0.7554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5014 - acc: 0.7569\n",
      "Epoch 110/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.5151 - acc: 0.7424\n",
      "Epoch 111/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.4941 - acc: 0.7670\n",
      "Epoch 112/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.4905 - acc: 0.7583\n",
      "Epoch 113/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.4931 - acc: 0.7699\n",
      "Epoch 114/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5070 - acc: 0.7467\n",
      "Epoch 115/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 0.5244 - acc: 0.7467\n",
      "Epoch 116/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 0.4964 - acc: 0.7438\n",
      "Epoch 117/150\n",
      "691/691 [==============================] - 0s 181us/step - loss: 0.4898 - acc: 0.7656\n",
      "Epoch 118/150\n",
      "691/691 [==============================] - 0s 188us/step - loss: 0.4872 - acc: 0.7757\n",
      "Epoch 119/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.4891 - acc: 0.7685\n",
      "Epoch 120/150\n",
      "691/691 [==============================] - 0s 151us/step - loss: 0.4923 - acc: 0.7583\n",
      "Epoch 121/150\n",
      "691/691 [==============================] - 0s 151us/step - loss: 0.4975 - acc: 0.7699\n",
      "Epoch 122/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.4854 - acc: 0.7598\n",
      "Epoch 123/150\n",
      "691/691 [==============================] - 0s 154us/step - loss: 0.4840 - acc: 0.7612\n",
      "Epoch 124/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 0.4947 - acc: 0.7482\n",
      "Epoch 125/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.4806 - acc: 0.7641\n",
      "Epoch 126/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.4929 - acc: 0.7554\n",
      "Epoch 127/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.4916 - acc: 0.7670\n",
      "Epoch 128/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.4799 - acc: 0.7757\n",
      "Epoch 129/150\n",
      "691/691 [==============================] - 0s 216us/step - loss: 0.4861 - acc: 0.7685\n",
      "Epoch 130/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.4780 - acc: 0.7670\n",
      "Epoch 131/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.4832 - acc: 0.7554\n",
      "Epoch 132/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.4852 - acc: 0.7670\n",
      "Epoch 133/150\n",
      "691/691 [==============================] - 0s 185us/step - loss: 0.4792 - acc: 0.7786\n",
      "Epoch 134/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.4919 - acc: 0.7670\n",
      "Epoch 135/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.4863 - acc: 0.7612\n",
      "Epoch 136/150\n",
      "691/691 [==============================] - 0s 146us/step - loss: 0.4741 - acc: 0.7656\n",
      "Epoch 137/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.4769 - acc: 0.7656\n",
      "Epoch 138/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 0.4814 - acc: 0.7685\n",
      "Epoch 139/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.4787 - acc: 0.7554\n",
      "Epoch 140/150\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.4670 - acc: 0.777 - 0s 167us/step - loss: 0.4810 - acc: 0.7670\n",
      "Epoch 141/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.4816 - acc: 0.7742\n",
      "Epoch 142/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.4772 - acc: 0.7742\n",
      "Epoch 143/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.4777 - acc: 0.7786\n",
      "Epoch 144/150\n",
      "691/691 [==============================] - 0s 154us/step - loss: 0.4878 - acc: 0.7554\n",
      "Epoch 145/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.4817 - acc: 0.7757\n",
      "Epoch 146/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.4856 - acc: 0.7656\n",
      "Epoch 147/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.4756 - acc: 0.7699\n",
      "Epoch 148/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.4728 - acc: 0.7728\n",
      "Epoch 149/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.4786 - acc: 0.7757\n",
      "Epoch 150/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.4797 - acc: 0.7713\n",
      "acc: 71.43%\n",
      "Epoch 1/150\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 10.3822 - acc: 0.3488\n",
      "Epoch 2/150\n",
      "691/691 [==============================] - 0s 152us/step - loss: 10.3806 - acc: 0.3488\n",
      "Epoch 3/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 10.3704 - acc: 0.3488\n",
      "Epoch 4/150\n",
      "691/691 [==============================] - 0s 146us/step - loss: 10.3111 - acc: 0.3488\n",
      "Epoch 5/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 3.7034 - acc: 0.5499\n",
      "Epoch 6/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 1.1004 - acc: 0.6295\n",
      "Epoch 7/150\n",
      "691/691 [==============================] - 0s 144us/step - loss: 0.8679 - acc: 0.6237\n",
      "Epoch 8/150\n",
      "691/691 [==============================] - 0s 143us/step - loss: 0.8083 - acc: 0.6208\n",
      "Epoch 9/150\n",
      "691/691 [==============================] - 0s 149us/step - loss: 0.7711 - acc: 0.6440\n",
      "Epoch 10/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.7443 - acc: 0.6223\n",
      "Epoch 11/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.7483 - acc: 0.6483\n",
      "Epoch 12/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.7260 - acc: 0.6179\n",
      "Epoch 13/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.6834 - acc: 0.6411\n",
      "Epoch 14/150\n",
      "691/691 [==============================] - 0s 154us/step - loss: 0.6953 - acc: 0.6469\n",
      "Epoch 15/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.6755 - acc: 0.6397\n",
      "Epoch 16/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.6969 - acc: 0.6382 0s - loss: 0.6999 - acc: 0.631\n",
      "Epoch 17/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 0.6686 - acc: 0.6744\n",
      "Epoch 18/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.6436 - acc: 0.6556\n",
      "Epoch 19/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.6448 - acc: 0.6671\n",
      "Epoch 20/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.6592 - acc: 0.6657\n",
      "Epoch 21/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.6550 - acc: 0.6845\n",
      "Epoch 22/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.6193 - acc: 0.6773\n",
      "Epoch 23/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.6468 - acc: 0.6758\n",
      "Epoch 24/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.6290 - acc: 0.7004\n",
      "Epoch 25/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 0.6132 - acc: 0.6918\n",
      "Epoch 26/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.6096 - acc: 0.7135\n",
      "Epoch 27/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.6092 - acc: 0.7019\n",
      "Epoch 28/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.6093 - acc: 0.7091\n",
      "Epoch 29/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.6290 - acc: 0.6961\n",
      "Epoch 30/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5928 - acc: 0.7164\n",
      "Epoch 31/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5830 - acc: 0.7149\n",
      "Epoch 32/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.6058 - acc: 0.7004\n",
      "Epoch 33/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5892 - acc: 0.7106\n",
      "Epoch 34/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5888 - acc: 0.6918\n",
      "Epoch 35/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.6229 - acc: 0.6831\n",
      "Epoch 36/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5927 - acc: 0.6889\n",
      "Epoch 37/150\n",
      "691/691 [==============================] - 0s 156us/step - loss: 0.5775 - acc: 0.7135\n",
      "Epoch 38/150\n",
      "691/691 [==============================] - 0s 156us/step - loss: 0.5873 - acc: 0.7062\n",
      "Epoch 39/150\n",
      "691/691 [==============================] - 0s 157us/step - loss: 0.5877 - acc: 0.7250\n",
      "Epoch 40/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 164us/step - loss: 0.6951 - acc: 0.6990\n",
      "Epoch 41/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5905 - acc: 0.7019\n",
      "Epoch 42/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.6003 - acc: 0.7120\n",
      "Epoch 43/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 0.6030 - acc: 0.7062\n",
      "Epoch 44/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5702 - acc: 0.7135\n",
      "Epoch 45/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5980 - acc: 0.6787\n",
      "Epoch 46/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5681 - acc: 0.7135\n",
      "Epoch 47/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.5629 - acc: 0.7250\n",
      "Epoch 48/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5653 - acc: 0.7236\n",
      "Epoch 49/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.5673 - acc: 0.6932\n",
      "Epoch 50/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5621 - acc: 0.7207\n",
      "Epoch 51/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5630 - acc: 0.7135\n",
      "Epoch 52/150\n",
      "691/691 [==============================] - 0s 139us/step - loss: 0.5538 - acc: 0.7236\n",
      "Epoch 53/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5584 - acc: 0.7062\n",
      "Epoch 54/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5603 - acc: 0.7149\n",
      "Epoch 55/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5725 - acc: 0.7164\n",
      "Epoch 56/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5524 - acc: 0.7236\n",
      "Epoch 57/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.5550 - acc: 0.7091 0s - loss: 0.5801 - acc: 0.69\n",
      "Epoch 58/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5735 - acc: 0.7106\n",
      "Epoch 59/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5537 - acc: 0.7308\n",
      "Epoch 60/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5465 - acc: 0.7221\n",
      "Epoch 61/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5455 - acc: 0.7352\n",
      "Epoch 62/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5735 - acc: 0.7149\n",
      "Epoch 63/150\n",
      "691/691 [==============================] - 0s 183us/step - loss: 0.5392 - acc: 0.7265\n",
      "Epoch 64/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5436 - acc: 0.7279\n",
      "Epoch 65/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5490 - acc: 0.7279\n",
      "Epoch 66/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5539 - acc: 0.7120\n",
      "Epoch 67/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.5496 - acc: 0.7337\n",
      "Epoch 68/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5482 - acc: 0.7294\n",
      "Epoch 69/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.5452 - acc: 0.7308\n",
      "Epoch 70/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5550 - acc: 0.7279\n",
      "Epoch 71/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5550 - acc: 0.7236\n",
      "Epoch 72/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5528 - acc: 0.7279\n",
      "Epoch 73/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5539 - acc: 0.7337\n",
      "Epoch 74/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5508 - acc: 0.7164\n",
      "Epoch 75/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5498 - acc: 0.7323\n",
      "Epoch 76/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5263 - acc: 0.7294\n",
      "Epoch 77/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.5385 - acc: 0.7236\n",
      "Epoch 78/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.5424 - acc: 0.7381\n",
      "Epoch 79/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5327 - acc: 0.7366\n",
      "Epoch 80/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5392 - acc: 0.7265\n",
      "Epoch 81/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5257 - acc: 0.7438\n",
      "Epoch 82/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5243 - acc: 0.7410\n",
      "Epoch 83/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5224 - acc: 0.7496\n",
      "Epoch 84/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5189 - acc: 0.7410\n",
      "Epoch 85/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 0.5385 - acc: 0.7250\n",
      "Epoch 86/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5646 - acc: 0.7207\n",
      "Epoch 87/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5835 - acc: 0.7337\n",
      "Epoch 88/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5416 - acc: 0.7294\n",
      "Epoch 89/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5245 - acc: 0.7438\n",
      "Epoch 90/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5273 - acc: 0.7410\n",
      "Epoch 91/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 0.5489 - acc: 0.7164\n",
      "Epoch 92/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5168 - acc: 0.7438\n",
      "Epoch 93/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.5195 - acc: 0.7381\n",
      "Epoch 94/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5246 - acc: 0.7294\n",
      "Epoch 95/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5284 - acc: 0.7482\n",
      "Epoch 96/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5191 - acc: 0.7366\n",
      "Epoch 97/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.5268 - acc: 0.7496\n",
      "Epoch 98/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5109 - acc: 0.7366\n",
      "Epoch 99/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5119 - acc: 0.7323\n",
      "Epoch 100/150\n",
      "691/691 [==============================] - 0s 161us/step - loss: 0.5384 - acc: 0.7352\n",
      "Epoch 101/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.5321 - acc: 0.7511\n",
      "Epoch 102/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5202 - acc: 0.7424\n",
      "Epoch 103/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.5133 - acc: 0.7467\n",
      "Epoch 104/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.5467 - acc: 0.7395\n",
      "Epoch 105/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.5176 - acc: 0.7381\n",
      "Epoch 106/150\n",
      "691/691 [==============================] - 0s 199us/step - loss: 0.5379 - acc: 0.7279\n",
      "Epoch 107/150\n",
      "691/691 [==============================] - 0s 243us/step - loss: 0.5104 - acc: 0.7366\n",
      "Epoch 108/150\n",
      "691/691 [==============================] - 0s 196us/step - loss: 0.5168 - acc: 0.7395\n",
      "Epoch 109/150\n",
      "691/691 [==============================] - 0s 238us/step - loss: 0.5098 - acc: 0.7482\n",
      "Epoch 110/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5051 - acc: 0.7583\n",
      "Epoch 111/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.5072 - acc: 0.7511\n",
      "Epoch 112/150\n",
      "691/691 [==============================] - 0s 188us/step - loss: 0.5241 - acc: 0.7265\n",
      "Epoch 113/150\n",
      "691/691 [==============================] - 0s 193us/step - loss: 0.5094 - acc: 0.7569\n",
      "Epoch 114/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5099 - acc: 0.7612\n",
      "Epoch 115/150\n",
      "691/691 [==============================] - 0s 153us/step - loss: 0.5116 - acc: 0.7438\n",
      "Epoch 116/150\n",
      "691/691 [==============================] - 0s 185us/step - loss: 0.5059 - acc: 0.7656\n",
      "Epoch 117/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 0.5091 - acc: 0.7294\n",
      "Epoch 118/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.5101 - acc: 0.7525\n",
      "Epoch 119/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5005 - acc: 0.7525\n",
      "Epoch 120/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5154 - acc: 0.7410\n",
      "Epoch 121/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5193 - acc: 0.7453\n",
      "Epoch 122/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 161us/step - loss: 0.5062 - acc: 0.7467\n",
      "Epoch 123/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.4941 - acc: 0.7598\n",
      "Epoch 124/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5451 - acc: 0.7323\n",
      "Epoch 125/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.4953 - acc: 0.7583\n",
      "Epoch 126/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.4997 - acc: 0.7656\n",
      "Epoch 127/150\n",
      "691/691 [==============================] - 0s 156us/step - loss: 0.4934 - acc: 0.7540\n",
      "Epoch 128/150\n",
      "691/691 [==============================] - 0s 141us/step - loss: 0.5053 - acc: 0.7525\n",
      "Epoch 129/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5186 - acc: 0.7294\n",
      "Epoch 130/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.4969 - acc: 0.7424\n",
      "Epoch 131/150\n",
      "691/691 [==============================] - 0s 137us/step - loss: 0.5055 - acc: 0.7366\n",
      "Epoch 132/150\n",
      "691/691 [==============================] - 0s 159us/step - loss: 0.5163 - acc: 0.7511\n",
      "Epoch 133/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5048 - acc: 0.7525\n",
      "Epoch 134/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.4968 - acc: 0.7612\n",
      "Epoch 135/150\n",
      "691/691 [==============================] - 0s 140us/step - loss: 0.5003 - acc: 0.7511\n",
      "Epoch 136/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.4925 - acc: 0.7612\n",
      "Epoch 137/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 0.4952 - acc: 0.7583\n",
      "Epoch 138/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.4920 - acc: 0.7685\n",
      "Epoch 139/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 0.4901 - acc: 0.7699\n",
      "Epoch 140/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 0.4812 - acc: 0.7829\n",
      "Epoch 141/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5096 - acc: 0.7627\n",
      "Epoch 142/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5045 - acc: 0.7641\n",
      "Epoch 143/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.4966 - acc: 0.7612\n",
      "Epoch 144/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.4959 - acc: 0.7612\n",
      "Epoch 145/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.4873 - acc: 0.7656\n",
      "Epoch 146/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.4897 - acc: 0.7742\n",
      "Epoch 147/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.4917 - acc: 0.7742\n",
      "Epoch 148/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.5007 - acc: 0.7569\n",
      "Epoch 149/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.4839 - acc: 0.7525\n",
      "Epoch 150/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.5029 - acc: 0.7583\n",
      "acc: 70.13%\n",
      "Epoch 1/150\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 4.6186 - acc: 0.4732\n",
      "Epoch 2/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 1.3722 - acc: 0.6006\n",
      "Epoch 3/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.8815 - acc: 0.6310\n",
      "Epoch 4/150\n",
      "691/691 [==============================] - 0s 225us/step - loss: 0.7739 - acc: 0.6223\n",
      "Epoch 5/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 0.7388 - acc: 0.6295\n",
      "Epoch 6/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 0.7163 - acc: 0.6425\n",
      "Epoch 7/150\n",
      "691/691 [==============================] - 0s 204us/step - loss: 0.6929 - acc: 0.6498\n",
      "Epoch 8/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.6910 - acc: 0.6353\n",
      "Epoch 9/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.6833 - acc: 0.6382 0s - loss: 0.7068 - acc: 0.58\n",
      "Epoch 10/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.6882 - acc: 0.6758\n",
      "Epoch 11/150\n",
      "691/691 [==============================] - 0s 191us/step - loss: 0.6642 - acc: 0.6498\n",
      "Epoch 12/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.6640 - acc: 0.6498\n",
      "Epoch 13/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.6726 - acc: 0.6440\n",
      "Epoch 14/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.6440 - acc: 0.6628\n",
      "Epoch 15/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.6285 - acc: 0.6700\n",
      "Epoch 16/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.6190 - acc: 0.6700\n",
      "Epoch 17/150\n",
      "691/691 [==============================] - 0s 180us/step - loss: 0.6311 - acc: 0.6773\n",
      "Epoch 18/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.6240 - acc: 0.6686\n",
      "Epoch 19/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.6142 - acc: 0.6671\n",
      "Epoch 20/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.6127 - acc: 0.6628\n",
      "Epoch 21/150\n",
      "691/691 [==============================] - 0s 176us/step - loss: 0.6141 - acc: 0.6744\n",
      "Epoch 22/150\n",
      "691/691 [==============================] - 0s 176us/step - loss: 0.6181 - acc: 0.6686\n",
      "Epoch 23/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.5987 - acc: 0.6845\n",
      "Epoch 24/150\n",
      "691/691 [==============================] - 0s 185us/step - loss: 0.6431 - acc: 0.6744\n",
      "Epoch 25/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.6010 - acc: 0.6758\n",
      "Epoch 26/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.5956 - acc: 0.6932\n",
      "Epoch 27/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 0.5883 - acc: 0.6932\n",
      "Epoch 28/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.5912 - acc: 0.6961\n",
      "Epoch 29/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.5994 - acc: 0.7033\n",
      "Epoch 30/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5996 - acc: 0.6845\n",
      "Epoch 31/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5938 - acc: 0.6990\n",
      "Epoch 32/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5913 - acc: 0.6946\n",
      "Epoch 33/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.5941 - acc: 0.6889\n",
      "Epoch 34/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5806 - acc: 0.7091\n",
      "Epoch 35/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.5792 - acc: 0.7033\n",
      "Epoch 36/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5670 - acc: 0.7250\n",
      "Epoch 37/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5776 - acc: 0.7033\n",
      "Epoch 38/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.5678 - acc: 0.7033\n",
      "Epoch 39/150\n",
      "691/691 [==============================] - 0s 191us/step - loss: 0.5808 - acc: 0.7135\n",
      "Epoch 40/150\n",
      "691/691 [==============================] - 0s 181us/step - loss: 0.5656 - acc: 0.7294\n",
      "Epoch 41/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5643 - acc: 0.7265\n",
      "Epoch 42/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 0.5690 - acc: 0.7120\n",
      "Epoch 43/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5589 - acc: 0.7149\n",
      "Epoch 44/150\n",
      "691/691 [==============================] - 0s 178us/step - loss: 0.5716 - acc: 0.7294\n",
      "Epoch 45/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5577 - acc: 0.7207\n",
      "Epoch 46/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5670 - acc: 0.6860\n",
      "Epoch 47/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.5545 - acc: 0.7381\n",
      "Epoch 48/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5510 - acc: 0.7265\n",
      "Epoch 49/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5540 - acc: 0.7438\n",
      "Epoch 50/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5544 - acc: 0.7381\n",
      "Epoch 51/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.5573 - acc: 0.7164\n",
      "Epoch 52/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5515 - acc: 0.7395\n",
      "Epoch 53/150\n",
      "691/691 [==============================] - 0s 178us/step - loss: 0.5488 - acc: 0.7106\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 181us/step - loss: 0.5434 - acc: 0.7352\n",
      "Epoch 55/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.5423 - acc: 0.7381\n",
      "Epoch 56/150\n",
      "691/691 [==============================] - 0s 219us/step - loss: 0.5473 - acc: 0.7467\n",
      "Epoch 57/150\n",
      "691/691 [==============================] - 0s 276us/step - loss: 0.5396 - acc: 0.7496\n",
      "Epoch 58/150\n",
      "691/691 [==============================] - 0s 241us/step - loss: 0.5744 - acc: 0.7004\n",
      "Epoch 59/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.5446 - acc: 0.7337\n",
      "Epoch 60/150\n",
      "691/691 [==============================] - 0s 188us/step - loss: 0.5455 - acc: 0.7410\n",
      "Epoch 61/150\n",
      "691/691 [==============================] - 0s 188us/step - loss: 0.5558 - acc: 0.7366\n",
      "Epoch 62/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.5388 - acc: 0.7453\n",
      "Epoch 63/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 0.5376 - acc: 0.7395\n",
      "Epoch 64/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5543 - acc: 0.7207\n",
      "Epoch 65/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5489 - acc: 0.7323\n",
      "Epoch 66/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5706 - acc: 0.7192\n",
      "Epoch 67/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5393 - acc: 0.7192\n",
      "Epoch 68/150\n",
      "691/691 [==============================] - 0s 191us/step - loss: 0.5455 - acc: 0.7265\n",
      "Epoch 69/150\n",
      "691/691 [==============================] - 0s 176us/step - loss: 0.5525 - acc: 0.7236\n",
      "Epoch 70/150\n",
      "691/691 [==============================] - 0s 181us/step - loss: 0.5507 - acc: 0.7337\n",
      "Epoch 71/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 0.5335 - acc: 0.7511\n",
      "Epoch 72/150\n",
      "691/691 [==============================] - 0s 181us/step - loss: 0.5406 - acc: 0.7308\n",
      "Epoch 73/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5395 - acc: 0.7221\n",
      "Epoch 74/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5315 - acc: 0.7453\n",
      "Epoch 75/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5339 - acc: 0.7424\n",
      "Epoch 76/150\n",
      "691/691 [==============================] - 0s 191us/step - loss: 0.5274 - acc: 0.7554\n",
      "Epoch 77/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.5314 - acc: 0.7525\n",
      "Epoch 78/150\n",
      "691/691 [==============================] - 0s 220us/step - loss: 0.5405 - acc: 0.7294\n",
      "Epoch 79/150\n",
      "691/691 [==============================] - 0s 218us/step - loss: 0.5428 - acc: 0.7410\n",
      "Epoch 80/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5391 - acc: 0.7395\n",
      "Epoch 81/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5334 - acc: 0.7511\n",
      "Epoch 82/150\n",
      "691/691 [==============================] - 0s 194us/step - loss: 0.5206 - acc: 0.7467\n",
      "Epoch 83/150\n",
      "691/691 [==============================] - 0s 185us/step - loss: 0.5291 - acc: 0.7294\n",
      "Epoch 84/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.5282 - acc: 0.7453\n",
      "Epoch 85/150\n",
      "691/691 [==============================] - 0s 163us/step - loss: 0.5261 - acc: 0.7525\n",
      "Epoch 86/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5313 - acc: 0.7511\n",
      "Epoch 87/150\n",
      "691/691 [==============================] - 0s 193us/step - loss: 0.5363 - acc: 0.7467\n",
      "Epoch 88/150\n",
      "691/691 [==============================] - 0s 196us/step - loss: 0.5247 - acc: 0.7482\n",
      "Epoch 89/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 0.5313 - acc: 0.7482\n",
      "Epoch 90/150\n",
      "691/691 [==============================] - 0s 217us/step - loss: 0.5292 - acc: 0.7525\n",
      "Epoch 91/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 0.5253 - acc: 0.7554\n",
      "Epoch 92/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.5358 - acc: 0.7554\n",
      "Epoch 93/150\n",
      "691/691 [==============================] - 0s 171us/step - loss: 0.5411 - acc: 0.7381\n",
      "Epoch 94/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5198 - acc: 0.7453\n",
      "Epoch 95/150\n",
      "691/691 [==============================] - 0s 180us/step - loss: 0.5372 - acc: 0.7381\n",
      "Epoch 96/150\n",
      "691/691 [==============================] - 0s 190us/step - loss: 0.5175 - acc: 0.7525\n",
      "Epoch 97/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.5492 - acc: 0.7496\n",
      "Epoch 98/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5565 - acc: 0.7120\n",
      "Epoch 99/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5176 - acc: 0.7453\n",
      "Epoch 100/150\n",
      "691/691 [==============================] - 0s 176us/step - loss: 0.5250 - acc: 0.7598\n",
      "Epoch 101/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5129 - acc: 0.7569\n",
      "Epoch 102/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5318 - acc: 0.7410\n",
      "Epoch 103/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.5250 - acc: 0.7598\n",
      "Epoch 104/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.5089 - acc: 0.7554\n",
      "Epoch 105/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5145 - acc: 0.7453\n",
      "Epoch 106/150\n",
      "691/691 [==============================] - 0s 178us/step - loss: 0.5220 - acc: 0.7554\n",
      "Epoch 107/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5201 - acc: 0.7496\n",
      "Epoch 108/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5257 - acc: 0.7540\n",
      "Epoch 109/150\n",
      "691/691 [==============================] - 0s 178us/step - loss: 0.5057 - acc: 0.7598\n",
      "Epoch 110/150\n",
      "691/691 [==============================] - 0s 192us/step - loss: 0.5120 - acc: 0.7540\n",
      "Epoch 111/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.5240 - acc: 0.7410\n",
      "Epoch 112/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5124 - acc: 0.7641\n",
      "Epoch 113/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.5175 - acc: 0.7453\n",
      "Epoch 114/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.5039 - acc: 0.7685\n",
      "Epoch 115/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.5132 - acc: 0.7569\n",
      "Epoch 116/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.5021 - acc: 0.7598\n",
      "Epoch 117/150\n",
      "691/691 [==============================] - 0s 183us/step - loss: 0.5013 - acc: 0.7554\n",
      "Epoch 118/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5244 - acc: 0.7381\n",
      "Epoch 119/150\n",
      "691/691 [==============================] - 0s 178us/step - loss: 0.5017 - acc: 0.7569\n",
      "Epoch 120/150\n",
      "691/691 [==============================] - 0s 176us/step - loss: 0.5064 - acc: 0.7410\n",
      "Epoch 121/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.4997 - acc: 0.7598\n",
      "Epoch 122/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.5029 - acc: 0.7511\n",
      "Epoch 123/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.4937 - acc: 0.7685\n",
      "Epoch 124/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.5058 - acc: 0.7496\n",
      "Epoch 125/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.4948 - acc: 0.7554\n",
      "Epoch 126/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.4949 - acc: 0.7583\n",
      "Epoch 127/150\n",
      "691/691 [==============================] - 0s 180us/step - loss: 0.5054 - acc: 0.7525\n",
      "Epoch 128/150\n",
      "691/691 [==============================] - 0s 180us/step - loss: 0.4941 - acc: 0.7670\n",
      "Epoch 129/150\n",
      "691/691 [==============================] - 0s 165us/step - loss: 0.4955 - acc: 0.7598\n",
      "Epoch 130/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.5084 - acc: 0.7554\n",
      "Epoch 131/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.4874 - acc: 0.7757\n",
      "Epoch 132/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 0.5062 - acc: 0.7612\n",
      "Epoch 133/150\n",
      "691/691 [==============================] - 0s 164us/step - loss: 0.5051 - acc: 0.7583\n",
      "Epoch 134/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.4927 - acc: 0.7670\n",
      "Epoch 135/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.4878 - acc: 0.7699\n",
      "Epoch 136/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 165us/step - loss: 0.5005 - acc: 0.7612\n",
      "Epoch 137/150\n",
      "691/691 [==============================] - 0s 170us/step - loss: 0.4907 - acc: 0.7598\n",
      "Epoch 138/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.4929 - acc: 0.7713\n",
      "Epoch 139/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 0.4944 - acc: 0.7641\n",
      "Epoch 140/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.5024 - acc: 0.7511\n",
      "Epoch 141/150\n",
      "691/691 [==============================] - 0s 183us/step - loss: 0.4960 - acc: 0.7598\n",
      "Epoch 142/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 0.4954 - acc: 0.7569\n",
      "Epoch 143/150\n",
      "691/691 [==============================] - 0s 208us/step - loss: 0.4924 - acc: 0.7670\n",
      "Epoch 144/150\n",
      "691/691 [==============================] - 0s 249us/step - loss: 0.4905 - acc: 0.7612\n",
      "Epoch 145/150\n",
      "691/691 [==============================] - 0s 240us/step - loss: 0.4963 - acc: 0.7757\n",
      "Epoch 146/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.4839 - acc: 0.7670\n",
      "Epoch 147/150\n",
      "691/691 [==============================] - 0s 194us/step - loss: 0.4883 - acc: 0.7627\n",
      "Epoch 148/150\n",
      "691/691 [==============================] - 0s 210us/step - loss: 0.4927 - acc: 0.7670\n",
      "Epoch 149/150\n",
      "691/691 [==============================] - 0s 198us/step - loss: 0.4866 - acc: 0.7641\n",
      "Epoch 150/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 0.4959 - acc: 0.7685\n",
      "acc: 70.13%\n",
      "Epoch 1/150\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.9882 - acc: 0.4964\n",
      "Epoch 2/150\n",
      "691/691 [==============================] - 0s 145us/step - loss: 0.6941 - acc: 0.6498\n",
      "Epoch 3/150\n",
      "691/691 [==============================] - 0s 160us/step - loss: 0.6844 - acc: 0.6512\n",
      "Epoch 4/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.6759 - acc: 0.6512\n",
      "Epoch 5/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 0.6712 - acc: 0.6512\n",
      "Epoch 6/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 0.6665 - acc: 0.6512\n",
      "Epoch 7/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.6622 - acc: 0.6512\n",
      "Epoch 8/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.6605 - acc: 0.6512\n",
      "Epoch 9/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.6552 - acc: 0.6512\n",
      "Epoch 10/150\n",
      "691/691 [==============================] - 0s 181us/step - loss: 0.6553 - acc: 0.6512\n",
      "Epoch 11/150\n",
      "691/691 [==============================] - 0s 192us/step - loss: 0.6542 - acc: 0.6512\n",
      "Epoch 12/150\n",
      "691/691 [==============================] - 0s 196us/step - loss: 0.6509 - acc: 0.6512\n",
      "Epoch 13/150\n",
      "691/691 [==============================] - 0s 192us/step - loss: 0.6501 - acc: 0.6512\n",
      "Epoch 14/150\n",
      "691/691 [==============================] - 0s 200us/step - loss: 0.6500 - acc: 0.6512\n",
      "Epoch 15/150\n",
      "691/691 [==============================] - 0s 256us/step - loss: 0.6481 - acc: 0.6512\n",
      "Epoch 16/150\n",
      "691/691 [==============================] - 0s 242us/step - loss: 0.6500 - acc: 0.6512\n",
      "Epoch 17/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.6449 - acc: 0.6512\n",
      "Epoch 18/150\n",
      "691/691 [==============================] - 0s 214us/step - loss: 0.6482 - acc: 0.6512\n",
      "Epoch 19/150\n",
      "691/691 [==============================] - 0s 215us/step - loss: 0.6462 - acc: 0.6512\n",
      "Epoch 20/150\n",
      "691/691 [==============================] - 0s 183us/step - loss: 0.6483 - acc: 0.6512\n",
      "Epoch 21/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.6449 - acc: 0.6512\n",
      "Epoch 22/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.6491 - acc: 0.6512\n",
      "Epoch 23/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 0.6445 - acc: 0.6512\n",
      "Epoch 24/150\n",
      "691/691 [==============================] - 0s 193us/step - loss: 0.6419 - acc: 0.6512\n",
      "Epoch 25/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.6435 - acc: 0.6512\n",
      "Epoch 26/150\n",
      "691/691 [==============================] - 0s 181us/step - loss: 0.6424 - acc: 0.6512\n",
      "Epoch 27/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 0.6428 - acc: 0.6512\n",
      "Epoch 28/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.6427 - acc: 0.6512\n",
      "Epoch 29/150\n",
      "691/691 [==============================] - 0s 256us/step - loss: 0.6420 - acc: 0.6512\n",
      "Epoch 30/150\n",
      "691/691 [==============================] - 0s 257us/step - loss: 0.6413 - acc: 0.6512\n",
      "Epoch 31/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.6426 - acc: 0.6512\n",
      "Epoch 32/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.6409 - acc: 0.6512\n",
      "Epoch 33/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.6428 - acc: 0.6512\n",
      "Epoch 34/150\n",
      "691/691 [==============================] - 0s 183us/step - loss: 0.6408 - acc: 0.6512\n",
      "Epoch 35/150\n",
      "691/691 [==============================] - 0s 180us/step - loss: 0.6411 - acc: 0.6512\n",
      "Epoch 36/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.6397 - acc: 0.6512\n",
      "Epoch 37/150\n",
      "691/691 [==============================] - 0s 176us/step - loss: 0.6406 - acc: 0.6512\n",
      "Epoch 38/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.6421 - acc: 0.6512\n",
      "Epoch 39/150\n",
      "691/691 [==============================] - 0s 178us/step - loss: 0.6430 - acc: 0.6512\n",
      "Epoch 40/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.6401 - acc: 0.6512\n",
      "Epoch 41/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.6406 - acc: 0.6512\n",
      "Epoch 42/150\n",
      "691/691 [==============================] - 0s 174us/step - loss: 0.6412 - acc: 0.6512\n",
      "Epoch 43/150\n",
      "691/691 [==============================] - 0s 178us/step - loss: 0.6401 - acc: 0.6512\n",
      "Epoch 44/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.6414 - acc: 0.6512\n",
      "Epoch 45/150\n",
      "691/691 [==============================] - 0s 173us/step - loss: 0.6398 - acc: 0.6512\n",
      "Epoch 46/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.6405 - acc: 0.6512\n",
      "Epoch 47/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.6393 - acc: 0.6512\n",
      "Epoch 48/150\n",
      "691/691 [==============================] - 0s 210us/step - loss: 0.6398 - acc: 0.6512\n",
      "Epoch 49/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.6404 - acc: 0.6512\n",
      "Epoch 50/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 0.6392 - acc: 0.6512\n",
      "Epoch 51/150\n",
      "691/691 [==============================] - 0s 228us/step - loss: 0.6377 - acc: 0.6512\n",
      "Epoch 52/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 0.6403 - acc: 0.6512\n",
      "Epoch 53/150\n",
      "691/691 [==============================] - 0s 237us/step - loss: 0.6373 - acc: 0.6512\n",
      "Epoch 54/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 0.6399 - acc: 0.6512\n",
      "Epoch 55/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 0.6340 - acc: 0.6512\n",
      "Epoch 56/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 0.6338 - acc: 0.6512\n",
      "Epoch 57/150\n",
      "691/691 [==============================] - 0s 214us/step - loss: 0.6390 - acc: 0.6512\n",
      "Epoch 58/150\n",
      "691/691 [==============================] - 0s 211us/step - loss: 0.6345 - acc: 0.6512\n",
      "Epoch 59/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 0.6352 - acc: 0.6512\n",
      "Epoch 60/150\n",
      "691/691 [==============================] - 0s 235us/step - loss: 0.6321 - acc: 0.6512\n",
      "Epoch 61/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 0.6370 - acc: 0.6512\n",
      "Epoch 62/150\n",
      "691/691 [==============================] - 0s 214us/step - loss: 0.6332 - acc: 0.6512\n",
      "Epoch 63/150\n",
      "691/691 [==============================] - 0s 230us/step - loss: 0.6336 - acc: 0.6512\n",
      "Epoch 64/150\n",
      "691/691 [==============================] - 0s 217us/step - loss: 0.6342 - acc: 0.6512\n",
      "Epoch 65/150\n",
      "691/691 [==============================] - 0s 222us/step - loss: 0.6329 - acc: 0.6512\n",
      "Epoch 66/150\n",
      "691/691 [==============================] - 0s 210us/step - loss: 0.6161 - acc: 0.6512\n",
      "Epoch 67/150\n",
      "691/691 [==============================] - 0s 196us/step - loss: 0.6202 - acc: 0.6512\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 187us/step - loss: 0.6101 - acc: 0.6512\n",
      "Epoch 69/150\n",
      "691/691 [==============================] - 0s 248us/step - loss: 0.6150 - acc: 0.6512\n",
      "Epoch 70/150\n",
      "691/691 [==============================] - 0s 279us/step - loss: 0.6122 - acc: 0.6512\n",
      "Epoch 71/150\n",
      "691/691 [==============================] - 0s 289us/step - loss: 0.6108 - acc: 0.6512\n",
      "Epoch 72/150\n",
      "691/691 [==============================] - 0s 258us/step - loss: 0.6098 - acc: 0.6512\n",
      "Epoch 73/150\n",
      "691/691 [==============================] - 0s 220us/step - loss: 0.6080 - acc: 0.6512\n",
      "Epoch 74/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 0.6047 - acc: 0.6512\n",
      "Epoch 75/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 0.6075 - acc: 0.6512\n",
      "Epoch 76/150\n",
      "691/691 [==============================] - 0s 217us/step - loss: 0.6120 - acc: 0.6512\n",
      "Epoch 77/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.6072 - acc: 0.6512\n",
      "Epoch 78/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 0.6023 - acc: 0.6512\n",
      "Epoch 79/150\n",
      "691/691 [==============================] - 0s 214us/step - loss: 0.6008 - acc: 0.6512\n",
      "Epoch 80/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 0.6074 - acc: 0.6512\n",
      "Epoch 81/150\n",
      "691/691 [==============================] - 0s 329us/step - loss: 0.6047 - acc: 0.6512\n",
      "Epoch 82/150\n",
      "691/691 [==============================] - 0s 315us/step - loss: 0.6067 - acc: 0.6512\n",
      "Epoch 83/150\n",
      "691/691 [==============================] - 0s 266us/step - loss: 0.5969 - acc: 0.6512\n",
      "Epoch 84/150\n",
      "691/691 [==============================] - 0s 216us/step - loss: 0.6016 - acc: 0.6512\n",
      "Epoch 85/150\n",
      "691/691 [==============================] - 0s 220us/step - loss: 0.6047 - acc: 0.6512\n",
      "Epoch 86/150\n",
      "691/691 [==============================] - 0s 202us/step - loss: 0.5984 - acc: 0.6512\n",
      "Epoch 87/150\n",
      "691/691 [==============================] - 0s 241us/step - loss: 0.5946 - acc: 0.6512\n",
      "Epoch 88/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.5914 - acc: 0.6512\n",
      "Epoch 89/150\n",
      "691/691 [==============================] - 0s 224us/step - loss: 0.5981 - acc: 0.6512\n",
      "Epoch 90/150\n",
      "691/691 [==============================] - 0s 202us/step - loss: 0.5954 - acc: 0.6512\n",
      "Epoch 91/150\n",
      "691/691 [==============================] - 0s 217us/step - loss: 0.5905 - acc: 0.6512\n",
      "Epoch 92/150\n",
      "691/691 [==============================] - 0s 206us/step - loss: 0.5822 - acc: 0.6512\n",
      "Epoch 93/150\n",
      "691/691 [==============================] - 0s 200us/step - loss: 0.5987 - acc: 0.6512\n",
      "Epoch 94/150\n",
      "691/691 [==============================] - 0s 215us/step - loss: 0.5910 - acc: 0.6512\n",
      "Epoch 95/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 0.5868 - acc: 0.6512\n",
      "Epoch 96/150\n",
      "691/691 [==============================] - 0s 223us/step - loss: 0.5911 - acc: 0.6512\n",
      "Epoch 97/150\n",
      "691/691 [==============================] - 0s 209us/step - loss: 0.5903 - acc: 0.6512\n",
      "Epoch 98/150\n",
      "691/691 [==============================] - 0s 217us/step - loss: 0.5859 - acc: 0.6512\n",
      "Epoch 99/150\n",
      "691/691 [==============================] - 0s 211us/step - loss: 0.5829 - acc: 0.6512\n",
      "Epoch 100/150\n",
      "691/691 [==============================] - 0s 274us/step - loss: 0.5854 - acc: 0.6512\n",
      "Epoch 101/150\n",
      "691/691 [==============================] - 0s 272us/step - loss: 0.5828 - acc: 0.6512\n",
      "Epoch 102/150\n",
      "691/691 [==============================] - 0s 271us/step - loss: 0.5911 - acc: 0.6512\n",
      "Epoch 103/150\n",
      "691/691 [==============================] - 0s 204us/step - loss: 0.5849 - acc: 0.6512\n",
      "Epoch 104/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.5902 - acc: 0.6512\n",
      "Epoch 105/150\n",
      "691/691 [==============================] - 0s 204us/step - loss: 0.5884 - acc: 0.6512\n",
      "Epoch 106/150\n",
      "691/691 [==============================] - 0s 225us/step - loss: 0.5850 - acc: 0.6512\n",
      "Epoch 107/150\n",
      "691/691 [==============================] - 0s 224us/step - loss: 0.5809 - acc: 0.6512\n",
      "Epoch 108/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 0.5872 - acc: 0.6512\n",
      "Epoch 109/150\n",
      "691/691 [==============================] - 0s 196us/step - loss: 0.5826 - acc: 0.6512\n",
      "Epoch 110/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.5826 - acc: 0.6512\n",
      "Epoch 111/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 0.5807 - acc: 0.6512\n",
      "Epoch 112/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.5822 - acc: 0.6512\n",
      "Epoch 113/150\n",
      "691/691 [==============================] - 0s 218us/step - loss: 0.5792 - acc: 0.6512\n",
      "Epoch 114/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.5787 - acc: 0.6512\n",
      "Epoch 115/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5830 - acc: 0.6512\n",
      "Epoch 116/150\n",
      "691/691 [==============================] - 0s 193us/step - loss: 0.5824 - acc: 0.6512\n",
      "Epoch 117/150\n",
      "691/691 [==============================] - 0s 193us/step - loss: 0.5803 - acc: 0.6512\n",
      "Epoch 118/150\n",
      "691/691 [==============================] - 0s 201us/step - loss: 0.5797 - acc: 0.6512\n",
      "Epoch 119/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.5814 - acc: 0.6512\n",
      "Epoch 120/150\n",
      "691/691 [==============================] - 0s 210us/step - loss: 0.5777 - acc: 0.6512\n",
      "Epoch 121/150\n",
      "691/691 [==============================] - 0s 194us/step - loss: 0.5842 - acc: 0.6512\n",
      "Epoch 122/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 0.5794 - acc: 0.6512\n",
      "Epoch 123/150\n",
      "691/691 [==============================] - 0s 199us/step - loss: 0.5822 - acc: 0.6512\n",
      "Epoch 124/150\n",
      "691/691 [==============================] - 0s 238us/step - loss: 0.5768 - acc: 0.6512\n",
      "Epoch 125/150\n",
      "691/691 [==============================] - 0s 254us/step - loss: 0.5760 - acc: 0.6512\n",
      "Epoch 126/150\n",
      "691/691 [==============================] - 0s 218us/step - loss: 0.5845 - acc: 0.6512\n",
      "Epoch 127/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 0.5772 - acc: 0.6512\n",
      "Epoch 128/150\n",
      "691/691 [==============================] - 0s 229us/step - loss: 0.5871 - acc: 0.6512\n",
      "Epoch 129/150\n",
      "691/691 [==============================] - 0s 209us/step - loss: 0.5821 - acc: 0.6512\n",
      "Epoch 130/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 0.5807 - acc: 0.6512\n",
      "Epoch 131/150\n",
      "691/691 [==============================] - 0s 200us/step - loss: 0.5792 - acc: 0.6512\n",
      "Epoch 132/150\n",
      "691/691 [==============================] - 0s 204us/step - loss: 0.5775 - acc: 0.6512\n",
      "Epoch 133/150\n",
      "691/691 [==============================] - 0s 203us/step - loss: 0.5826 - acc: 0.6512\n",
      "Epoch 134/150\n",
      "691/691 [==============================] - 0s 240us/step - loss: 0.5767 - acc: 0.6512\n",
      "Epoch 135/150\n",
      "691/691 [==============================] - 0s 201us/step - loss: 0.5750 - acc: 0.6512\n",
      "Epoch 136/150\n",
      "691/691 [==============================] - 0s 198us/step - loss: 0.5794 - acc: 0.6512\n",
      "Epoch 137/150\n",
      "691/691 [==============================] - 0s 190us/step - loss: 0.5761 - acc: 0.6512\n",
      "Epoch 138/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 0.5791 - acc: 0.6512\n",
      "Epoch 139/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 0.5756 - acc: 0.6469\n",
      "Epoch 140/150\n",
      "691/691 [==============================] - 0s 202us/step - loss: 0.5775 - acc: 0.6686\n",
      "Epoch 141/150\n",
      "691/691 [==============================] - 0s 263us/step - loss: 0.5739 - acc: 0.6918\n",
      "Epoch 142/150\n",
      "691/691 [==============================] - 0s 194us/step - loss: 0.5766 - acc: 0.6961\n",
      "Epoch 143/150\n",
      "691/691 [==============================] - 0s 194us/step - loss: 0.5767 - acc: 0.6845\n",
      "Epoch 144/150\n",
      "691/691 [==============================] - 0s 208us/step - loss: 0.5738 - acc: 0.7048\n",
      "Epoch 145/150\n",
      "691/691 [==============================] - 0s 236us/step - loss: 0.5854 - acc: 0.6874\n",
      "Epoch 146/150\n",
      "691/691 [==============================] - 0s 249us/step - loss: 0.5761 - acc: 0.6961\n",
      "Epoch 147/150\n",
      "691/691 [==============================] - 0s 196us/step - loss: 0.5739 - acc: 0.6889\n",
      "Epoch 148/150\n",
      "691/691 [==============================] - 0s 202us/step - loss: 0.5780 - acc: 0.6860\n",
      "Epoch 149/150\n",
      "691/691 [==============================] - 0s 216us/step - loss: 0.5767 - acc: 0.6918\n",
      "Epoch 150/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 210us/step - loss: 0.5730 - acc: 0.6961\n",
      "acc: 68.83%\n",
      "Epoch 1/150\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 5.2166 - acc: 0.6295\n",
      "Epoch 2/150\n",
      "691/691 [==============================] - 0s 168us/step - loss: 3.4441 - acc: 0.5890\n",
      "Epoch 3/150\n",
      "691/691 [==============================] - 0s 172us/step - loss: 1.1393 - acc: 0.5253\n",
      "Epoch 4/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.7467 - acc: 0.5181\n",
      "Epoch 5/150\n",
      "691/691 [==============================] - 0s 181us/step - loss: 0.6797 - acc: 0.5962\n",
      "Epoch 6/150\n",
      "691/691 [==============================] - 0s 193us/step - loss: 0.6598 - acc: 0.6324\n",
      "Epoch 7/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.6485 - acc: 0.6339\n",
      "Epoch 8/150\n",
      "691/691 [==============================] - 0s 198us/step - loss: 0.6406 - acc: 0.6686\n",
      "Epoch 9/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.6307 - acc: 0.6860\n",
      "Epoch 10/150\n",
      "691/691 [==============================] - 0s 190us/step - loss: 0.6230 - acc: 0.6831\n",
      "Epoch 11/150\n",
      "691/691 [==============================] - 0s 193us/step - loss: 0.6217 - acc: 0.6831\n",
      "Epoch 12/150\n",
      "691/691 [==============================] - 0s 191us/step - loss: 0.6128 - acc: 0.6744\n",
      "Epoch 13/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.6061 - acc: 0.6932\n",
      "Epoch 14/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.5959 - acc: 0.6946\n",
      "Epoch 15/150\n",
      "691/691 [==============================] - 0s 201us/step - loss: 0.5914 - acc: 0.6946\n",
      "Epoch 16/150\n",
      "691/691 [==============================] - 0s 198us/step - loss: 0.5871 - acc: 0.7004\n",
      "Epoch 17/150\n",
      "691/691 [==============================] - 0s 190us/step - loss: 0.5874 - acc: 0.6975\n",
      "Epoch 18/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5784 - acc: 0.6946\n",
      "Epoch 19/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.5867 - acc: 0.7062\n",
      "Epoch 20/150\n",
      "691/691 [==============================] - 0s 181us/step - loss: 0.5784 - acc: 0.7062 0s - loss: 0.5775 - acc: 0.715\n",
      "Epoch 21/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 0.5738 - acc: 0.7062\n",
      "Epoch 22/150\n",
      "691/691 [==============================] - 0s 200us/step - loss: 0.5773 - acc: 0.7004\n",
      "Epoch 23/150\n",
      "691/691 [==============================] - 0s 201us/step - loss: 0.5683 - acc: 0.7077\n",
      "Epoch 24/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.5667 - acc: 0.7062\n",
      "Epoch 25/150\n",
      "691/691 [==============================] - 0s 187us/step - loss: 0.5619 - acc: 0.7192\n",
      "Epoch 26/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5572 - acc: 0.7135\n",
      "Epoch 27/150\n",
      "691/691 [==============================] - 0s 184us/step - loss: 0.5677 - acc: 0.7077 0s - loss: 0.5680 - acc: 0.70\n",
      "Epoch 28/150\n",
      "691/691 [==============================] - 0s 199us/step - loss: 0.5595 - acc: 0.7207\n",
      "Epoch 29/150\n",
      "691/691 [==============================] - 0s 192us/step - loss: 0.5553 - acc: 0.7062\n",
      "Epoch 30/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5607 - acc: 0.7178\n",
      "Epoch 31/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 0.5489 - acc: 0.7323\n",
      "Epoch 32/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 0.5557 - acc: 0.7135\n",
      "Epoch 33/150\n",
      "691/691 [==============================] - 0s 196us/step - loss: 0.5589 - acc: 0.7120\n",
      "Epoch 34/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.5515 - acc: 0.7062\n",
      "Epoch 35/150\n",
      "691/691 [==============================] - 0s 183us/step - loss: 0.5505 - acc: 0.7337\n",
      "Epoch 36/150\n",
      "691/691 [==============================] - 0s 185us/step - loss: 0.5472 - acc: 0.7106\n",
      "Epoch 37/150\n",
      "691/691 [==============================] - 0s 200us/step - loss: 0.5456 - acc: 0.7308\n",
      "Epoch 38/150\n",
      "691/691 [==============================] - 0s 312us/step - loss: 0.5405 - acc: 0.7120\n",
      "Epoch 39/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.5417 - acc: 0.7467\n",
      "Epoch 40/150\n",
      "691/691 [==============================] - 0s 189us/step - loss: 0.5458 - acc: 0.7352\n",
      "Epoch 41/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.5436 - acc: 0.7207\n",
      "Epoch 42/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 0.5450 - acc: 0.7410\n",
      "Epoch 43/150\n",
      "691/691 [==============================] - 0s 191us/step - loss: 0.5330 - acc: 0.7337\n",
      "Epoch 44/150\n",
      "691/691 [==============================] - 0s 206us/step - loss: 0.5429 - acc: 0.7279\n",
      "Epoch 45/150\n",
      "691/691 [==============================] - 0s 213us/step - loss: 0.5431 - acc: 0.7308\n",
      "Epoch 46/150\n",
      "691/691 [==============================] - 0s 294us/step - loss: 0.5310 - acc: 0.7395\n",
      "Epoch 47/150\n",
      "691/691 [==============================] - 0s 202us/step - loss: 0.5353 - acc: 0.7164\n",
      "Epoch 48/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 0.5298 - acc: 0.7352\n",
      "Epoch 49/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 0.5341 - acc: 0.7221\n",
      "Epoch 50/150\n",
      "691/691 [==============================] - 0s 180us/step - loss: 0.5264 - acc: 0.7410\n",
      "Epoch 51/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5477 - acc: 0.7294\n",
      "Epoch 52/150\n",
      "691/691 [==============================] - 0s 182us/step - loss: 0.5296 - acc: 0.7308\n",
      "Epoch 53/150\n",
      "691/691 [==============================] - 0s 192us/step - loss: 0.5327 - acc: 0.7352\n",
      "Epoch 54/150\n",
      "691/691 [==============================] - 0s 185us/step - loss: 0.5382 - acc: 0.7207\n",
      "Epoch 55/150\n",
      "691/691 [==============================] - 0s 188us/step - loss: 0.5253 - acc: 0.7352\n",
      "Epoch 56/150\n",
      "691/691 [==============================] - 0s 190us/step - loss: 0.5259 - acc: 0.7279\n",
      "Epoch 57/150\n",
      "691/691 [==============================] - 0s 288us/step - loss: 0.5233 - acc: 0.7366\n",
      "Epoch 58/150\n",
      "691/691 [==============================] - 0s 236us/step - loss: 0.5356 - acc: 0.7352\n",
      "Epoch 59/150\n",
      "691/691 [==============================] - 0s 190us/step - loss: 0.5198 - acc: 0.7554\n",
      "Epoch 60/150\n",
      "691/691 [==============================] - 0s 212us/step - loss: 0.5223 - acc: 0.7453\n",
      "Epoch 61/150\n",
      "691/691 [==============================] - 0s 201us/step - loss: 0.5211 - acc: 0.7511\n",
      "Epoch 62/150\n",
      "691/691 [==============================] - 0s 178us/step - loss: 0.5189 - acc: 0.7467\n",
      "Epoch 63/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 0.5214 - acc: 0.7424\n",
      "Epoch 64/150\n",
      "691/691 [==============================] - 0s 315us/step - loss: 0.5189 - acc: 0.7294\n",
      "Epoch 65/150\n",
      "691/691 [==============================] - 0s 210us/step - loss: 0.5188 - acc: 0.7381\n",
      "Epoch 66/150\n",
      "691/691 [==============================] - 0s 192us/step - loss: 0.5223 - acc: 0.7612\n",
      "Epoch 67/150\n",
      "691/691 [==============================] - 0s 195us/step - loss: 0.5232 - acc: 0.7294\n",
      "Epoch 68/150\n",
      "691/691 [==============================] - 0s 267us/step - loss: 0.5209 - acc: 0.7453\n",
      "Epoch 69/150\n",
      "691/691 [==============================] - 0s 205us/step - loss: 0.5187 - acc: 0.7308\n",
      "Epoch 70/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5215 - acc: 0.7381\n",
      "Epoch 71/150\n",
      "691/691 [==============================] - 0s 197us/step - loss: 0.5154 - acc: 0.7438\n",
      "Epoch 72/150\n",
      "691/691 [==============================] - 0s 203us/step - loss: 0.5243 - acc: 0.7221\n",
      "Epoch 73/150\n",
      "691/691 [==============================] - 0s 342us/step - loss: 0.5187 - acc: 0.7308\n",
      "Epoch 74/150\n",
      "691/691 [==============================] - 0s 193us/step - loss: 0.5190 - acc: 0.7511\n",
      "Epoch 75/150\n",
      "691/691 [==============================] - 0s 199us/step - loss: 0.5170 - acc: 0.7496\n",
      "Epoch 76/150\n",
      "691/691 [==============================] - 0s 191us/step - loss: 0.5295 - acc: 0.7265\n",
      "Epoch 77/150\n",
      "691/691 [==============================] - 0s 202us/step - loss: 0.5162 - acc: 0.7410\n",
      "Epoch 78/150\n",
      "691/691 [==============================] - 0s 188us/step - loss: 0.5132 - acc: 0.7496\n",
      "Epoch 79/150\n",
      "691/691 [==============================] - 0s 180us/step - loss: 0.5166 - acc: 0.7453\n",
      "Epoch 80/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5207 - acc: 0.7482\n",
      "Epoch 81/150\n",
      "691/691 [==============================] - 0s 186us/step - loss: 0.5220 - acc: 0.7453\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 188us/step - loss: 0.5108 - acc: 0.7496\n",
      "Epoch 83/150\n",
      "691/691 [==============================] - 0s 190us/step - loss: 0.5100 - acc: 0.7438\n",
      "Epoch 84/150\n",
      "691/691 [==============================] - 0s 207us/step - loss: 0.5087 - acc: 0.7467\n",
      "Epoch 85/150\n",
      "691/691 [==============================] - 0s 243us/step - loss: 0.5081 - acc: 0.7482\n",
      "Epoch 86/150\n",
      "691/691 [==============================] - 0s 240us/step - loss: 0.5098 - acc: 0.7410\n",
      "Epoch 87/150\n",
      "691/691 [==============================] - 0s 188us/step - loss: 0.5164 - acc: 0.7366\n",
      "Epoch 88/150\n",
      "691/691 [==============================] - 0s 138us/step - loss: 0.5168 - acc: 0.7467\n",
      "Epoch 89/150\n",
      "691/691 [==============================] - 0s 132us/step - loss: 0.5079 - acc: 0.7424\n",
      "Epoch 90/150\n",
      "691/691 [==============================] - 0s 126us/step - loss: 0.5175 - acc: 0.7482\n",
      "Epoch 91/150\n",
      "691/691 [==============================] - 0s 126us/step - loss: 0.5105 - acc: 0.7337\n",
      "Epoch 92/150\n",
      "691/691 [==============================] - 0s 128us/step - loss: 0.5114 - acc: 0.7438\n",
      "Epoch 93/150\n",
      "691/691 [==============================] - 0s 134us/step - loss: 0.5065 - acc: 0.7540\n",
      "Epoch 94/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.5006 - acc: 0.7540\n",
      "Epoch 95/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.5075 - acc: 0.7395\n",
      "Epoch 96/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.5039 - acc: 0.7410\n",
      "Epoch 97/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.5106 - acc: 0.7467\n",
      "Epoch 98/150\n",
      "691/691 [==============================] - 0s 128us/step - loss: 0.5030 - acc: 0.7496\n",
      "Epoch 99/150\n",
      "691/691 [==============================] - 0s 123us/step - loss: 0.5140 - acc: 0.7453\n",
      "Epoch 100/150\n",
      "691/691 [==============================] - 0s 124us/step - loss: 0.5164 - acc: 0.7540\n",
      "Epoch 101/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.5036 - acc: 0.7438\n",
      "Epoch 102/150\n",
      "691/691 [==============================] - 0s 123us/step - loss: 0.5118 - acc: 0.7366\n",
      "Epoch 103/150\n",
      "691/691 [==============================] - 0s 122us/step - loss: 0.5119 - acc: 0.7381\n",
      "Epoch 104/150\n",
      "691/691 [==============================] - 0s 134us/step - loss: 0.5079 - acc: 0.7598\n",
      "Epoch 105/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.4983 - acc: 0.7453\n",
      "Epoch 106/150\n",
      "691/691 [==============================] - 0s 122us/step - loss: 0.5050 - acc: 0.7554\n",
      "Epoch 107/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.5197 - acc: 0.7467\n",
      "Epoch 108/150\n",
      "691/691 [==============================] - 0s 120us/step - loss: 0.4992 - acc: 0.7467\n",
      "Epoch 109/150\n",
      "691/691 [==============================] - 0s 113us/step - loss: 0.5147 - acc: 0.7366\n",
      "Epoch 110/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.4966 - acc: 0.7511\n",
      "Epoch 111/150\n",
      "691/691 [==============================] - 0s 113us/step - loss: 0.4983 - acc: 0.7511\n",
      "Epoch 112/150\n",
      "691/691 [==============================] - 0s 115us/step - loss: 0.4959 - acc: 0.7453\n",
      "Epoch 113/150\n",
      "691/691 [==============================] - 0s 114us/step - loss: 0.4964 - acc: 0.7583\n",
      "Epoch 114/150\n",
      "691/691 [==============================] - 0s 111us/step - loss: 0.5034 - acc: 0.7482\n",
      "Epoch 115/150\n",
      "691/691 [==============================] - 0s 113us/step - loss: 0.4957 - acc: 0.7496\n",
      "Epoch 116/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.4972 - acc: 0.7583\n",
      "Epoch 117/150\n",
      "691/691 [==============================] - 0s 128us/step - loss: 0.4960 - acc: 0.7496\n",
      "Epoch 118/150\n",
      "691/691 [==============================] - 0s 167us/step - loss: 0.5004 - acc: 0.7554\n",
      "Epoch 119/150\n",
      "691/691 [==============================] - 0s 169us/step - loss: 0.4988 - acc: 0.7685\n",
      "Epoch 120/150\n",
      "691/691 [==============================] - 0s 134us/step - loss: 0.5034 - acc: 0.7395\n",
      "Epoch 121/150\n",
      "691/691 [==============================] - 0s 134us/step - loss: 0.4934 - acc: 0.7496\n",
      "Epoch 122/150\n",
      "691/691 [==============================] - 0s 127us/step - loss: 0.5011 - acc: 0.7453\n",
      "Epoch 123/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.4940 - acc: 0.7583\n",
      "Epoch 124/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.4967 - acc: 0.7511\n",
      "Epoch 125/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.4907 - acc: 0.7511\n",
      "Epoch 126/150\n",
      "691/691 [==============================] - 0s 131us/step - loss: 0.5126 - acc: 0.7438\n",
      "Epoch 127/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.4926 - acc: 0.7395\n",
      "Epoch 128/150\n",
      "691/691 [==============================] - 0s 137us/step - loss: 0.4894 - acc: 0.7583\n",
      "Epoch 129/150\n",
      "691/691 [==============================] - 0s 137us/step - loss: 0.4931 - acc: 0.7525\n",
      "Epoch 130/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.4986 - acc: 0.7482\n",
      "Epoch 131/150\n",
      "691/691 [==============================] - 0s 137us/step - loss: 0.4852 - acc: 0.7569\n",
      "Epoch 132/150\n",
      "691/691 [==============================] - 0s 134us/step - loss: 0.4859 - acc: 0.7656\n",
      "Epoch 133/150\n",
      "691/691 [==============================] - 0s 123us/step - loss: 0.4984 - acc: 0.7453\n",
      "Epoch 134/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.5066 - acc: 0.7525\n",
      "Epoch 135/150\n",
      "691/691 [==============================] - 0s 113us/step - loss: 0.4956 - acc: 0.7612\n",
      "Epoch 136/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.4876 - acc: 0.7583\n",
      "Epoch 137/150\n",
      "691/691 [==============================] - 0s 113us/step - loss: 0.4915 - acc: 0.7496\n",
      "Epoch 138/150\n",
      "691/691 [==============================] - 0s 119us/step - loss: 0.4877 - acc: 0.7540\n",
      "Epoch 139/150\n",
      "691/691 [==============================] - 0s 120us/step - loss: 0.4889 - acc: 0.7583\n",
      "Epoch 140/150\n",
      "691/691 [==============================] - 0s 133us/step - loss: 0.5025 - acc: 0.7410\n",
      "Epoch 141/150\n",
      "691/691 [==============================] - 0s 132us/step - loss: 0.4846 - acc: 0.7569\n",
      "Epoch 142/150\n",
      "691/691 [==============================] - 0s 127us/step - loss: 0.4830 - acc: 0.7569\n",
      "Epoch 143/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.4887 - acc: 0.7641\n",
      "Epoch 144/150\n",
      "691/691 [==============================] - 0s 123us/step - loss: 0.4827 - acc: 0.7554\n",
      "Epoch 145/150\n",
      "691/691 [==============================] - 0s 123us/step - loss: 0.4975 - acc: 0.7496\n",
      "Epoch 146/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.4992 - acc: 0.7641\n",
      "Epoch 147/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.4813 - acc: 0.7699\n",
      "Epoch 148/150\n",
      "691/691 [==============================] - 0s 177us/step - loss: 0.4812 - acc: 0.7583\n",
      "Epoch 149/150\n",
      "691/691 [==============================] - 0s 142us/step - loss: 0.4940 - acc: 0.7511\n",
      "Epoch 150/150\n",
      "691/691 [==============================] - 0s 128us/step - loss: 0.4953 - acc: 0.7438\n",
      "acc: 70.13%\n",
      "Epoch 1/150\n",
      "691/691 [==============================] - 1s 2ms/step - loss: 5.1615 - acc: 0.3835\n",
      "Epoch 2/150\n",
      "691/691 [==============================] - 0s 115us/step - loss: 1.4415 - acc: 0.5109\n",
      "Epoch 3/150\n",
      "691/691 [==============================] - 0s 123us/step - loss: 1.0601 - acc: 0.5832\n",
      "Epoch 4/150\n",
      "691/691 [==============================] - 0s 123us/step - loss: 0.9026 - acc: 0.6179\n",
      "Epoch 5/150\n",
      "691/691 [==============================] - 0s 119us/step - loss: 0.8162 - acc: 0.6194\n",
      "Epoch 6/150\n",
      "691/691 [==============================] - 0s 131us/step - loss: 0.7399 - acc: 0.6483\n",
      "Epoch 7/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.6961 - acc: 0.6295\n",
      "Epoch 8/150\n",
      "691/691 [==============================] - 0s 124us/step - loss: 0.6648 - acc: 0.6657\n",
      "Epoch 9/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.6602 - acc: 0.6440\n",
      "Epoch 10/150\n",
      "691/691 [==============================] - 0s 122us/step - loss: 0.6484 - acc: 0.6657\n",
      "Epoch 11/150\n",
      "691/691 [==============================] - 0s 123us/step - loss: 0.6337 - acc: 0.6816\n",
      "Epoch 12/150\n",
      "691/691 [==============================] - 0s 128us/step - loss: 0.6105 - acc: 0.6874\n",
      "Epoch 13/150\n",
      "691/691 [==============================] - 0s 125us/step - loss: 0.6163 - acc: 0.6599\n",
      "Epoch 14/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 120us/step - loss: 0.5995 - acc: 0.6889\n",
      "Epoch 15/150\n",
      "691/691 [==============================] - 0s 120us/step - loss: 0.6094 - acc: 0.6729\n",
      "Epoch 16/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.5983 - acc: 0.6845\n",
      "Epoch 17/150\n",
      "691/691 [==============================] - 0s 119us/step - loss: 0.5820 - acc: 0.7033\n",
      "Epoch 18/150\n",
      "691/691 [==============================] - 0s 126us/step - loss: 0.5920 - acc: 0.6874\n",
      "Epoch 19/150\n",
      "691/691 [==============================] - 0s 141us/step - loss: 0.5740 - acc: 0.7106\n",
      "Epoch 20/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.5855 - acc: 0.6932\n",
      "Epoch 21/150\n",
      "691/691 [==============================] - 0s 115us/step - loss: 0.5714 - acc: 0.7106\n",
      "Epoch 22/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.5796 - acc: 0.7135\n",
      "Epoch 23/150\n",
      "691/691 [==============================] - 0s 113us/step - loss: 0.5764 - acc: 0.7033\n",
      "Epoch 24/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.5683 - acc: 0.7048\n",
      "Epoch 25/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.5553 - acc: 0.7250\n",
      "Epoch 26/150\n",
      "691/691 [==============================] - 0s 112us/step - loss: 0.5711 - acc: 0.6961\n",
      "Epoch 27/150\n",
      "691/691 [==============================] - 0s 113us/step - loss: 0.5600 - acc: 0.7149\n",
      "Epoch 28/150\n",
      "691/691 [==============================] - 0s 112us/step - loss: 0.5503 - acc: 0.7149\n",
      "Epoch 29/150\n",
      "691/691 [==============================] - 0s 135us/step - loss: 0.5463 - acc: 0.7192\n",
      "Epoch 30/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.5459 - acc: 0.7221\n",
      "Epoch 31/150\n",
      "691/691 [==============================] - 0s 131us/step - loss: 0.5472 - acc: 0.7250\n",
      "Epoch 32/150\n",
      "691/691 [==============================] - 0s 131us/step - loss: 0.5508 - acc: 0.7149\n",
      "Epoch 33/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.5521 - acc: 0.7106\n",
      "Epoch 34/150\n",
      "691/691 [==============================] - 0s 114us/step - loss: 0.5482 - acc: 0.7207\n",
      "Epoch 35/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.5479 - acc: 0.7250\n",
      "Epoch 36/150\n",
      "691/691 [==============================] - 0s 144us/step - loss: 0.5423 - acc: 0.7149\n",
      "Epoch 37/150\n",
      "691/691 [==============================] - 0s 141us/step - loss: 0.5489 - acc: 0.7135\n",
      "Epoch 38/150\n",
      "691/691 [==============================] - 0s 137us/step - loss: 0.5369 - acc: 0.7308\n",
      "Epoch 39/150\n",
      "691/691 [==============================] - 0s 125us/step - loss: 0.5492 - acc: 0.7019\n",
      "Epoch 40/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.5435 - acc: 0.7250\n",
      "Epoch 41/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.5257 - acc: 0.7323\n",
      "Epoch 42/150\n",
      "691/691 [==============================] - 0s 115us/step - loss: 0.5318 - acc: 0.7192\n",
      "Epoch 43/150\n",
      "691/691 [==============================] - 0s 111us/step - loss: 0.5299 - acc: 0.7250\n",
      "Epoch 44/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.5319 - acc: 0.7221\n",
      "Epoch 45/150\n",
      "691/691 [==============================] - 0s 114us/step - loss: 0.5337 - acc: 0.7294\n",
      "Epoch 46/150\n",
      "691/691 [==============================] - 0s 115us/step - loss: 0.5420 - acc: 0.7236\n",
      "Epoch 47/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.5279 - acc: 0.7366\n",
      "Epoch 48/150\n",
      "691/691 [==============================] - 0s 111us/step - loss: 0.5292 - acc: 0.7323\n",
      "Epoch 49/150\n",
      "691/691 [==============================] - 0s 113us/step - loss: 0.5305 - acc: 0.7352\n",
      "Epoch 50/150\n",
      "691/691 [==============================] - 0s 115us/step - loss: 0.5246 - acc: 0.7279\n",
      "Epoch 51/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.5400 - acc: 0.7250\n",
      "Epoch 52/150\n",
      "691/691 [==============================] - 0s 113us/step - loss: 0.5282 - acc: 0.7395\n",
      "Epoch 53/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.5268 - acc: 0.7279\n",
      "Epoch 54/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.5416 - acc: 0.7106\n",
      "Epoch 55/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.5315 - acc: 0.7250\n",
      "Epoch 56/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.5167 - acc: 0.7366\n",
      "Epoch 57/150\n",
      "691/691 [==============================] - 0s 125us/step - loss: 0.5229 - acc: 0.7192\n",
      "Epoch 58/150\n",
      "691/691 [==============================] - 0s 128us/step - loss: 0.5254 - acc: 0.7366\n",
      "Epoch 59/150\n",
      "691/691 [==============================] - 0s 126us/step - loss: 0.5093 - acc: 0.7453\n",
      "Epoch 60/150\n",
      "691/691 [==============================] - 0s 123us/step - loss: 0.5069 - acc: 0.7424\n",
      "Epoch 61/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.5289 - acc: 0.7265\n",
      "Epoch 62/150\n",
      "691/691 [==============================] - 0s 127us/step - loss: 0.5152 - acc: 0.7294\n",
      "Epoch 63/150\n",
      "691/691 [==============================] - 0s 125us/step - loss: 0.5138 - acc: 0.7381\n",
      "Epoch 64/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.5135 - acc: 0.7496\n",
      "Epoch 65/150\n",
      "691/691 [==============================] - 0s 123us/step - loss: 0.5041 - acc: 0.7525\n",
      "Epoch 66/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.5072 - acc: 0.7467\n",
      "Epoch 67/150\n",
      "691/691 [==============================] - 0s 120us/step - loss: 0.5086 - acc: 0.7511\n",
      "Epoch 68/150\n",
      "691/691 [==============================] - 0s 128us/step - loss: 0.5070 - acc: 0.7352\n",
      "Epoch 69/150\n",
      "691/691 [==============================] - 0s 138us/step - loss: 0.5110 - acc: 0.7395\n",
      "Epoch 70/150\n",
      "691/691 [==============================] - 0s 139us/step - loss: 0.5034 - acc: 0.7511\n",
      "Epoch 71/150\n",
      "691/691 [==============================] - 0s 145us/step - loss: 0.5177 - acc: 0.7453\n",
      "Epoch 72/150\n",
      "691/691 [==============================] - 0s 131us/step - loss: 0.5119 - acc: 0.7496\n",
      "Epoch 73/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.5152 - acc: 0.7265\n",
      "Epoch 74/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.5203 - acc: 0.7250\n",
      "Epoch 75/150\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.4998 - acc: 0.745 - 0s 126us/step - loss: 0.5082 - acc: 0.7381\n",
      "Epoch 76/150\n",
      "691/691 [==============================] - 0s 119us/step - loss: 0.5051 - acc: 0.7511\n",
      "Epoch 77/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.5120 - acc: 0.7395\n",
      "Epoch 78/150\n",
      "691/691 [==============================] - 0s 113us/step - loss: 0.5062 - acc: 0.7323\n",
      "Epoch 79/150\n",
      "691/691 [==============================] - 0s 114us/step - loss: 0.5051 - acc: 0.7540\n",
      "Epoch 80/150\n",
      "691/691 [==============================] - 0s 115us/step - loss: 0.5127 - acc: 0.7395\n",
      "Epoch 81/150\n",
      "691/691 [==============================] - 0s 129us/step - loss: 0.5114 - acc: 0.7381\n",
      "Epoch 82/150\n",
      "691/691 [==============================] - 0s 133us/step - loss: 0.5067 - acc: 0.7395\n",
      "Epoch 83/150\n",
      "691/691 [==============================] - 0s 131us/step - loss: 0.5057 - acc: 0.7627\n",
      "Epoch 84/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.5008 - acc: 0.7467\n",
      "Epoch 85/150\n",
      "691/691 [==============================] - 0s 139us/step - loss: 0.4998 - acc: 0.7496\n",
      "Epoch 86/150\n",
      "691/691 [==============================] - 0s 146us/step - loss: 0.5184 - acc: 0.7395\n",
      "Epoch 87/150\n",
      "691/691 [==============================] - 0s 127us/step - loss: 0.5195 - acc: 0.7395\n",
      "Epoch 88/150\n",
      "691/691 [==============================] - 0s 129us/step - loss: 0.5032 - acc: 0.7467\n",
      "Epoch 89/150\n",
      "691/691 [==============================] - 0s 126us/step - loss: 0.4971 - acc: 0.7554\n",
      "Epoch 90/150\n",
      "691/691 [==============================] - 0s 126us/step - loss: 0.4969 - acc: 0.7641\n",
      "Epoch 91/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.4958 - acc: 0.7424\n",
      "Epoch 92/150\n",
      "691/691 [==============================] - 0s 134us/step - loss: 0.5040 - acc: 0.7438\n",
      "Epoch 93/150\n",
      "691/691 [==============================] - 0s 141us/step - loss: 0.4990 - acc: 0.7438\n",
      "Epoch 94/150\n",
      "691/691 [==============================] - 0s 125us/step - loss: 0.4939 - acc: 0.7641\n",
      "Epoch 95/150\n",
      "691/691 [==============================] - 0s 140us/step - loss: 0.4991 - acc: 0.7511\n",
      "Epoch 96/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 188us/step - loss: 0.4991 - acc: 0.7728\n",
      "Epoch 97/150\n",
      "691/691 [==============================] - 0s 126us/step - loss: 0.4944 - acc: 0.7728\n",
      "Epoch 98/150\n",
      "691/691 [==============================] - 0s 119us/step - loss: 0.4929 - acc: 0.7612\n",
      "Epoch 99/150\n",
      "691/691 [==============================] - 0s 129us/step - loss: 0.4977 - acc: 0.7540\n",
      "Epoch 100/150\n",
      "691/691 [==============================] - 0s 140us/step - loss: 0.4937 - acc: 0.7554\n",
      "Epoch 101/150\n",
      "691/691 [==============================] - 0s 136us/step - loss: 0.5012 - acc: 0.7453\n",
      "Epoch 102/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.4935 - acc: 0.7598\n",
      "Epoch 103/150\n",
      "691/691 [==============================] - 0s 120us/step - loss: 0.4866 - acc: 0.7627\n",
      "Epoch 104/150\n",
      "691/691 [==============================] - 0s 128us/step - loss: 0.5084 - acc: 0.7366\n",
      "Epoch 105/150\n",
      "691/691 [==============================] - 0s 126us/step - loss: 0.4991 - acc: 0.7612\n",
      "Epoch 106/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.5065 - acc: 0.7482\n",
      "Epoch 107/150\n",
      "691/691 [==============================] - 0s 130us/step - loss: 0.4972 - acc: 0.7496\n",
      "Epoch 108/150\n",
      "691/691 [==============================] - 0s 138us/step - loss: 0.4943 - acc: 0.7525\n",
      "Epoch 109/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.4946 - acc: 0.7656\n",
      "Epoch 110/150\n",
      "691/691 [==============================] - 0s 119us/step - loss: 0.4939 - acc: 0.7583\n",
      "Epoch 111/150\n",
      "691/691 [==============================] - 0s 162us/step - loss: 0.4910 - acc: 0.7482\n",
      "Epoch 112/150\n",
      "691/691 [==============================] - 0s 150us/step - loss: 0.4929 - acc: 0.7583\n",
      "Epoch 113/150\n",
      "691/691 [==============================] - 0s 147us/step - loss: 0.5002 - acc: 0.7554\n",
      "Epoch 114/150\n",
      "691/691 [==============================] - 0s 128us/step - loss: 0.5002 - acc: 0.7467\n",
      "Epoch 115/150\n",
      "691/691 [==============================] - 0s 130us/step - loss: 0.4876 - acc: 0.7757\n",
      "Epoch 116/150\n",
      "691/691 [==============================] - 0s 126us/step - loss: 0.4814 - acc: 0.7713\n",
      "Epoch 117/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.4786 - acc: 0.7685\n",
      "Epoch 118/150\n",
      "691/691 [==============================] - 0s 119us/step - loss: 0.4880 - acc: 0.7554\n",
      "Epoch 119/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.4930 - acc: 0.7670\n",
      "Epoch 120/150\n",
      "691/691 [==============================] - 0s 110us/step - loss: 0.4922 - acc: 0.7627\n",
      "Epoch 121/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.4818 - acc: 0.7656\n",
      "Epoch 122/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.4910 - acc: 0.7713\n",
      "Epoch 123/150\n",
      "691/691 [==============================] - 0s 112us/step - loss: 0.4818 - acc: 0.7728\n",
      "Epoch 124/150\n",
      "691/691 [==============================] - 0s 110us/step - loss: 0.4943 - acc: 0.7583\n",
      "Epoch 125/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.4834 - acc: 0.7771\n",
      "Epoch 126/150\n",
      "691/691 [==============================] - 0s 110us/step - loss: 0.4843 - acc: 0.7583\n",
      "Epoch 127/150\n",
      "691/691 [==============================] - 0s 138us/step - loss: 0.4886 - acc: 0.7627\n",
      "Epoch 128/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.4731 - acc: 0.7728\n",
      "Epoch 129/150\n",
      "691/691 [==============================] - 0s 126us/step - loss: 0.4775 - acc: 0.7685\n",
      "Epoch 130/150\n",
      "691/691 [==============================] - 0s 175us/step - loss: 0.4780 - acc: 0.7699\n",
      "Epoch 131/150\n",
      "691/691 [==============================] - 0s 128us/step - loss: 0.4767 - acc: 0.7699\n",
      "Epoch 132/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.4807 - acc: 0.7656\n",
      "Epoch 133/150\n",
      "691/691 [==============================] - 0s 128us/step - loss: 0.4756 - acc: 0.7815\n",
      "Epoch 134/150\n",
      "691/691 [==============================] - 0s 179us/step - loss: 0.4753 - acc: 0.7699\n",
      "Epoch 135/150\n",
      "691/691 [==============================] - 0s 117us/step - loss: 0.4772 - acc: 0.7685\n",
      "Epoch 136/150\n",
      "691/691 [==============================] - 0s 114us/step - loss: 0.4718 - acc: 0.7771\n",
      "Epoch 137/150\n",
      "691/691 [==============================] - 0s 127us/step - loss: 0.4670 - acc: 0.7829\n",
      "Epoch 138/150\n",
      "691/691 [==============================] - 0s 166us/step - loss: 0.4800 - acc: 0.7612\n",
      "Epoch 139/150\n",
      "691/691 [==============================] - 0s 148us/step - loss: 0.4782 - acc: 0.7569\n",
      "Epoch 140/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.4804 - acc: 0.7641\n",
      "Epoch 141/150\n",
      "691/691 [==============================] - 0s 116us/step - loss: 0.4650 - acc: 0.7844\n",
      "Epoch 142/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.4748 - acc: 0.7815\n",
      "Epoch 143/150\n",
      "691/691 [==============================] - 0s 125us/step - loss: 0.4698 - acc: 0.7815\n",
      "Epoch 144/150\n",
      "691/691 [==============================] - 0s 123us/step - loss: 0.4832 - acc: 0.7786\n",
      "Epoch 145/150\n",
      "691/691 [==============================] - 0s 119us/step - loss: 0.4671 - acc: 0.7771\n",
      "Epoch 146/150\n",
      "691/691 [==============================] - 0s 126us/step - loss: 0.4675 - acc: 0.7699\n",
      "Epoch 147/150\n",
      "691/691 [==============================] - 0s 119us/step - loss: 0.4838 - acc: 0.7728\n",
      "Epoch 148/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.4830 - acc: 0.7612\n",
      "Epoch 149/150\n",
      "691/691 [==============================] - 0s 121us/step - loss: 0.4807 - acc: 0.7786\n",
      "Epoch 150/150\n",
      "691/691 [==============================] - 0s 118us/step - loss: 0.4694 - acc: 0.7728\n",
      "acc: 70.13%\n",
      "Epoch 1/150\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 2.4817 - acc: 0.5737\n",
      "Epoch 2/150\n",
      "692/692 [==============================] - 0s 191us/step - loss: 1.7661 - acc: 0.5448\n",
      "Epoch 3/150\n",
      "692/692 [==============================] - 0s 193us/step - loss: 1.3092 - acc: 0.5405\n",
      "Epoch 4/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 1.1001 - acc: 0.5419\n",
      "Epoch 5/150\n",
      "692/692 [==============================] - 0s 128us/step - loss: 0.8604 - acc: 0.5766\n",
      "Epoch 6/150\n",
      "692/692 [==============================] - 0s 130us/step - loss: 0.7717 - acc: 0.5968\n",
      "Epoch 7/150\n",
      "692/692 [==============================] - 0s 128us/step - loss: 0.7836 - acc: 0.6127\n",
      "Epoch 8/150\n",
      "692/692 [==============================] - 0s 121us/step - loss: 0.7508 - acc: 0.6113\n",
      "Epoch 9/150\n",
      "692/692 [==============================] - 0s 122us/step - loss: 0.6938 - acc: 0.6228\n",
      "Epoch 10/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 0.6495 - acc: 0.6590\n",
      "Epoch 11/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 0.6985 - acc: 0.6257\n",
      "Epoch 12/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 0.6469 - acc: 0.6546\n",
      "Epoch 13/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 0.6371 - acc: 0.6763\n",
      "Epoch 14/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 0.6269 - acc: 0.6821\n",
      "Epoch 15/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 0.6159 - acc: 0.6850\n",
      "Epoch 16/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 0.6224 - acc: 0.6936\n",
      "Epoch 17/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 0.6369 - acc: 0.6835\n",
      "Epoch 18/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 0.6331 - acc: 0.6647\n",
      "Epoch 19/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 0.6992 - acc: 0.6329\n",
      "Epoch 20/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 0.6110 - acc: 0.6922\n",
      "Epoch 21/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 0.6504 - acc: 0.6488\n",
      "Epoch 22/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.6092 - acc: 0.6879\n",
      "Epoch 23/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 0.6412 - acc: 0.6618\n",
      "Epoch 24/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.5869 - acc: 0.6980\n",
      "Epoch 25/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 0.5843 - acc: 0.6922\n",
      "Epoch 26/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 0.5729 - acc: 0.7240\n",
      "Epoch 27/150\n",
      "692/692 [==============================] - 0s 196us/step - loss: 0.6087 - acc: 0.6980\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692/692 [==============================] - 0s 150us/step - loss: 0.6464 - acc: 0.6705\n",
      "Epoch 29/150\n",
      "692/692 [==============================] - 0s 173us/step - loss: 0.5991 - acc: 0.6879\n",
      "Epoch 30/150\n",
      "692/692 [==============================] - 0s 171us/step - loss: 0.5809 - acc: 0.7197\n",
      "Epoch 31/150\n",
      "692/692 [==============================] - 0s 167us/step - loss: 0.6218 - acc: 0.6980\n",
      "Epoch 32/150\n",
      "692/692 [==============================] - 0s 169us/step - loss: 0.6052 - acc: 0.6734\n",
      "Epoch 33/150\n",
      "692/692 [==============================] - 0s 139us/step - loss: 0.5816 - acc: 0.7052\n",
      "Epoch 34/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 0.5890 - acc: 0.7081\n",
      "Epoch 35/150\n",
      "692/692 [==============================] - 0s 135us/step - loss: 0.5876 - acc: 0.6908\n",
      "Epoch 36/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.5832 - acc: 0.7124\n",
      "Epoch 37/150\n",
      "692/692 [==============================] - 0s 140us/step - loss: 0.6038 - acc: 0.6893\n",
      "Epoch 38/150\n",
      "692/692 [==============================] - 0s 135us/step - loss: 0.6453 - acc: 0.6936\n",
      "Epoch 39/150\n",
      "692/692 [==============================] - 0s 140us/step - loss: 0.5879 - acc: 0.7110\n",
      "Epoch 40/150\n",
      "692/692 [==============================] - 0s 157us/step - loss: 0.5826 - acc: 0.7023\n",
      "Epoch 41/150\n",
      "692/692 [==============================] - 0s 143us/step - loss: 0.5591 - acc: 0.7413\n",
      "Epoch 42/150\n",
      "692/692 [==============================] - 0s 128us/step - loss: 0.5735 - acc: 0.7225\n",
      "Epoch 43/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 0.5506 - acc: 0.7168\n",
      "Epoch 44/150\n",
      "692/692 [==============================] - 0s 128us/step - loss: 0.5737 - acc: 0.7023\n",
      "Epoch 45/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 0.6162 - acc: 0.6835\n",
      "Epoch 46/150\n",
      "692/692 [==============================] - 0s 110us/step - loss: 0.6192 - acc: 0.6908\n",
      "Epoch 47/150\n",
      "692/692 [==============================] - 0s 112us/step - loss: 0.5613 - acc: 0.7182\n",
      "Epoch 48/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 0.5548 - acc: 0.7327\n",
      "Epoch 49/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 0.5628 - acc: 0.7312\n",
      "Epoch 50/150\n",
      "692/692 [==============================] - 0s 154us/step - loss: 0.5604 - acc: 0.7168\n",
      "Epoch 51/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 0.5491 - acc: 0.7384\n",
      "Epoch 52/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 0.5652 - acc: 0.7355\n",
      "Epoch 53/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 0.5620 - acc: 0.7182\n",
      "Epoch 54/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 0.5577 - acc: 0.7312\n",
      "Epoch 55/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 0.5889 - acc: 0.7038\n",
      "Epoch 56/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 0.5859 - acc: 0.7254\n",
      "Epoch 57/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 0.6483 - acc: 0.6850\n",
      "Epoch 58/150\n",
      "692/692 [==============================] - 0s 136us/step - loss: 0.5641 - acc: 0.7312\n",
      "Epoch 59/150\n",
      "692/692 [==============================] - 0s 128us/step - loss: 0.6021 - acc: 0.7038\n",
      "Epoch 60/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 0.5541 - acc: 0.7341\n",
      "Epoch 61/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 0.5675 - acc: 0.7341\n",
      "Epoch 62/150\n",
      "692/692 [==============================] - 0s 124us/step - loss: 0.5475 - acc: 0.7312\n",
      "Epoch 63/150\n",
      "692/692 [==============================] - 0s 126us/step - loss: 0.5598 - acc: 0.7182\n",
      "Epoch 64/150\n",
      "692/692 [==============================] - 0s 121us/step - loss: 0.5384 - acc: 0.7514\n",
      "Epoch 65/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.5452 - acc: 0.7283\n",
      "Epoch 66/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 0.5320 - acc: 0.7341\n",
      "Epoch 67/150\n",
      "692/692 [==============================] - 0s 201us/step - loss: 0.5334 - acc: 0.7312\n",
      "Epoch 68/150\n",
      "692/692 [==============================] - 0s 130us/step - loss: 0.5266 - acc: 0.7413\n",
      "Epoch 69/150\n",
      "692/692 [==============================] - 0s 126us/step - loss: 0.5607 - acc: 0.7182\n",
      "Epoch 70/150\n",
      "692/692 [==============================] - 0s 131us/step - loss: 0.5486 - acc: 0.7355\n",
      "Epoch 71/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 0.5326 - acc: 0.7384\n",
      "Epoch 72/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.5354 - acc: 0.7312\n",
      "Epoch 73/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 0.5257 - acc: 0.7601\n",
      "Epoch 74/150\n",
      "692/692 [==============================] - 0s 126us/step - loss: 0.5184 - acc: 0.7471\n",
      "Epoch 75/150\n",
      "692/692 [==============================] - 0s 129us/step - loss: 0.5567 - acc: 0.7240\n",
      "Epoch 76/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 0.5615 - acc: 0.7211\n",
      "Epoch 77/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 0.5657 - acc: 0.7413\n",
      "Epoch 78/150\n",
      "692/692 [==============================] - 0s 124us/step - loss: 0.5242 - acc: 0.7457\n",
      "Epoch 79/150\n",
      "692/692 [==============================] - 0s 220us/step - loss: 0.5735 - acc: 0.7066\n",
      "Epoch 80/150\n",
      "692/692 [==============================] - 0s 150us/step - loss: 0.6102 - acc: 0.7110\n",
      "Epoch 81/150\n",
      "692/692 [==============================] - 0s 206us/step - loss: 0.5166 - acc: 0.7500\n",
      "Epoch 82/150\n",
      "692/692 [==============================] - 0s 182us/step - loss: 0.5580 - acc: 0.7182\n",
      "Epoch 83/150\n",
      "692/692 [==============================] - 0s 138us/step - loss: 0.5143 - acc: 0.7616\n",
      "Epoch 84/150\n",
      "692/692 [==============================] - 0s 149us/step - loss: 0.5309 - acc: 0.7457\n",
      "Epoch 85/150\n",
      "692/692 [==============================] - 0s 153us/step - loss: 0.5235 - acc: 0.7486\n",
      "Epoch 86/150\n",
      "692/692 [==============================] - 0s 168us/step - loss: 0.5352 - acc: 0.7572\n",
      "Epoch 87/150\n",
      "692/692 [==============================] - 0s 137us/step - loss: 0.5292 - acc: 0.7428\n",
      "Epoch 88/150\n",
      "692/692 [==============================] - 0s 130us/step - loss: 0.5332 - acc: 0.7442\n",
      "Epoch 89/150\n",
      "692/692 [==============================] - 0s 130us/step - loss: 0.5583 - acc: 0.7298\n",
      "Epoch 90/150\n",
      "692/692 [==============================] - 0s 132us/step - loss: 0.5079 - acc: 0.7399\n",
      "Epoch 91/150\n",
      "692/692 [==============================] - 0s 124us/step - loss: 0.5129 - acc: 0.7572\n",
      "Epoch 92/150\n",
      "692/692 [==============================] - 0s 129us/step - loss: 0.5091 - acc: 0.7659\n",
      "Epoch 93/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 0.5167 - acc: 0.7486\n",
      "Epoch 94/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.5175 - acc: 0.7630\n",
      "Epoch 95/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 0.5218 - acc: 0.7442\n",
      "Epoch 96/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.5240 - acc: 0.7399\n",
      "Epoch 97/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 0.5825 - acc: 0.7413\n",
      "Epoch 98/150\n",
      "692/692 [==============================] - 0s 124us/step - loss: 0.5017 - acc: 0.7587\n",
      "Epoch 99/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 0.4858 - acc: 0.7702\n",
      "Epoch 100/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.5467 - acc: 0.7384\n",
      "Epoch 101/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 0.5090 - acc: 0.7514\n",
      "Epoch 102/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 0.5493 - acc: 0.7341\n",
      "Epoch 103/150\n",
      "692/692 [==============================] - 0s 133us/step - loss: 0.5109 - acc: 0.7558\n",
      "Epoch 104/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 0.5022 - acc: 0.7514\n",
      "Epoch 105/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 0.5391 - acc: 0.7457\n",
      "Epoch 106/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 0.4970 - acc: 0.7601\n",
      "Epoch 107/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.5171 - acc: 0.7486\n",
      "Epoch 108/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 0.5113 - acc: 0.7442\n",
      "Epoch 109/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 0.5331 - acc: 0.7442\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692/692 [==============================] - 0s 120us/step - loss: 0.5038 - acc: 0.7486\n",
      "Epoch 111/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 0.5237 - acc: 0.7399\n",
      "Epoch 112/150\n",
      "692/692 [==============================] - 0s 122us/step - loss: 0.5339 - acc: 0.7529\n",
      "Epoch 113/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.5054 - acc: 0.7572\n",
      "Epoch 114/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 0.5360 - acc: 0.7442\n",
      "Epoch 115/150\n",
      "692/692 [==============================] - 0s 110us/step - loss: 0.5200 - acc: 0.7312\n",
      "Epoch 116/150\n",
      "692/692 [==============================] - 0s 135us/step - loss: 0.4903 - acc: 0.7645\n",
      "Epoch 117/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 0.5389 - acc: 0.7254\n",
      "Epoch 118/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 0.5552 - acc: 0.7384\n",
      "Epoch 119/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 0.5156 - acc: 0.7659\n",
      "Epoch 120/150\n",
      "692/692 [==============================] - 0s 128us/step - loss: 0.4924 - acc: 0.7645\n",
      "Epoch 121/150\n",
      "692/692 [==============================] - 0s 142us/step - loss: 0.5315 - acc: 0.7428\n",
      "Epoch 122/150\n",
      "692/692 [==============================] - 0s 130us/step - loss: 0.5100 - acc: 0.7601\n",
      "Epoch 123/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 0.5050 - acc: 0.7630\n",
      "Epoch 124/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 0.5134 - acc: 0.7341\n",
      "Epoch 125/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 0.5136 - acc: 0.7558\n",
      "Epoch 126/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.5489 - acc: 0.7283\n",
      "Epoch 127/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 0.5226 - acc: 0.7399\n",
      "Epoch 128/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 0.4931 - acc: 0.7616\n",
      "Epoch 129/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 0.4905 - acc: 0.7673\n",
      "Epoch 130/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 0.4959 - acc: 0.7630\n",
      "Epoch 131/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 0.5214 - acc: 0.7572\n",
      "Epoch 132/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 0.5016 - acc: 0.7543\n",
      "Epoch 133/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 0.4873 - acc: 0.7688\n",
      "Epoch 134/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 0.4873 - acc: 0.7601\n",
      "Epoch 135/150\n",
      "692/692 [==============================] - 0s 124us/step - loss: 0.5251 - acc: 0.7587\n",
      "Epoch 136/150\n",
      "692/692 [==============================] - 0s 122us/step - loss: 0.5239 - acc: 0.7471\n",
      "Epoch 137/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 0.4996 - acc: 0.7746\n",
      "Epoch 138/150\n",
      "692/692 [==============================] - 0s 127us/step - loss: 0.4857 - acc: 0.7760\n",
      "Epoch 139/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 0.5468 - acc: 0.7471\n",
      "Epoch 140/150\n",
      "692/692 [==============================] - 0s 143us/step - loss: 0.5475 - acc: 0.7442\n",
      "Epoch 141/150\n",
      "692/692 [==============================] - 0s 126us/step - loss: 0.4901 - acc: 0.7659\n",
      "Epoch 142/150\n",
      "692/692 [==============================] - 0s 129us/step - loss: 0.5126 - acc: 0.7543\n",
      "Epoch 143/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 0.4838 - acc: 0.7731\n",
      "Epoch 144/150\n",
      "692/692 [==============================] - 0s 122us/step - loss: 0.5482 - acc: 0.7616\n",
      "Epoch 145/150\n",
      "692/692 [==============================] - 0s 139us/step - loss: 0.4935 - acc: 0.7775\n",
      "Epoch 146/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 0.4869 - acc: 0.7688\n",
      "Epoch 147/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.4877 - acc: 0.7803\n",
      "Epoch 148/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 0.4985 - acc: 0.7558\n",
      "Epoch 149/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 0.5621 - acc: 0.7211\n",
      "Epoch 150/150\n",
      "692/692 [==============================] - 0s 121us/step - loss: 0.4773 - acc: 0.7760\n",
      "acc: 72.37%\n",
      "Epoch 1/150\n",
      "692/692 [==============================] - 1s 2ms/step - loss: 5.5967 - acc: 0.6503\n",
      "Epoch 2/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5933 - acc: 0.6488\n",
      "Epoch 3/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 5.5932 - acc: 0.6517\n",
      "Epoch 4/150\n",
      "692/692 [==============================] - 0s 121us/step - loss: 5.5939 - acc: 0.6503\n",
      "Epoch 5/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 5.5939 - acc: 0.6517\n",
      "Epoch 6/150\n",
      "692/692 [==============================] - 0s 122us/step - loss: 5.5932 - acc: 0.6517\n",
      "Epoch 7/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5932 - acc: 0.6517\n",
      "Epoch 8/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 9/150\n",
      "692/692 [==============================] - 0s 112us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 10/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 11/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 5.5933 - acc: 0.6503\n",
      "Epoch 12/150\n",
      "692/692 [==============================] - 0s 112us/step - loss: 5.5942 - acc: 0.6503\n",
      "Epoch 13/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 5.5932 - acc: 0.6517\n",
      "Epoch 14/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 15/150\n",
      "692/692 [==============================] - 0s 112us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 16/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 17/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 18/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 19/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 20/150\n",
      "692/692 [==============================] - 0s 121us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 21/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 22/150\n",
      "692/692 [==============================] - 0s 126us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 23/150\n",
      "692/692 [==============================] - 0s 121us/step - loss: 5.5931 - acc: 0.6503\n",
      "Epoch 24/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 5.5942 - acc: 0.6503\n",
      "Epoch 25/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 26/150\n",
      "692/692 [==============================] - 0s 119us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 27/150\n",
      "692/692 [==============================] - 0s 124us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 28/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 29/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 30/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 31/150\n",
      "692/692 [==============================] - 0s 112us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 32/150\n",
      "692/692 [==============================] - 0s 112us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 33/150\n",
      "692/692 [==============================] - 0s 110us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 34/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 35/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 36/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 37/150\n",
      "692/692 [==============================] - 0s 121us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 38/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 39/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 40/150\n",
      "692/692 [==============================] - 0s 112us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 41/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 42/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692/692 [==============================] - 0s 118us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 43/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 44/150\n",
      "692/692 [==============================] - 0s 112us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 45/150\n",
      "692/692 [==============================] - 0s 109us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 46/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 47/150\n",
      "692/692 [==============================] - 0s 125us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 48/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 49/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 50/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 51/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 52/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 53/150\n",
      "692/692 [==============================] - 0s 124us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 54/150\n",
      "692/692 [==============================] - 0s 112us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 55/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5941 - acc: 0.6503\n",
      "Epoch 56/150\n",
      "692/692 [==============================] - 0s 110us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 57/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.6017 - acc: 0.6517\n",
      "Epoch 58/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 59/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5932 - acc: 0.6517\n",
      "Epoch 60/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 61/150\n",
      "692/692 [==============================] - 0s 111us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 62/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 63/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 64/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 65/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 66/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 67/150\n",
      "692/692 [==============================] - 0s 112us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 68/150\n",
      "692/692 [==============================] - 0s 110us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 69/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 70/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 71/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 72/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5959 - acc: 0.6503\n",
      "Epoch 73/150\n",
      "692/692 [==============================] - 0s 111us/step - loss: 5.5933 - acc: 0.6517\n",
      "Epoch 74/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 75/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 76/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 77/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 78/150\n",
      "692/692 [==============================] - 0s 112us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 79/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 80/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 81/150\n",
      "692/692 [==============================] - 0s 111us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 82/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 83/150\n",
      "692/692 [==============================] - 0s 111us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 84/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 85/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 86/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 87/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5977 - acc: 0.6503\n",
      "Epoch 88/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5934 - acc: 0.6517\n",
      "Epoch 89/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 90/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 91/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 92/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 93/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 94/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 95/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 96/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 97/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 98/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 99/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 100/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 101/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 102/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 103/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5958 - acc: 0.6517\n",
      "Epoch 104/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 105/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 106/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 107/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 108/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 109/150\n",
      "692/692 [==============================] - 0s 127us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 110/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 111/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 112/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 113/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 114/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 115/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 116/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 117/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 118/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 119/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 5.5937 - acc: 0.6503\n",
      "Epoch 120/150\n",
      "692/692 [==============================] - 0s 110us/step - loss: 5.5931 - acc: 0.6517\n",
      "Epoch 121/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 122/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 123/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 124/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692/692 [==============================] - 0s 112us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 125/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 126/150\n",
      "692/692 [==============================] - 0s 111us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 127/150\n",
      "692/692 [==============================] - 0s 110us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 128/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 129/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 130/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 131/150\n",
      "692/692 [==============================] - 0s 118us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 132/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 133/150\n",
      "692/692 [==============================] - 0s 114us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 134/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 135/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5959 - acc: 0.6503\n",
      "Epoch 136/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 137/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 5.5952 - acc: 0.6503\n",
      "Epoch 138/150\n",
      "692/692 [==============================] - 0s 121us/step - loss: 5.5939 - acc: 0.6503\n",
      "Epoch 139/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 140/150\n",
      "692/692 [==============================] - 0s 117us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 141/150\n",
      "692/692 [==============================] - 0s 122us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 142/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 143/150\n",
      "692/692 [==============================] - 0s 123us/step - loss: 5.5930 - acc: 0.6517\n",
      "Epoch 144/150\n",
      "692/692 [==============================] - 0s 129us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 145/150\n",
      "692/692 [==============================] - 0s 120us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 146/150\n",
      "692/692 [==============================] - 0s 115us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 147/150\n",
      "692/692 [==============================] - 0s 116us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 148/150\n",
      "692/692 [==============================] - 0s 111us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 149/150\n",
      "692/692 [==============================] - 0s 113us/step - loss: 5.5929 - acc: 0.6517\n",
      "Epoch 150/150\n",
      "692/692 [==============================] - 0s 111us/step - loss: 5.5929 - acc: 0.6517\n",
      "acc: 65.79%\n",
      "70.05% (+/- 3.10%)\n"
     ]
    }
   ],
   "source": [
    "# Keras——模型评估\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed = 7\n",
    "# 设定随机数种子\n",
    "np.random.seed(seed)\n",
    "# 导入数据\n",
    "current_path = r'C:/Users/Lenovo/Desktop/data/data/'\n",
    "dataset = np.loadtxt(current_path+'pima-indians-diabetes.csv', delimiter=',')\n",
    "# 分割输入x和输出Y\n",
    "x = dataset[:, 0: 8]\n",
    "Y = dataset[:, 8]\n",
    "# 分割数据集\n",
    "x_train, x_validation, Y_train, Y_validation = train_test_split(x, Y, test_size=0.2, random_state=seed)\n",
    "# 构建模型\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# 编译模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 自动评估\n",
    "# 训练模型并自动评估模型:设置验证分割参数为0.2，使用20%的数据评估模型\n",
    "model.fit(x=x, y=Y, epochs=150, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# 手动评估\n",
    "# 手动分离数据进行评估\n",
    "model.fit(x_train, Y_train, validation_data=(x_validation, Y_validation), epochs=150, batch_size=10)\n",
    "# k折交叉验证：将数据集分为k个子集，选择其中一个子集作为评估数据集，利用剩余的k-1个子集训练模型，重复直至每个子集都被用作过评估\n",
    "# 使用StratifiedKFold将数据分割成10个子集，并利用这10个子集创建和评估10个模型，且收集这10个模型的评估得分。\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "cvscores = []\n",
    "for train, validation in kfold.split(x, Y):\n",
    "    # 创建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # 编译模型\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # 训练模型\n",
    "    model.fit(x[train], Y[train], epochs=150, batch_size=10, verbose=1)\n",
    "    # 评估模型\n",
    "    scores = model.evaluate(x[validation], Y[validation], verbose=0)\n",
    "    # 输出评估结果\n",
    "    print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "# 输出均值和标准差\n",
    "print('%.2f%% (+/- %.2f%%)' % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/200\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 1.0079 - acc: 0.4833 - val_loss: 1.1250 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "120/120 [==============================] - 0s 363us/step - loss: 0.9405 - acc: 0.6000 - val_loss: 1.1520 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "120/120 [==============================] - 0s 711us/step - loss: 0.8958 - acc: 0.6833 - val_loss: 1.1725 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "120/120 [==============================] - 0s 492us/step - loss: 0.8555 - acc: 0.7167 - val_loss: 1.1862 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.8142 - acc: 0.7333 - val_loss: 1.1970 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "120/120 [==============================] - 0s 645us/step - loss: 0.7679 - acc: 0.7417 - val_loss: 1.2048 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "120/120 [==============================] - 0s 558us/step - loss: 0.7235 - acc: 0.6750 - val_loss: 1.2055 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "120/120 [==============================] - 0s 467us/step - loss: 0.6872 - acc: 0.5917 - val_loss: 1.1992 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "120/120 [==============================] - 0s 711us/step - loss: 0.6577 - acc: 0.6083 - val_loss: 1.2090 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      "120/120 [==============================] - 0s 513us/step - loss: 0.6325 - acc: 0.6167 - val_loss: 1.2095 - val_acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      "120/120 [==============================] - 0s 455us/step - loss: 0.6106 - acc: 0.6417 - val_loss: 1.2191 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      "120/120 [==============================] - 0s 674us/step - loss: 0.5901 - acc: 0.7000 - val_loss: 1.2175 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      "120/120 [==============================] - 0s 492us/step - loss: 0.5708 - acc: 0.7833 - val_loss: 1.2428 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      "120/120 [==============================] - 0s 575us/step - loss: 0.5520 - acc: 0.8000 - val_loss: 1.2296 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      "120/120 [==============================] - 0s 727us/step - loss: 0.5319 - acc: 0.8167 - val_loss: 1.2282 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      "120/120 [==============================] - 0s 504us/step - loss: 0.5121 - acc: 0.8167 - val_loss: 1.2044 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      "120/120 [==============================] - 0s 513us/step - loss: 0.4943 - acc: 0.8167 - val_loss: 1.2811 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      "120/120 [==============================] - 0s 769us/step - loss: 0.4791 - acc: 0.8167 - val_loss: 1.2601 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      "120/120 [==============================] - 0s 496us/step - loss: 0.4617 - acc: 0.8250 - val_loss: 1.2633 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      "120/120 [==============================] - 0s 459us/step - loss: 0.4457 - acc: 0.8250 - val_loss: 1.2902 - val_acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      "120/120 [==============================] - 0s 686us/step - loss: 0.4306 - acc: 0.8250 - val_loss: 1.2641 - val_acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      "120/120 [==============================] - 0s 446us/step - loss: 0.4178 - acc: 0.8250 - val_loss: 1.2750 - val_acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      "120/120 [==============================] - 0s 591us/step - loss: 0.4042 - acc: 0.8250 - val_loss: 1.2622 - val_acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      "120/120 [==============================] - 0s 575us/step - loss: 0.3915 - acc: 0.8333 - val_loss: 1.2471 - val_acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      "120/120 [==============================] - 0s 665us/step - loss: 0.3785 - acc: 0.8333 - val_loss: 1.3446 - val_acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      "120/120 [==============================] - 0s 504us/step - loss: 0.3694 - acc: 0.8333 - val_loss: 1.3199 - val_acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      "120/120 [==============================] - 0s 744us/step - loss: 0.3583 - acc: 0.8333 - val_loss: 1.2870 - val_acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      "120/120 [==============================] - 0s 471us/step - loss: 0.3476 - acc: 0.8333 - val_loss: 1.3181 - val_acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      "120/120 [==============================] - 0s 608us/step - loss: 0.3370 - acc: 0.8333 - val_loss: 1.2166 - val_acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      "120/120 [==============================] - 0s 628us/step - loss: 0.3263 - acc: 0.8333 - val_loss: 1.1769 - val_acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      "120/120 [==============================] - 0s 513us/step - loss: 0.3174 - acc: 0.8333 - val_loss: 1.2408 - val_acc: 0.3000\n",
      "Epoch 32/200\n",
      "120/120 [==============================] - 0s 694us/step - loss: 0.3089 - acc: 0.8750 - val_loss: 1.2098 - val_acc: 0.3000\n",
      "Epoch 33/200\n",
      "120/120 [==============================] - 0s 438us/step - loss: 0.2993 - acc: 0.8917 - val_loss: 1.1896 - val_acc: 0.3000\n",
      "Epoch 34/200\n",
      "120/120 [==============================] - 0s 661us/step - loss: 0.2917 - acc: 0.9000 - val_loss: 1.2216 - val_acc: 0.3000\n",
      "Epoch 35/200\n",
      "120/120 [==============================] - 0s 430us/step - loss: 0.2849 - acc: 0.9083 - val_loss: 1.2040 - val_acc: 0.3000\n",
      "Epoch 36/200\n",
      "120/120 [==============================] - 0s 690us/step - loss: 0.2747 - acc: 0.9083 - val_loss: 1.2021 - val_acc: 0.3000\n",
      "Epoch 37/200\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.2672 - acc: 0.9083 - val_loss: 1.2665 - val_acc: 0.3000\n",
      "Epoch 38/200\n",
      "120/120 [==============================] - 0s 628us/step - loss: 0.2612 - acc: 0.9083 - val_loss: 1.1995 - val_acc: 0.3000\n",
      "Epoch 39/200\n",
      "120/120 [==============================] - 0s 521us/step - loss: 0.2533 - acc: 0.9250 - val_loss: 1.1689 - val_acc: 0.3000\n",
      "Epoch 40/200\n",
      "120/120 [==============================] - 0s 546us/step - loss: 0.2454 - acc: 0.9167 - val_loss: 1.1952 - val_acc: 0.3000\n",
      "Epoch 41/200\n",
      "120/120 [==============================] - 0s 723us/step - loss: 0.2392 - acc: 0.9250 - val_loss: 1.1184 - val_acc: 0.4667\n",
      "Epoch 42/200\n",
      "120/120 [==============================] - 0s 562us/step - loss: 0.2313 - acc: 0.9333 - val_loss: 1.0642 - val_acc: 0.4667\n",
      "Epoch 43/200\n",
      "120/120 [==============================] - 0s 281us/step - loss: 0.2264 - acc: 0.9250 - val_loss: 1.0313 - val_acc: 0.5000\n",
      "Epoch 44/200\n",
      "120/120 [==============================] - 0s 508us/step - loss: 0.2188 - acc: 0.9500 - val_loss: 1.1030 - val_acc: 0.4667\n",
      "Epoch 45/200\n",
      "120/120 [==============================] - 0s 587us/step - loss: 0.2132 - acc: 0.9417 - val_loss: 1.1165 - val_acc: 0.4667\n",
      "Epoch 46/200\n",
      "120/120 [==============================] - 0s 719us/step - loss: 0.2019 - acc: 0.9417 - val_loss: 0.9230 - val_acc: 0.5333\n",
      "Epoch 47/200\n",
      "120/120 [==============================] - 0s 843us/step - loss: 0.2020 - acc: 0.9417 - val_loss: 0.9313 - val_acc: 0.5333\n",
      "Epoch 48/200\n",
      "120/120 [==============================] - 0s 612us/step - loss: 0.1959 - acc: 0.9750 - val_loss: 1.0252 - val_acc: 0.5000\n",
      "Epoch 49/200\n",
      "120/120 [==============================] - 0s 533us/step - loss: 0.1898 - acc: 0.9583 - val_loss: 1.0766 - val_acc: 0.4667\n",
      "Epoch 50/200\n",
      "120/120 [==============================] - 0s 599us/step - loss: 0.1842 - acc: 0.9500 - val_loss: 0.9862 - val_acc: 0.5000\n",
      "Epoch 51/200\n",
      "120/120 [==============================] - 0s 521us/step - loss: 0.1796 - acc: 0.9667 - val_loss: 0.9925 - val_acc: 0.5000\n",
      "Epoch 52/200\n",
      "120/120 [==============================] - 0s 632us/step - loss: 0.1731 - acc: 0.9750 - val_loss: 1.0639 - val_acc: 0.5000\n",
      "Epoch 53/200\n",
      "120/120 [==============================] - 0s 517us/step - loss: 0.1700 - acc: 0.9750 - val_loss: 0.9996 - val_acc: 0.5000\n",
      "Epoch 54/200\n",
      "120/120 [==============================] - 0s 537us/step - loss: 0.1616 - acc: 0.9750 - val_loss: 0.8037 - val_acc: 0.6667\n",
      "Epoch 55/200\n",
      "120/120 [==============================] - 0s 508us/step - loss: 0.1600 - acc: 0.9667 - val_loss: 0.9683 - val_acc: 0.5000\n",
      "Epoch 56/200\n",
      "120/120 [==============================] - 0s 603us/step - loss: 0.1575 - acc: 0.9583 - val_loss: 0.8985 - val_acc: 0.5333\n",
      "Epoch 57/200\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.1515 - acc: 0.9750 - val_loss: 0.8767 - val_acc: 0.5333\n",
      "Epoch 58/200\n",
      "120/120 [==============================] - 0s 467us/step - loss: 0.1464 - acc: 0.9750 - val_loss: 0.8951 - val_acc: 0.5333\n",
      "Epoch 59/200\n",
      "120/120 [==============================] - 0s 508us/step - loss: 0.1432 - acc: 0.9750 - val_loss: 0.7874 - val_acc: 0.6333\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 430us/step - loss: 0.1405 - acc: 0.9833 - val_loss: 0.7864 - val_acc: 0.6333\n",
      "Epoch 61/200\n",
      "120/120 [==============================] - 0s 442us/step - loss: 0.1361 - acc: 0.9750 - val_loss: 0.8154 - val_acc: 0.5667\n",
      "Epoch 62/200\n",
      "120/120 [==============================] - 0s 484us/step - loss: 0.1306 - acc: 0.9833 - val_loss: 0.9969 - val_acc: 0.5000\n",
      "Epoch 63/200\n",
      "120/120 [==============================] - 0s 417us/step - loss: 0.1300 - acc: 0.9583 - val_loss: 0.7588 - val_acc: 0.6667\n",
      "Epoch 64/200\n",
      "120/120 [==============================] - 0s 405us/step - loss: 0.1255 - acc: 0.9750 - val_loss: 0.7962 - val_acc: 0.6000\n",
      "Epoch 65/200\n",
      "120/120 [==============================] - 0s 339us/step - loss: 0.1225 - acc: 0.9750 - val_loss: 0.8114 - val_acc: 0.5667\n",
      "Epoch 66/200\n",
      "120/120 [==============================] - 0s 446us/step - loss: 0.1196 - acc: 0.9750 - val_loss: 0.8792 - val_acc: 0.5333\n",
      "Epoch 67/200\n",
      "120/120 [==============================] - 0s 355us/step - loss: 0.1175 - acc: 0.9750 - val_loss: 0.7607 - val_acc: 0.6333\n",
      "Epoch 68/200\n",
      "120/120 [==============================] - 0s 393us/step - loss: 0.1134 - acc: 0.9750 - val_loss: 0.6522 - val_acc: 0.6667\n",
      "Epoch 69/200\n",
      "120/120 [==============================] - 0s 430us/step - loss: 0.1112 - acc: 0.9667 - val_loss: 0.7739 - val_acc: 0.6333\n",
      "Epoch 70/200\n",
      "120/120 [==============================] - 0s 405us/step - loss: 0.1094 - acc: 0.9750 - val_loss: 0.6998 - val_acc: 0.6667\n",
      "Epoch 71/200\n",
      "120/120 [==============================] - 0s 356us/step - loss: 0.1074 - acc: 0.9750 - val_loss: 0.7107 - val_acc: 0.6667\n",
      "Epoch 72/200\n",
      "120/120 [==============================] - 0s 401us/step - loss: 0.1047 - acc: 0.9833 - val_loss: 0.7885 - val_acc: 0.6000\n",
      "Epoch 73/200\n",
      "120/120 [==============================] - 0s 513us/step - loss: 0.1033 - acc: 0.9750 - val_loss: 0.7641 - val_acc: 0.6333\n",
      "Epoch 74/200\n",
      "120/120 [==============================] - 0s 409us/step - loss: 0.1000 - acc: 0.9750 - val_loss: 0.7700 - val_acc: 0.6000\n",
      "Epoch 75/200\n",
      "120/120 [==============================] - 0s 475us/step - loss: 0.0980 - acc: 0.9833 - val_loss: 0.8234 - val_acc: 0.5333\n",
      "Epoch 76/200\n",
      "120/120 [==============================] - 0s 376us/step - loss: 0.0971 - acc: 0.9667 - val_loss: 0.7043 - val_acc: 0.6667\n",
      "Epoch 77/200\n",
      "120/120 [==============================] - 0s 384us/step - loss: 0.0925 - acc: 0.9833 - val_loss: 0.7504 - val_acc: 0.6333\n",
      "Epoch 78/200\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.0927 - acc: 0.9750 - val_loss: 0.7196 - val_acc: 0.6667\n",
      "Epoch 79/200\n",
      "120/120 [==============================] - 0s 372us/step - loss: 0.0913 - acc: 0.9750 - val_loss: 0.6389 - val_acc: 0.6667\n",
      "Epoch 80/200\n",
      "120/120 [==============================] - 0s 409us/step - loss: 0.0896 - acc: 0.9750 - val_loss: 0.6556 - val_acc: 0.6667\n",
      "Epoch 81/200\n",
      "120/120 [==============================] - 0s 422us/step - loss: 0.0870 - acc: 0.9833 - val_loss: 0.6017 - val_acc: 0.6667\n",
      "Epoch 82/200\n",
      "120/120 [==============================] - 0s 372us/step - loss: 0.0857 - acc: 0.9667 - val_loss: 0.6790 - val_acc: 0.6667\n",
      "Epoch 83/200\n",
      "120/120 [==============================] - 0s 393us/step - loss: 0.0869 - acc: 0.9750 - val_loss: 0.5930 - val_acc: 0.6667\n",
      "Epoch 84/200\n",
      "120/120 [==============================] - 0s 455us/step - loss: 0.0806 - acc: 0.9833 - val_loss: 0.6356 - val_acc: 0.6667\n",
      "Epoch 85/200\n",
      "120/120 [==============================] - 0s 376us/step - loss: 0.0811 - acc: 0.9750 - val_loss: 0.6394 - val_acc: 0.6667\n",
      "Epoch 86/200\n",
      "120/120 [==============================] - 0s 401us/step - loss: 0.0786 - acc: 0.9750 - val_loss: 0.6549 - val_acc: 0.6667\n",
      "Epoch 87/200\n",
      "120/120 [==============================] - 0s 384us/step - loss: 0.0767 - acc: 0.9833 - val_loss: 0.6741 - val_acc: 0.6667\n",
      "Epoch 88/200\n",
      "120/120 [==============================] - 0s 417us/step - loss: 0.0767 - acc: 0.9833 - val_loss: 0.7094 - val_acc: 0.6667\n",
      "Epoch 89/200\n",
      "120/120 [==============================] - 0s 380us/step - loss: 0.0767 - acc: 0.9833 - val_loss: 0.5994 - val_acc: 0.6667\n",
      "Epoch 90/200\n",
      "120/120 [==============================] - 0s 347us/step - loss: 0.0761 - acc: 0.9750 - val_loss: 0.6122 - val_acc: 0.6667\n",
      "Epoch 91/200\n",
      "120/120 [==============================] - 0s 360us/step - loss: 0.0729 - acc: 0.9750 - val_loss: 0.5354 - val_acc: 0.7333\n",
      "Epoch 92/200\n",
      "120/120 [==============================] - 0s 360us/step - loss: 0.0714 - acc: 0.9833 - val_loss: 0.6392 - val_acc: 0.6667\n",
      "Epoch 93/200\n",
      "120/120 [==============================] - 0s 384us/step - loss: 0.0747 - acc: 0.9667 - val_loss: 0.5536 - val_acc: 0.6667\n",
      "Epoch 94/200\n",
      "120/120 [==============================] - 0s 446us/step - loss: 0.0703 - acc: 0.9750 - val_loss: 0.6067 - val_acc: 0.6667\n",
      "Epoch 95/200\n",
      "120/120 [==============================] - 0s 368us/step - loss: 0.0698 - acc: 0.9750 - val_loss: 0.5793 - val_acc: 0.6667\n",
      "Epoch 96/200\n",
      "120/120 [==============================] - 0s 389us/step - loss: 0.0690 - acc: 0.9750 - val_loss: 0.6805 - val_acc: 0.6667\n",
      "Epoch 97/200\n",
      "120/120 [==============================] - 0s 384us/step - loss: 0.0668 - acc: 0.9667 - val_loss: 0.6377 - val_acc: 0.6667\n",
      "Epoch 98/200\n",
      "120/120 [==============================] - 0s 322us/step - loss: 0.0690 - acc: 0.9833 - val_loss: 0.5420 - val_acc: 0.7000\n",
      "Epoch 99/200\n",
      "120/120 [==============================] - 0s 430us/step - loss: 0.0674 - acc: 0.9750 - val_loss: 0.6239 - val_acc: 0.6667\n",
      "Epoch 100/200\n",
      "120/120 [==============================] - 0s 376us/step - loss: 0.0672 - acc: 0.9833 - val_loss: 0.5451 - val_acc: 0.6667\n",
      "Epoch 101/200\n",
      "120/120 [==============================] - 0s 422us/step - loss: 0.0637 - acc: 0.9750 - val_loss: 0.5020 - val_acc: 0.7667\n",
      "Epoch 102/200\n",
      "120/120 [==============================] - 0s 372us/step - loss: 0.0674 - acc: 0.9833 - val_loss: 0.5685 - val_acc: 0.6667\n",
      "Epoch 103/200\n",
      "120/120 [==============================] - 0s 384us/step - loss: 0.0633 - acc: 0.9750 - val_loss: 0.6434 - val_acc: 0.6667\n",
      "Epoch 104/200\n",
      "120/120 [==============================] - 0s 422us/step - loss: 0.0625 - acc: 0.9750 - val_loss: 0.6483 - val_acc: 0.6667\n",
      "Epoch 105/200\n",
      "120/120 [==============================] - 0s 384us/step - loss: 0.0611 - acc: 0.9833 - val_loss: 0.4663 - val_acc: 0.8000\n",
      "Epoch 106/200\n",
      "120/120 [==============================] - 0s 372us/step - loss: 0.0600 - acc: 0.9750 - val_loss: 0.5252 - val_acc: 0.7333\n",
      "Epoch 107/200\n",
      "120/120 [==============================] - 0s 335us/step - loss: 0.0623 - acc: 0.9750 - val_loss: 0.6217 - val_acc: 0.6667\n",
      "Epoch 108/200\n",
      "120/120 [==============================] - 0s 355us/step - loss: 0.0580 - acc: 0.9750 - val_loss: 0.5002 - val_acc: 0.7333\n",
      "Epoch 109/200\n",
      "120/120 [==============================] - 0s 360us/step - loss: 0.0636 - acc: 0.9667 - val_loss: 0.5762 - val_acc: 0.6667\n",
      "Epoch 110/200\n",
      "120/120 [==============================] - 0s 397us/step - loss: 0.0592 - acc: 0.9833 - val_loss: 0.5220 - val_acc: 0.7333\n",
      "Epoch 111/200\n",
      "120/120 [==============================] - 0s 364us/step - loss: 0.0615 - acc: 0.9667 - val_loss: 0.5731 - val_acc: 0.6667\n",
      "Epoch 112/200\n",
      "120/120 [==============================] - 0s 376us/step - loss: 0.0576 - acc: 0.9750 - val_loss: 0.4608 - val_acc: 0.8000\n",
      "Epoch 113/200\n",
      "120/120 [==============================] - 0s 364us/step - loss: 0.0561 - acc: 0.9750 - val_loss: 0.5685 - val_acc: 0.6667\n",
      "Epoch 114/200\n",
      "120/120 [==============================] - 0s 372us/step - loss: 0.0566 - acc: 0.9667 - val_loss: 0.7328 - val_acc: 0.6667\n",
      "Epoch 115/200\n",
      "120/120 [==============================] - 0s 384us/step - loss: 0.0545 - acc: 0.9833 - val_loss: 0.4581 - val_acc: 0.8000\n",
      "Epoch 116/200\n",
      "120/120 [==============================] - 0s 376us/step - loss: 0.0572 - acc: 0.9833 - val_loss: 0.4610 - val_acc: 0.8000\n",
      "Epoch 117/200\n",
      "120/120 [==============================] - 0s 380us/step - loss: 0.0579 - acc: 0.9750 - val_loss: 0.6205 - val_acc: 0.6667\n",
      "Epoch 118/200\n",
      "120/120 [==============================] - 0s 355us/step - loss: 0.0559 - acc: 0.9750 - val_loss: 0.6309 - val_acc: 0.6667\n",
      "Epoch 119/200\n",
      "120/120 [==============================] - 0s 372us/step - loss: 0.0556 - acc: 0.9750 - val_loss: 0.4744 - val_acc: 0.7667\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 417us/step - loss: 0.0535 - acc: 0.9833 - val_loss: 0.7079 - val_acc: 0.6667\n",
      "Epoch 121/200\n",
      "120/120 [==============================] - 0s 372us/step - loss: 0.0551 - acc: 0.9750 - val_loss: 0.5219 - val_acc: 0.7333\n",
      "Epoch 122/200\n",
      "120/120 [==============================] - 0s 376us/step - loss: 0.0561 - acc: 0.9750 - val_loss: 0.5663 - val_acc: 0.6667\n",
      "Epoch 123/200\n",
      "120/120 [==============================] - 0s 418us/step - loss: 0.0530 - acc: 0.9833 - val_loss: 0.5669 - val_acc: 0.6667\n",
      "Epoch 124/200\n",
      "120/120 [==============================] - 0s 438us/step - loss: 0.0538 - acc: 0.9833 - val_loss: 0.6029 - val_acc: 0.6667\n",
      "Epoch 125/200\n",
      "120/120 [==============================] - 0s 389us/step - loss: 0.0548 - acc: 0.9833 - val_loss: 0.5433 - val_acc: 0.6667\n",
      "Epoch 126/200\n",
      "120/120 [==============================] - 0s 471us/step - loss: 0.0553 - acc: 0.9833 - val_loss: 0.6061 - val_acc: 0.6667\n",
      "Epoch 127/200\n",
      "120/120 [==============================] - 0s 384us/step - loss: 0.0568 - acc: 0.9750 - val_loss: 0.5693 - val_acc: 0.6667\n",
      "Epoch 128/200\n",
      "120/120 [==============================] - 0s 430us/step - loss: 0.0519 - acc: 0.9750 - val_loss: 0.4957 - val_acc: 0.7333\n",
      "Epoch 129/200\n",
      "120/120 [==============================] - 0s 347us/step - loss: 0.0536 - acc: 0.9750 - val_loss: 0.5745 - val_acc: 0.6667\n",
      "Epoch 130/200\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.0507 - acc: 0.9750 - val_loss: 0.7594 - val_acc: 0.6667\n",
      "Epoch 131/200\n",
      "120/120 [==============================] - 0s 347us/step - loss: 0.0516 - acc: 0.9750 - val_loss: 0.5079 - val_acc: 0.7333\n",
      "Epoch 132/200\n",
      "120/120 [==============================] - 0s 438us/step - loss: 0.0521 - acc: 0.9750 - val_loss: 0.5843 - val_acc: 0.6667\n",
      "Epoch 133/200\n",
      "120/120 [==============================] - 0s 376us/step - loss: 0.0494 - acc: 0.9833 - val_loss: 0.4789 - val_acc: 0.7667\n",
      "Epoch 134/200\n",
      "120/120 [==============================] - 0s 397us/step - loss: 0.0519 - acc: 0.9750 - val_loss: 0.6612 - val_acc: 0.6667\n",
      "Epoch 135/200\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.0513 - acc: 0.9833 - val_loss: 0.5311 - val_acc: 0.7000\n",
      "Epoch 136/200\n",
      "120/120 [==============================] - 0s 566us/step - loss: 0.0512 - acc: 0.9750 - val_loss: 0.6258 - val_acc: 0.6667\n",
      "Epoch 137/200\n",
      "120/120 [==============================] - 0s 868us/step - loss: 0.0491 - acc: 0.9750 - val_loss: 0.4804 - val_acc: 0.7333\n",
      "Epoch 138/200\n",
      "120/120 [==============================] - 0s 769us/step - loss: 0.0457 - acc: 0.9750 - val_loss: 0.7606 - val_acc: 0.6667\n",
      "Epoch 139/200\n",
      "120/120 [==============================] - 0s 459us/step - loss: 0.0489 - acc: 0.9750 - val_loss: 0.6326 - val_acc: 0.6667\n",
      "Epoch 140/200\n",
      "120/120 [==============================] - 0s 401us/step - loss: 0.0499 - acc: 0.9750 - val_loss: 0.6969 - val_acc: 0.6667\n",
      "Epoch 141/200\n",
      "120/120 [==============================] - 0s 413us/step - loss: 0.0532 - acc: 0.9750 - val_loss: 0.6169 - val_acc: 0.6667\n",
      "Epoch 142/200\n",
      "120/120 [==============================] - 0s 384us/step - loss: 0.0498 - acc: 0.9833 - val_loss: 0.5111 - val_acc: 0.7333\n",
      "Epoch 143/200\n",
      "120/120 [==============================] - 0s 380us/step - loss: 0.0497 - acc: 0.9750 - val_loss: 0.6433 - val_acc: 0.6667\n",
      "Epoch 144/200\n",
      "120/120 [==============================] - 0s 471us/step - loss: 0.0491 - acc: 0.9833 - val_loss: 0.6798 - val_acc: 0.6667\n",
      "Epoch 145/200\n",
      "120/120 [==============================] - 0s 372us/step - loss: 0.0507 - acc: 0.9833 - val_loss: 0.6247 - val_acc: 0.6667\n",
      "Epoch 146/200\n",
      "120/120 [==============================] - 0s 500us/step - loss: 0.0480 - acc: 0.9750 - val_loss: 0.7392 - val_acc: 0.6667\n",
      "Epoch 147/200\n",
      "120/120 [==============================] - 0s 355us/step - loss: 0.0492 - acc: 0.9833 - val_loss: 0.5813 - val_acc: 0.6667\n",
      "Epoch 148/200\n",
      "120/120 [==============================] - 0s 364us/step - loss: 0.0472 - acc: 0.9833 - val_loss: 0.6391 - val_acc: 0.6667\n",
      "Epoch 149/200\n",
      "120/120 [==============================] - 0s 401us/step - loss: 0.0498 - acc: 0.9833 - val_loss: 0.5837 - val_acc: 0.6667\n",
      "Epoch 150/200\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.0474 - acc: 0.9833 - val_loss: 0.7155 - val_acc: 0.6667\n",
      "Epoch 151/200\n",
      "120/120 [==============================] - 0s 364us/step - loss: 0.0477 - acc: 0.9833 - val_loss: 0.6923 - val_acc: 0.6667\n",
      "Epoch 152/200\n",
      "120/120 [==============================] - 0s 413us/step - loss: 0.0490 - acc: 0.9833 - val_loss: 0.5924 - val_acc: 0.6667\n",
      "Epoch 153/200\n",
      "120/120 [==============================] - 0s 368us/step - loss: 0.0480 - acc: 0.9833 - val_loss: 0.6021 - val_acc: 0.6667\n",
      "Epoch 154/200\n",
      "120/120 [==============================] - 0s 417us/step - loss: 0.0479 - acc: 0.9750 - val_loss: 0.5068 - val_acc: 0.7333\n",
      "Epoch 155/200\n",
      "120/120 [==============================] - 0s 380us/step - loss: 0.0500 - acc: 0.9750 - val_loss: 0.6317 - val_acc: 0.6667\n",
      "Epoch 156/200\n",
      "120/120 [==============================] - 0s 409us/step - loss: 0.0471 - acc: 0.9833 - val_loss: 0.7392 - val_acc: 0.6667\n",
      "Epoch 157/200\n",
      "120/120 [==============================] - 0s 413us/step - loss: 0.0487 - acc: 0.9833 - val_loss: 0.6410 - val_acc: 0.6667\n",
      "Epoch 158/200\n",
      "120/120 [==============================] - 0s 475us/step - loss: 0.0486 - acc: 0.9750 - val_loss: 0.6403 - val_acc: 0.6667\n",
      "Epoch 159/200\n",
      "120/120 [==============================] - 0s 372us/step - loss: 0.0476 - acc: 0.9833 - val_loss: 0.5564 - val_acc: 0.7000\n",
      "Epoch 160/200\n",
      "120/120 [==============================] - 0s 438us/step - loss: 0.0435 - acc: 0.9833 - val_loss: 0.5427 - val_acc: 0.7000\n",
      "Epoch 161/200\n",
      "120/120 [==============================] - 0s 360us/step - loss: 0.0499 - acc: 0.9750 - val_loss: 0.6494 - val_acc: 0.6667\n",
      "Epoch 162/200\n",
      "120/120 [==============================] - 0s 360us/step - loss: 0.0479 - acc: 0.9833 - val_loss: 0.6588 - val_acc: 0.6667\n",
      "Epoch 163/200\n",
      "120/120 [==============================] - 0s 364us/step - loss: 0.0452 - acc: 0.9833 - val_loss: 0.7666 - val_acc: 0.6667\n",
      "Epoch 164/200\n",
      "120/120 [==============================] - 0s 409us/step - loss: 0.0480 - acc: 0.9833 - val_loss: 0.7683 - val_acc: 0.6667\n",
      "Epoch 165/200\n",
      "120/120 [==============================] - 0s 360us/step - loss: 0.0462 - acc: 0.9750 - val_loss: 0.7187 - val_acc: 0.6667\n",
      "Epoch 166/200\n",
      "120/120 [==============================] - 0s 351us/step - loss: 0.0475 - acc: 0.9833 - val_loss: 0.6910 - val_acc: 0.6667\n",
      "Epoch 167/200\n",
      "120/120 [==============================] - 0s 380us/step - loss: 0.0465 - acc: 0.9833 - val_loss: 0.5722 - val_acc: 0.6667\n",
      "Epoch 168/200\n",
      "120/120 [==============================] - 0s 422us/step - loss: 0.0469 - acc: 0.9833 - val_loss: 0.6528 - val_acc: 0.6667\n",
      "Epoch 169/200\n",
      "120/120 [==============================] - 0s 372us/step - loss: 0.0479 - acc: 0.9833 - val_loss: 0.5811 - val_acc: 0.6667\n",
      "Epoch 170/200\n",
      "120/120 [==============================] - 0s 413us/step - loss: 0.0472 - acc: 0.9833 - val_loss: 0.5219 - val_acc: 0.7333\n",
      "Epoch 171/200\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0101 - acc: 1.000 - 0s 372us/step - loss: 0.0464 - acc: 0.9750 - val_loss: 0.6323 - val_acc: 0.6667\n",
      "Epoch 172/200\n",
      "120/120 [==============================] - 0s 430us/step - loss: 0.0470 - acc: 0.9833 - val_loss: 0.7084 - val_acc: 0.6667\n",
      "Epoch 173/200\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.0479 - acc: 0.9833 - val_loss: 0.5685 - val_acc: 0.6667\n",
      "Epoch 174/200\n",
      "120/120 [==============================] - 0s 389us/step - loss: 0.0447 - acc: 0.9833 - val_loss: 0.6313 - val_acc: 0.6667\n",
      "Epoch 175/200\n",
      "120/120 [==============================] - 0s 384us/step - loss: 0.0433 - acc: 0.9833 - val_loss: 0.5540 - val_acc: 0.7000\n",
      "Epoch 176/200\n",
      "120/120 [==============================] - 0s 351us/step - loss: 0.0471 - acc: 0.9750 - val_loss: 0.5784 - val_acc: 0.6667\n",
      "Epoch 177/200\n",
      "120/120 [==============================] - 0s 459us/step - loss: 0.0465 - acc: 0.9833 - val_loss: 0.5479 - val_acc: 0.7333\n",
      "Epoch 178/200\n",
      "120/120 [==============================] - 0s 393us/step - loss: 0.0427 - acc: 0.9833 - val_loss: 0.4831 - val_acc: 0.7333\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 393us/step - loss: 0.0471 - acc: 0.9750 - val_loss: 0.5750 - val_acc: 0.7000\n",
      "Epoch 180/200\n",
      "120/120 [==============================] - 0s 318us/step - loss: 0.0456 - acc: 0.9750 - val_loss: 0.5195 - val_acc: 0.7333\n",
      "Epoch 181/200\n",
      "120/120 [==============================] - 0s 417us/step - loss: 0.0449 - acc: 0.9833 - val_loss: 0.7191 - val_acc: 0.6667\n",
      "Epoch 182/200\n",
      "120/120 [==============================] - 0s 364us/step - loss: 0.0422 - acc: 0.9833 - val_loss: 0.9109 - val_acc: 0.6333\n",
      "Epoch 183/200\n",
      "120/120 [==============================] - 0s 393us/step - loss: 0.0474 - acc: 0.9750 - val_loss: 0.7252 - val_acc: 0.6667\n",
      "Epoch 184/200\n",
      "120/120 [==============================] - 0s 405us/step - loss: 0.0439 - acc: 0.9833 - val_loss: 0.7697 - val_acc: 0.6667\n",
      "Epoch 185/200\n",
      "120/120 [==============================] - 0s 393us/step - loss: 0.0478 - acc: 0.9833 - val_loss: 0.6797 - val_acc: 0.6667\n",
      "Epoch 186/200\n",
      "120/120 [==============================] - 0s 393us/step - loss: 0.0468 - acc: 0.9833 - val_loss: 0.6311 - val_acc: 0.6667\n",
      "Epoch 187/200\n",
      "120/120 [==============================] - 0s 397us/step - loss: 0.0457 - acc: 0.9833 - val_loss: 0.6411 - val_acc: 0.6667\n",
      "Epoch 188/200\n",
      "120/120 [==============================] - 0s 351us/step - loss: 0.0451 - acc: 0.9833 - val_loss: 0.5641 - val_acc: 0.7000\n",
      "Epoch 189/200\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.0458 - acc: 0.9750 - val_loss: 0.6673 - val_acc: 0.6667\n",
      "Epoch 190/200\n",
      "120/120 [==============================] - 0s 422us/step - loss: 0.0454 - acc: 0.9833 - val_loss: 0.7288 - val_acc: 0.6667\n",
      "Epoch 191/200\n",
      "120/120 [==============================] - 0s 347us/step - loss: 0.0461 - acc: 0.9833 - val_loss: 0.7075 - val_acc: 0.6667\n",
      "Epoch 192/200\n",
      "120/120 [==============================] - 0s 417us/step - loss: 0.0451 - acc: 0.9833 - val_loss: 0.5678 - val_acc: 0.7000\n",
      "Epoch 193/200\n",
      "120/120 [==============================] - 0s 368us/step - loss: 0.0462 - acc: 0.9833 - val_loss: 0.5972 - val_acc: 0.6667\n",
      "Epoch 194/200\n",
      "120/120 [==============================] - 0s 455us/step - loss: 0.0429 - acc: 0.9750 - val_loss: 0.5850 - val_acc: 0.7000\n",
      "Epoch 195/200\n",
      "120/120 [==============================] - 0s 397us/step - loss: 0.0426 - acc: 0.9833 - val_loss: 0.4840 - val_acc: 0.7333\n",
      "Epoch 196/200\n",
      "120/120 [==============================] - 0s 389us/step - loss: 0.0438 - acc: 0.9833 - val_loss: 0.4388 - val_acc: 0.8000\n",
      "Epoch 197/200\n",
      "120/120 [==============================] - 0s 355us/step - loss: 0.0457 - acc: 0.9833 - val_loss: 0.4782 - val_acc: 0.7333\n",
      "Epoch 198/200\n",
      "120/120 [==============================] - 0s 389us/step - loss: 0.0452 - acc: 0.9750 - val_loss: 0.4934 - val_acc: 0.7333\n",
      "Epoch 199/200\n",
      "120/120 [==============================] - 0s 364us/step - loss: 0.0466 - acc: 0.9833 - val_loss: 0.5650 - val_acc: 0.7333\n",
      "Epoch 200/200\n",
      "120/120 [==============================] - 0s 393us/step - loss: 0.0449 - acc: 0.9833 - val_loss: 0.5699 - val_acc: 0.7000\n",
      "acc: 92.67%\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "# Keras——模型训练可视化\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "# 导入数据\n",
    "dataset = datasets.load_iris()\n",
    "x = dataset.data\n",
    "Y = dataset.target\n",
    "# 将标签转换成分类编码\n",
    "Y_labels = to_categorical(Y, num_classes=3)\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# 构建模型函数\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init))\n",
    "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "# 构建模型\n",
    "model = create_model()\n",
    "history = model.fit(x, Y_labels, validation_split=0.2, epochs=200, batch_size=5, verbose=1)\n",
    "# 评估模型\n",
    "scores = model.evaluate(x, Y_labels, verbose=0)\n",
    "print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n",
    "\n",
    "# Hisotry列表.history类对象包含两个属性，分别为训练轮数epoch和字典history(包含val_loss,val_acc,loss,acc四个key值)。\n",
    "print(history.history.keys())\n",
    "# accuracy的历史\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "current_path = r'C:/Users/Lenovo/Desktop/data/image/'\n",
    "plt.savefig(current_path+'accuracy.png')\n",
    "plt.close()\n",
    "# loss的历史\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(current_path+'loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  app.launch_new_instance()\n",
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:26: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "# Keras——图像增强\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import mnist\n",
    "from keras import backend\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "backend.set_image_data_format('channels_first')\n",
    "\n",
    "# 从Keras导入Mnist数据集\n",
    "(X_train, y_train), (X_validation, y_validation) = mnist.load_data()\n",
    "# 显示9张手写数字的图片\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(331 + i)\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "plt.savefig('view_image.png')\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], 1, 28, 28).astype('float32')\n",
    "# 图像特征化\n",
    "imgGen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "imgGen.fit(X_train)\n",
    "for X_batch, y_batch in imgGen.flow(X_train, y_train, batch_size=9):\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(331 + i)\n",
    "        plt.imshow(X_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    plt.savefig('feature_standard.png')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35040, 1, 8) (35040,) (120, 1, 8) (120,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 50)             11800     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 32,051\n",
      "Trainable params: 32,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 35040 samples, validate on 120 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 84.2277 - val_loss: 111.4211\n",
      "Epoch 2/50\n",
      " - 2s - loss: 71.8700 - val_loss: 102.7730\n",
      "Epoch 3/50\n",
      " - 2s - loss: 62.2644 - val_loss: 92.8527\n",
      "Epoch 4/50\n",
      " - 2s - loss: 50.1496 - val_loss: 85.1986\n",
      "Epoch 5/50\n",
      " - 2s - loss: 42.3690 - val_loss: 79.7136\n",
      "Epoch 6/50\n",
      " - 2s - loss: 37.2724 - val_loss: 74.9667\n",
      "Epoch 7/50\n",
      " - 2s - loss: 33.9545 - val_loss: 70.6438\n",
      "Epoch 8/50\n",
      " - 2s - loss: 31.0778 - val_loss: 66.6638\n",
      "Epoch 9/50\n",
      " - 2s - loss: 28.5726 - val_loss: 63.0364\n",
      "Epoch 10/50\n",
      " - 2s - loss: 26.4079 - val_loss: 59.9056\n",
      "Epoch 11/50\n",
      " - 2s - loss: 24.5860 - val_loss: 56.9228\n",
      "Epoch 12/50\n",
      " - 2s - loss: 23.0634 - val_loss: 54.8652\n",
      "Epoch 13/50\n",
      " - 2s - loss: 21.7255 - val_loss: 53.1299\n",
      "Epoch 14/50\n",
      " - 2s - loss: 20.6375 - val_loss: 53.2470\n",
      "Epoch 15/50\n",
      " - 2s - loss: 19.6647 - val_loss: 53.3236\n",
      "Epoch 16/50\n",
      " - 2s - loss: 18.8917 - val_loss: 53.8349\n",
      "Epoch 17/50\n",
      " - 2s - loss: 18.1782 - val_loss: 54.1451\n",
      "Epoch 18/50\n",
      " - 2s - loss: 17.6100 - val_loss: 55.7247\n",
      "Epoch 19/50\n",
      " - 2s - loss: 17.0748 - val_loss: 56.6757\n",
      "Epoch 20/50\n",
      " - 2s - loss: 16.6389 - val_loss: 57.5160\n",
      "Epoch 21/50\n",
      " - 2s - loss: 16.2461 - val_loss: 58.5597\n",
      "Epoch 22/50\n",
      " - 2s - loss: 15.9158 - val_loss: 59.9370\n",
      "Epoch 23/50\n",
      " - 2s - loss: 15.6768 - val_loss: 60.6037\n",
      "Epoch 24/50\n",
      " - 2s - loss: 15.4230 - val_loss: 62.3705\n",
      "Epoch 25/50\n",
      " - 2s - loss: 15.2335 - val_loss: 62.3148\n",
      "Epoch 26/50\n",
      " - 2s - loss: 15.0500 - val_loss: 62.9292\n",
      "Epoch 27/50\n",
      " - 2s - loss: 14.9406 - val_loss: 64.2462\n",
      "Epoch 28/50\n",
      " - 2s - loss: 14.7691 - val_loss: 64.3810\n",
      "Epoch 29/50\n",
      " - 2s - loss: 14.6889 - val_loss: 65.8046\n",
      "Epoch 30/50\n",
      " - 2s - loss: 14.5476 - val_loss: 67.2666\n",
      "Epoch 31/50\n",
      " - 2s - loss: 14.4534 - val_loss: 68.0714\n",
      "Epoch 32/50\n",
      " - 2s - loss: 14.3813 - val_loss: 69.8761\n",
      "Epoch 33/50\n",
      " - 2s - loss: 14.2794 - val_loss: 69.9292\n",
      "Epoch 34/50\n",
      " - 2s - loss: 14.1993 - val_loss: 71.0288\n",
      "Epoch 35/50\n",
      " - 2s - loss: 14.1276 - val_loss: 72.1610\n",
      "Epoch 36/50\n",
      " - 2s - loss: 14.0598 - val_loss: 73.1019\n",
      "Epoch 37/50\n",
      " - 2s - loss: 14.0240 - val_loss: 74.6245\n",
      "Epoch 38/50\n",
      " - 2s - loss: 14.0268 - val_loss: 75.3606\n",
      "Epoch 39/50\n",
      " - 2s - loss: 13.9567 - val_loss: 76.9051\n",
      "Epoch 40/50\n",
      " - 2s - loss: 13.8842 - val_loss: 77.9738\n",
      "Epoch 41/50\n",
      " - 2s - loss: 13.8495 - val_loss: 77.9792\n",
      "Epoch 42/50\n",
      " - 2s - loss: 13.8359 - val_loss: 79.0540\n",
      "Epoch 43/50\n",
      " - 2s - loss: 13.7762 - val_loss: 81.7113\n",
      "Epoch 44/50\n",
      " - 2s - loss: 13.7557 - val_loss: 82.6794\n",
      "Epoch 45/50\n",
      " - 2s - loss: 13.7345 - val_loss: 84.0918\n",
      "Epoch 46/50\n",
      " - 2s - loss: 13.7156 - val_loss: 84.4048\n",
      "Epoch 47/50\n",
      " - 2s - loss: 13.6884 - val_loss: 85.7412\n",
      "Epoch 48/50\n",
      " - 2s - loss: 13.6588 - val_loss: 85.7443\n",
      "Epoch 49/50\n",
      " - 2s - loss: 13.6400 - val_loss: 86.1823\n",
      "Epoch 50/50\n",
      " - 2s - loss: 13.6310 - val_loss: 88.3814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "# Keras——基于多变量时间序列的PM2.5预测\n",
    "from pandas import DataFrame, concat, read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "batch_size = 72\n",
    "epochs = 50\n",
    "# 通过过去几次的数据进行预测\n",
    "n_input = 1\n",
    "n_train_hours = 365 * 24 * 4\n",
    "n_validation_hours = 24 * 5\n",
    "\n",
    "current_path = r'C:/Users/Lenovo/Desktop/data/'\n",
    "file_path = r'data/pollution_original.csv'\n",
    "filename = current_path + file_path\n",
    "\n",
    "def prase(x):\n",
    "    return datetime.strptime(x, '%Y %m %d %H')\n",
    "\n",
    "def load_dataset():\n",
    "    # 导入数据\n",
    "    dataset = read_csv(filename, parse_dates=[['year', 'month', 'day', 'hour']], index_col=0, date_parser=prase)\n",
    "    # 删除No.列\n",
    "    dataset.drop('No', axis=1, inplace=True)\n",
    "    # 设定列名\n",
    "    dataset.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']\n",
    "    dataset.index.name = 'date'\n",
    "    # 使用中位数填充缺失值\n",
    "    dataset['pollution'].fillna(dataset['pollution'].mean(), inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def convert_dataset(data, n_input=1, out_index=0, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = [], []\n",
    "    # 输入序列 (t-n, ... t-1)\n",
    "    for i in range(n_input, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # 输出结果 (t)\n",
    "    cols.append(df[df.columns[out_index]])\n",
    "    names += ['result']\n",
    "    # 合并输入输出序列\n",
    "    result = concat(cols, axis=1)\n",
    "    result.columns = names\n",
    "    # 删除包含缺失值的行\n",
    "    if dropnan:\n",
    "        result.dropna(inplace=True)\n",
    "    return result\n",
    "\n",
    "# class_indexs 编码的字段序列号，或者序列号List，列号从0开始\n",
    "def class_encode(data, class_indexs):\n",
    "    encoder = LabelEncoder()\n",
    "    class_indexs = class_indexs if type(class_indexs) is list else [class_indexs]\n",
    "    values = DataFrame(data).values\n",
    "    for index in class_indexs:\n",
    "        values[:, index] = encoder.fit_transform(values[:, index])\n",
    "    return DataFrame(values) if type(data) is DataFrame else values\n",
    "\n",
    "def build_model(lstm_input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, input_shape=lstm_input_shape, return_sequences=True))\n",
    "    model.add(LSTM(units=50, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 导入数据\n",
    "    data = load_dataset()\n",
    "    # 对风向列进行编码\n",
    "    data = class_encode(data, 4)\n",
    "    # 生成数据集，使用前5次的数据，来预测新数据\n",
    "    dataset = convert_dataset(data, n_input=n_input)\n",
    "    values = dataset.values.astype('float32')\n",
    "    # 分类训练与评估数据集\n",
    "    train = values[:n_train_hours, :]\n",
    "    validation = values[-n_validation_hours:, :]\n",
    "    x_train, y_train = train[:, :-1], train[:, -1]\n",
    "    x_validation, y_validation = validation[:, :-1], validation[:, -1]\n",
    "    # 数据归一元(0-1之间)\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_validation = scaler.fit_transform(x_validation)\n",
    "    # 将数据整理成【样本，时间步长，特征】结构\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1])\n",
    "    x_validation = x_validation.reshape(x_validation.shape[0], 1, x_validation.shape[1])\n",
    "    # 查看数据维度\n",
    "    print(x_train.shape, y_train.shape, x_validation.shape, y_validation.shape)\n",
    "    # 训练模型\n",
    "    lstm_input_shape = (x_train.shape[1], x_train.shape[2])\n",
    "    model = build_model(lstm_input_shape)\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, validation_data=(x_validation, y_validation), epochs=epochs,\n",
    "              verbose=2)\n",
    "    # 使用模型预测评估数据集\n",
    "    prediction = model.predict(x_validation)\n",
    "    # 图表显示\n",
    "    plt.plot(y_validation, color='blue', label='Actual')\n",
    "    plt.plot(prediction, color='green', label='Prediction')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    plt.savefig('PM2.5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 09:25:06.819317 10980 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0806 09:25:06.834693 10980 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0806 09:25:06.840645 10980 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0806 09:25:06.926452 10980 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0806 09:25:06.972084 10980 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0806 09:25:06.984484 10980 deprecation.py:323] From c:\\python3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0806 09:25:07.181893 10980 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s 464us/step - loss: 3.6813 - acc: 0.5938\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 175us/step - loss: 0.9318 - acc: 0.6029\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 147us/step - loss: 0.7398 - acc: 0.6380\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 134us/step - loss: 0.7059 - acc: 0.6641\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.6819 - acc: 0.6719\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.6504 - acc: 0.6823\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.6490 - acc: 0.6797\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.6361 - acc: 0.6875\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.6241 - acc: 0.6953\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.6287 - acc: 0.6784\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.6441 - acc: 0.6732\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.6397 - acc: 0.6732\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.6249 - acc: 0.6745\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.6174 - acc: 0.7018\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.6013 - acc: 0.6966\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5869 - acc: 0.7044\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 143us/step - loss: 0.5839 - acc: 0.7005\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.5994 - acc: 0.6888\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.5803 - acc: 0.7122\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5795 - acc: 0.7227\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5700 - acc: 0.7096\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.5820 - acc: 0.7005\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5742 - acc: 0.7135\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5691 - acc: 0.7305\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5572 - acc: 0.7396\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5705 - acc: 0.7044\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 141us/step - loss: 0.5551 - acc: 0.7227\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5550 - acc: 0.7318\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5737 - acc: 0.7161\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5610 - acc: 0.7227\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5685 - acc: 0.7188\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 134us/step - loss: 0.5639 - acc: 0.7148\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5525 - acc: 0.7201\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.5480 - acc: 0.7305\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.5484 - acc: 0.7240\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5655 - acc: 0.7057\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.5330 - acc: 0.7383\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.5400 - acc: 0.7253\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5466 - acc: 0.7253\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5445 - acc: 0.7266\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5437 - acc: 0.7331\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5365 - acc: 0.7422\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5296 - acc: 0.7448\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5337 - acc: 0.7487\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.5316 - acc: 0.7591\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.5283 - acc: 0.7487\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5332 - acc: 0.7396\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5330 - acc: 0.7422\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5332 - acc: 0.7487\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5271 - acc: 0.7409\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.5277 - acc: 0.7487\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5321 - acc: 0.7448\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5387 - acc: 0.7461\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 154us/step - loss: 0.5386 - acc: 0.7279\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5213 - acc: 0.7526\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.5303 - acc: 0.7448\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.5310 - acc: 0.7370\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.5215 - acc: 0.7500\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5132 - acc: 0.7630\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5350 - acc: 0.7344\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 155us/step - loss: 0.5251 - acc: 0.7357\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.5152 - acc: 0.7604\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 167us/step - loss: 0.5414 - acc: 0.7305\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 147us/step - loss: 0.5306 - acc: 0.7461\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.5213 - acc: 0.7448\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5053 - acc: 0.7513\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 143us/step - loss: 0.5154 - acc: 0.7396\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 136us/step - loss: 0.5134 - acc: 0.7552\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.5122 - acc: 0.7448\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 158us/step - loss: 0.5357 - acc: 0.7201\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 160us/step - loss: 0.5186 - acc: 0.7435\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 134us/step - loss: 0.5161 - acc: 0.7487\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 141us/step - loss: 0.5148 - acc: 0.7435\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5096 - acc: 0.7604\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5113 - acc: 0.7565\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 144us/step - loss: 0.5133 - acc: 0.7526\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 146us/step - loss: 0.5158 - acc: 0.7617\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 141us/step - loss: 0.5135 - acc: 0.7513\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5131 - acc: 0.7461\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.5093 - acc: 0.7617\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 137us/step - loss: 0.5031 - acc: 0.7708\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.5011 - acc: 0.7565\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 121us/step - loss: 0.5000 - acc: 0.7656\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4956 - acc: 0.7630\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 156us/step - loss: 0.5043 - acc: 0.7565\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5076 - acc: 0.7513\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.4971 - acc: 0.7591\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4987 - acc: 0.7643\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5031 - acc: 0.7747\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.5080 - acc: 0.7526\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.4977 - acc: 0.7604\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 134us/step - loss: 0.5041 - acc: 0.7513\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4972 - acc: 0.7630\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4962 - acc: 0.7721\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5025 - acc: 0.7487\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.4895 - acc: 0.7695\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4955 - acc: 0.7773\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4884 - acc: 0.7604\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4891 - acc: 0.7656\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4839 - acc: 0.7812\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4884 - acc: 0.7760\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4967 - acc: 0.7604\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4963 - acc: 0.7591\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4904 - acc: 0.7839\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5290 - acc: 0.7474\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4910 - acc: 0.7760\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4895 - acc: 0.7734\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5023 - acc: 0.7604\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.4854 - acc: 0.7630\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.4855 - acc: 0.7643\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4824 - acc: 0.7799\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4907 - acc: 0.7826\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.4967 - acc: 0.7539\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.4891 - acc: 0.7591\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4900 - acc: 0.7656\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4901 - acc: 0.7682\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4883 - acc: 0.7695\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4877 - acc: 0.7799\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4828 - acc: 0.7643\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4946 - acc: 0.7760\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4918 - acc: 0.7747\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.4807 - acc: 0.7799\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4852 - acc: 0.7656\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.4838 - acc: 0.7773\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4852 - acc: 0.7799\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.4784 - acc: 0.7669\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4854 - acc: 0.7708\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4701 - acc: 0.7708\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4793 - acc: 0.7747\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4693 - acc: 0.7891\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.4811 - acc: 0.7669\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.4792 - acc: 0.7786\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4813 - acc: 0.7734\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4843 - acc: 0.7760\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4725 - acc: 0.7682\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4699 - acc: 0.7773\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.4665 - acc: 0.7852\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4766 - acc: 0.7917\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4662 - acc: 0.7786\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4776 - acc: 0.7839\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4691 - acc: 0.7865\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4801 - acc: 0.7721\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4699 - acc: 0.7799\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.4720 - acc: 0.7878\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4854 - acc: 0.7617\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4895 - acc: 0.7656\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4803 - acc: 0.7812\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.4769 - acc: 0.773 - 0s 96us/step - loss: 0.4674 - acc: 0.7773\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4702 - acc: 0.7630\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4770 - acc: 0.7852\n",
      "768/768 [==============================] - 0s 79us/step\n",
      "\n",
      "acc : 77.73%\n"
     ]
    }
   ],
   "source": [
    "# Keras——基于多层感知器的印第安人糖尿病诊断\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# 设定随机数种子，使用固定随机种子初始化随机数生成器，这样就可以重复地运行相同的代码，并获得相同的结果\n",
    "np.random.seed(7)\n",
    "# 导入数据，使用np.loadtxt\n",
    "current_path = r'C:/Users/Lenovo/Desktop/data/'\n",
    "dataset = np.loadtxt(current_path+'data/pima-indians-diabetes.csv', delimiter=',')\n",
    "# 分割输入变量x和输出变量y\n",
    "x = dataset[:, 0 : 8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "# 创建模型，首先要确保输入层具有正确的输入维度。神经元数量（unit）初始化方法（init），激活函数activation\n",
    "# 使用三层连接的网络结构，通过Sequential的add函数将层添加到模型，并组合在一起\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))   # 第一个隐藏层有12个神经元，使用8个输入变量\n",
    "model.add(Dense(8, activation='relu'))               # 第二层隐藏层有8个神经元\n",
    "model.add(Dense(1, activation='sigmoid'))            # 输出层有一个神经元来预测数据结果\n",
    "\n",
    "# 评估一组权重的损失函数（loss），用于搜索网络不同权重的优化器（optimizer）\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=x, y=Y, epochs=150, batch_size=10)\n",
    "\n",
    "scores = model.evaluate(x=x, y=Y)\n",
    "print('\\n%s : %.2f%%' % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.0179 - acc: 0.3933\n",
      "Epoch 2/200\n",
      "150/150 [==============================] - 0s 255us/step - loss: 0.9654 - acc: 0.5467\n",
      "Epoch 3/200\n",
      "150/150 [==============================] - 0s 311us/step - loss: 0.9240 - acc: 0.5733\n",
      "Epoch 4/200\n",
      "150/150 [==============================] - 0s 341us/step - loss: 0.8788 - acc: 0.5867\n",
      "Epoch 5/200\n",
      "150/150 [==============================] - 0s 350us/step - loss: 0.8265 - acc: 0.6133\n",
      "Epoch 6/200\n",
      "150/150 [==============================] - 0s 443us/step - loss: 0.7805 - acc: 0.5067\n",
      "Epoch 7/200\n",
      "150/150 [==============================] - 0s 288us/step - loss: 0.7483 - acc: 0.4733\n",
      "Epoch 8/200\n",
      "150/150 [==============================] - 0s 351us/step - loss: 0.7220 - acc: 0.6133\n",
      "Epoch 9/200\n",
      "150/150 [==============================] - 0s 350us/step - loss: 0.6982 - acc: 0.8000\n",
      "Epoch 10/200\n",
      "150/150 [==============================] - 0s 327us/step - loss: 0.6750 - acc: 0.8533\n",
      "Epoch 11/200\n",
      "150/150 [==============================] - 0s 407us/step - loss: 0.6531 - acc: 0.9000\n",
      "Epoch 12/200\n",
      "150/150 [==============================] - 0s 453us/step - loss: 0.6323 - acc: 0.9333\n",
      "Epoch 13/200\n",
      "150/150 [==============================] - 0s 304us/step - loss: 0.6125 - acc: 0.9400\n",
      "Epoch 14/200\n",
      "150/150 [==============================] - 0s 321us/step - loss: 0.5962 - acc: 0.9133\n",
      "Epoch 15/200\n",
      "150/150 [==============================] - 0s 403us/step - loss: 0.5786 - acc: 0.9267\n",
      "Epoch 16/200\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.5613 - acc: 0.9333\n",
      "Epoch 17/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.5427 - acc: 0.9133\n",
      "Epoch 18/200\n",
      "150/150 [==============================] - 0s 357us/step - loss: 0.5294 - acc: 0.9267\n",
      "Epoch 19/200\n",
      "150/150 [==============================] - 0s 513us/step - loss: 0.5128 - acc: 0.9333\n",
      "Epoch 20/200\n",
      "150/150 [==============================] - 0s 288us/step - loss: 0.4970 - acc: 0.9200\n",
      "Epoch 21/200\n",
      "150/150 [==============================] - 0s 331us/step - loss: 0.4824 - acc: 0.9400\n",
      "Epoch 22/200\n",
      "150/150 [==============================] - 0s 413us/step - loss: 0.4681 - acc: 0.9400\n",
      "Epoch 23/200\n",
      "150/150 [==============================] - 0s 288us/step - loss: 0.4541 - acc: 0.9133\n",
      "Epoch 24/200\n",
      "150/150 [==============================] - 0s 407us/step - loss: 0.4394 - acc: 0.9400\n",
      "Epoch 25/200\n",
      "150/150 [==============================] - 0s 430us/step - loss: 0.4246 - acc: 0.9333\n",
      "Epoch 26/200\n",
      "150/150 [==============================] - 0s 291us/step - loss: 0.4130 - acc: 0.9400\n",
      "Epoch 27/200\n",
      "150/150 [==============================] - 0s 397us/step - loss: 0.4006 - acc: 0.9467\n",
      "Epoch 28/200\n",
      "150/150 [==============================] - 0s 291us/step - loss: 0.3882 - acc: 0.9467\n",
      "Epoch 29/200\n",
      "150/150 [==============================] - 0s 479us/step - loss: 0.3747 - acc: 0.9400\n",
      "Epoch 30/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.3620 - acc: 0.9333\n",
      "Epoch 31/200\n",
      "150/150 [==============================] - 0s 400us/step - loss: 0.3510 - acc: 0.9533\n",
      "Epoch 32/200\n",
      "150/150 [==============================] - 0s 165us/step - loss: 0.3381 - acc: 0.9533\n",
      "Epoch 33/200\n",
      "150/150 [==============================] - 0s 377us/step - loss: 0.3278 - acc: 0.9467\n",
      "Epoch 34/200\n",
      "150/150 [==============================] - 0s 417us/step - loss: 0.3164 - acc: 0.9467\n",
      "Epoch 35/200\n",
      "150/150 [==============================] - 0s 301us/step - loss: 0.3056 - acc: 0.9467\n",
      "Epoch 36/200\n",
      "150/150 [==============================] - 0s 192us/step - loss: 0.2931 - acc: 0.9467\n",
      "Epoch 37/200\n",
      "150/150 [==============================] - 0s 324us/step - loss: 0.2868 - acc: 0.9533\n",
      "Epoch 38/200\n",
      "150/150 [==============================] - 0s 331us/step - loss: 0.2741 - acc: 0.9600\n",
      "Epoch 39/200\n",
      "150/150 [==============================] - 0s 420us/step - loss: 0.2671 - acc: 0.9600\n",
      "Epoch 40/200\n",
      "150/150 [==============================] - 0s 255us/step - loss: 0.2581 - acc: 0.9533\n",
      "Epoch 41/200\n",
      "150/150 [==============================] - 0s 403us/step - loss: 0.2493 - acc: 0.9600\n",
      "Epoch 42/200\n",
      "150/150 [==============================] - 0s 281us/step - loss: 0.2414 - acc: 0.9600\n",
      "Epoch 43/200\n",
      "150/150 [==============================] - 0s 314us/step - loss: 0.2325 - acc: 0.9600\n",
      "Epoch 44/200\n",
      "150/150 [==============================] - 0s 420us/step - loss: 0.2253 - acc: 0.9600\n",
      "Epoch 45/200\n",
      "150/150 [==============================] - 0s 215us/step - loss: 0.2136 - acc: 0.9600\n",
      "Epoch 46/200\n",
      "150/150 [==============================] - 0s 410us/step - loss: 0.2122 - acc: 0.9533\n",
      "Epoch 47/200\n",
      "150/150 [==============================] - 0s 301us/step - loss: 0.2046 - acc: 0.9600\n",
      "Epoch 48/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.2005 - acc: 0.9467\n",
      "Epoch 49/200\n",
      "150/150 [==============================] - 0s 324us/step - loss: 0.1898 - acc: 0.9533\n",
      "Epoch 50/200\n",
      "150/150 [==============================] - 0s 334us/step - loss: 0.1855 - acc: 0.9667\n",
      "Epoch 51/200\n",
      "150/150 [==============================] - 0s 377us/step - loss: 0.1827 - acc: 0.9600\n",
      "Epoch 52/200\n",
      "150/150 [==============================] - 0s 274us/step - loss: 0.1777 - acc: 0.9733\n",
      "Epoch 53/200\n",
      "150/150 [==============================] - 0s 357us/step - loss: 0.1727 - acc: 0.9667\n",
      "Epoch 54/200\n",
      "150/150 [==============================] - 0s 344us/step - loss: 0.1681 - acc: 0.9600\n",
      "Epoch 55/200\n",
      "150/150 [==============================] - 0s 304us/step - loss: 0.1645 - acc: 0.9533\n",
      "Epoch 56/200\n",
      "150/150 [==============================] - 0s 413us/step - loss: 0.1623 - acc: 0.9600\n",
      "Epoch 57/200\n",
      "150/150 [==============================] - 0s 288us/step - loss: 0.1572 - acc: 0.9600\n",
      "Epoch 58/200\n",
      "150/150 [==============================] - 0s 294us/step - loss: 0.1553 - acc: 0.9600\n",
      "Epoch 59/200\n",
      "150/150 [==============================] - 0s 380us/step - loss: 0.1508 - acc: 0.9600\n",
      "Epoch 60/200\n",
      "150/150 [==============================] - 0s 284us/step - loss: 0.1478 - acc: 0.9600\n",
      "Epoch 61/200\n",
      "150/150 [==============================] - 0s 228us/step - loss: 0.1457 - acc: 0.9667\n",
      "Epoch 62/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.1410 - acc: 0.9667\n",
      "Epoch 63/200\n",
      "150/150 [==============================] - 0s 251us/step - loss: 0.1407 - acc: 0.9533\n",
      "Epoch 64/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.1343 - acc: 0.9667\n",
      "Epoch 65/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.1361 - acc: 0.9600\n",
      "Epoch 66/200\n",
      "150/150 [==============================] - 0s 215us/step - loss: 0.1376 - acc: 0.9600\n",
      "Epoch 67/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.1296 - acc: 0.9600\n",
      "Epoch 68/200\n",
      "150/150 [==============================] - 0s 265us/step - loss: 0.1304 - acc: 0.9733\n",
      "Epoch 69/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.1305 - acc: 0.9600\n",
      "Epoch 70/200\n",
      "150/150 [==============================] - 0s 228us/step - loss: 0.1276 - acc: 0.9600\n",
      "Epoch 71/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.1237 - acc: 0.9667\n",
      "Epoch 72/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.1244 - acc: 0.9667\n",
      "Epoch 73/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.1231 - acc: 0.9600\n",
      "Epoch 74/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.1223 - acc: 0.9600\n",
      "Epoch 75/200\n",
      "150/150 [==============================] - 0s 278us/step - loss: 0.1164 - acc: 0.9600\n",
      "Epoch 76/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.1176 - acc: 0.9667\n",
      "Epoch 77/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.1169 - acc: 0.9600\n",
      "Epoch 78/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.1151 - acc: 0.9600\n",
      "Epoch 79/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.1163 - acc: 0.9600\n",
      "Epoch 80/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1296 - acc: 0.956 - 0s 430us/step - loss: 0.1144 - acc: 0.9667\n",
      "Epoch 81/200\n",
      "150/150 [==============================] - 0s 374us/step - loss: 0.1115 - acc: 0.9600\n",
      "Epoch 82/200\n",
      "150/150 [==============================] - 0s 274us/step - loss: 0.1130 - acc: 0.9667\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 291us/step - loss: 0.1094 - acc: 0.9667\n",
      "Epoch 84/200\n",
      "150/150 [==============================] - 0s 255us/step - loss: 0.1116 - acc: 0.9600\n",
      "Epoch 85/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.1110 - acc: 0.9667\n",
      "Epoch 86/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.1111 - acc: 0.9600\n",
      "Epoch 87/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.1086 - acc: 0.9667\n",
      "Epoch 88/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.1039 - acc: 0.9600\n",
      "Epoch 89/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.1114 - acc: 0.9533\n",
      "Epoch 90/200\n",
      "150/150 [==============================] - 0s 301us/step - loss: 0.1086 - acc: 0.9733\n",
      "Epoch 91/200\n",
      "150/150 [==============================] - 0s 298us/step - loss: 0.1040 - acc: 0.9667\n",
      "Epoch 92/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.1066 - acc: 0.9667\n",
      "Epoch 93/200\n",
      "150/150 [==============================] - 0s 215us/step - loss: 0.1062 - acc: 0.9600\n",
      "Epoch 94/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.1024 - acc: 0.9600\n",
      "Epoch 95/200\n",
      "150/150 [==============================] - 0s 228us/step - loss: 0.1040 - acc: 0.9667\n",
      "Epoch 96/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.1029 - acc: 0.9667\n",
      "Epoch 97/200\n",
      "150/150 [==============================] - 0s 215us/step - loss: 0.1019 - acc: 0.9667\n",
      "Epoch 98/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.1022 - acc: 0.9667\n",
      "Epoch 99/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.1017 - acc: 0.9600\n",
      "Epoch 100/200\n",
      "150/150 [==============================] - 0s 215us/step - loss: 0.1014 - acc: 0.9667\n",
      "Epoch 101/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.1013 - acc: 0.9733\n",
      "Epoch 102/200\n",
      "150/150 [==============================] - 0s 198us/step - loss: 0.1013 - acc: 0.9600\n",
      "Epoch 103/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.1008 - acc: 0.9667\n",
      "Epoch 104/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.0984 - acc: 0.9667\n",
      "Epoch 105/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.1003 - acc: 0.9600\n",
      "Epoch 106/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.0966 - acc: 0.9667\n",
      "Epoch 107/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.1005 - acc: 0.9600\n",
      "Epoch 108/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.0995 - acc: 0.9733\n",
      "Epoch 109/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.0992 - acc: 0.9733\n",
      "Epoch 110/200\n",
      "150/150 [==============================] - 0s 228us/step - loss: 0.0987 - acc: 0.9667\n",
      "Epoch 111/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.1001 - acc: 0.9667\n",
      "Epoch 112/200\n",
      "150/150 [==============================] - 0s 218us/step - loss: 0.0978 - acc: 0.9600\n",
      "Epoch 113/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.0916 - acc: 0.9600\n",
      "Epoch 114/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.0992 - acc: 0.9733\n",
      "Epoch 115/200\n",
      "150/150 [==============================] - 0s 202us/step - loss: 0.0974 - acc: 0.9667\n",
      "Epoch 116/200\n",
      "150/150 [==============================] - 0s 198us/step - loss: 0.0956 - acc: 0.9667\n",
      "Epoch 117/200\n",
      "150/150 [==============================] - 0s 195us/step - loss: 0.0948 - acc: 0.9600\n",
      "Epoch 118/200\n",
      "150/150 [==============================] - 0s 185us/step - loss: 0.0935 - acc: 0.9667\n",
      "Epoch 119/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.0927 - acc: 0.9600\n",
      "Epoch 120/200\n",
      "150/150 [==============================] - 0s 188us/step - loss: 0.1023 - acc: 0.9800\n",
      "Epoch 121/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.0935 - acc: 0.9667\n",
      "Epoch 122/200\n",
      "150/150 [==============================] - 0s 192us/step - loss: 0.0959 - acc: 0.9667\n",
      "Epoch 123/200\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.0961 - acc: 0.9600\n",
      "Epoch 124/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.0951 - acc: 0.9667\n",
      "Epoch 125/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.0930 - acc: 0.9600\n",
      "Epoch 126/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.0959 - acc: 0.9667\n",
      "Epoch 127/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.0930 - acc: 0.9667\n",
      "Epoch 128/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.0952 - acc: 0.9667\n",
      "Epoch 129/200\n",
      "150/150 [==============================] - 0s 228us/step - loss: 0.0882 - acc: 0.9733\n",
      "Epoch 130/200\n",
      "150/150 [==============================] - 0s 202us/step - loss: 0.0880 - acc: 0.9667\n",
      "Epoch 131/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.0944 - acc: 0.9600\n",
      "Epoch 132/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.0915 - acc: 0.9733\n",
      "Epoch 133/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.0928 - acc: 0.9600\n",
      "Epoch 134/200\n",
      "150/150 [==============================] - 0s 205us/step - loss: 0.0936 - acc: 0.9667\n",
      "Epoch 135/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.0914 - acc: 0.9600\n",
      "Epoch 136/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.0923 - acc: 0.9667\n",
      "Epoch 137/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.0937 - acc: 0.9667\n",
      "Epoch 138/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.0936 - acc: 0.9600\n",
      "Epoch 139/200\n",
      "150/150 [==============================] - 0s 218us/step - loss: 0.0929 - acc: 0.9733\n",
      "Epoch 140/200\n",
      "150/150 [==============================] - 0s 192us/step - loss: 0.0947 - acc: 0.9667\n",
      "Epoch 141/200\n",
      "150/150 [==============================] - 0s 198us/step - loss: 0.0922 - acc: 0.9667\n",
      "Epoch 142/200\n",
      "150/150 [==============================] - 0s 245us/step - loss: 0.0936 - acc: 0.9667\n",
      "Epoch 143/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.0906 - acc: 0.9667\n",
      "Epoch 144/200\n",
      "150/150 [==============================] - 0s 205us/step - loss: 0.0934 - acc: 0.9667\n",
      "Epoch 145/200\n",
      "150/150 [==============================] - 0s 202us/step - loss: 0.0885 - acc: 0.9733\n",
      "Epoch 146/200\n",
      "150/150 [==============================] - 0s 195us/step - loss: 0.0950 - acc: 0.9667\n",
      "Epoch 147/200\n",
      "150/150 [==============================] - 0s 218us/step - loss: 0.0921 - acc: 0.9733\n",
      "Epoch 148/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.0882 - acc: 0.9733\n",
      "Epoch 149/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.0900 - acc: 0.9733\n",
      "Epoch 150/200\n",
      "150/150 [==============================] - 0s 218us/step - loss: 0.0942 - acc: 0.9733\n",
      "Epoch 151/200\n",
      "150/150 [==============================] - 0s 228us/step - loss: 0.0911 - acc: 0.9733\n",
      "Epoch 152/200\n",
      "150/150 [==============================] - 0s 182us/step - loss: 0.0894 - acc: 0.9667\n",
      "Epoch 153/200\n",
      "150/150 [==============================] - 0s 195us/step - loss: 0.0941 - acc: 0.9533\n",
      "Epoch 154/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.0919 - acc: 0.9667\n",
      "Epoch 155/200\n",
      "150/150 [==============================] - 0s 215us/step - loss: 0.0900 - acc: 0.9733\n",
      "Epoch 156/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.0927 - acc: 0.9667\n",
      "Epoch 157/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.0893 - acc: 0.9667\n",
      "Epoch 158/200\n",
      "150/150 [==============================] - 0s 215us/step - loss: 0.0918 - acc: 0.9533\n",
      "Epoch 159/200\n",
      "150/150 [==============================] - 0s 212us/step - loss: 0.0870 - acc: 0.9733\n",
      "Epoch 160/200\n",
      "150/150 [==============================] - 0s 188us/step - loss: 0.0901 - acc: 0.9667\n",
      "Epoch 161/200\n",
      "150/150 [==============================] - 0s 198us/step - loss: 0.0890 - acc: 0.9667\n",
      "Epoch 162/200\n",
      "150/150 [==============================] - 0s 198us/step - loss: 0.0927 - acc: 0.9600\n",
      "Epoch 163/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.0889 - acc: 0.9600\n",
      "Epoch 164/200\n",
      "150/150 [==============================] - 0s 222us/step - loss: 0.0873 - acc: 0.9600\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 198us/step - loss: 0.0884 - acc: 0.9667\n",
      "Epoch 166/200\n",
      "150/150 [==============================] - 0s 202us/step - loss: 0.0909 - acc: 0.9600\n",
      "Epoch 167/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.0868 - acc: 0.9667\n",
      "Epoch 168/200\n",
      "150/150 [==============================] - 0s 185us/step - loss: 0.0892 - acc: 0.9733\n",
      "Epoch 169/200\n",
      "150/150 [==============================] - 0s 208us/step - loss: 0.0854 - acc: 0.9733\n",
      "Epoch 170/200\n",
      "150/150 [==============================] - 0s 225us/step - loss: 0.0915 - acc: 0.9667\n",
      "Epoch 171/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.0849 - acc: 0.9733\n",
      "Epoch 172/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.0891 - acc: 0.9600\n",
      "Epoch 173/200\n",
      "150/150 [==============================] - 0s 265us/step - loss: 0.0851 - acc: 0.9600\n",
      "Epoch 174/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.0829 - acc: 0.9667\n",
      "Epoch 175/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.0898 - acc: 0.9600\n",
      "Epoch 176/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.0910 - acc: 0.9733\n",
      "Epoch 177/200\n",
      "150/150 [==============================] - 0s 202us/step - loss: 0.0874 - acc: 0.9667\n",
      "Epoch 178/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.0807 - acc: 0.9800\n",
      "Epoch 179/200\n",
      "150/150 [==============================] - 0s 278us/step - loss: 0.0891 - acc: 0.9667\n",
      "Epoch 180/200\n",
      "150/150 [==============================] - 0s 354us/step - loss: 0.0883 - acc: 0.9667\n",
      "Epoch 181/200\n",
      "150/150 [==============================] - 0s 360us/step - loss: 0.0846 - acc: 0.9733\n",
      "Epoch 182/200\n",
      "150/150 [==============================] - 0s 278us/step - loss: 0.0869 - acc: 0.9667\n",
      "Epoch 183/200\n",
      "150/150 [==============================] - 0s 238us/step - loss: 0.0911 - acc: 0.9667\n",
      "Epoch 184/200\n",
      "150/150 [==============================] - 0s 231us/step - loss: 0.0860 - acc: 0.9667\n",
      "Epoch 185/200\n",
      "150/150 [==============================] - 0s 202us/step - loss: 0.0873 - acc: 0.9667\n",
      "Epoch 186/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.0896 - acc: 0.9600\n",
      "Epoch 187/200\n",
      "150/150 [==============================] - 0s 195us/step - loss: 0.0875 - acc: 0.9667\n",
      "Epoch 188/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.0859 - acc: 0.9667\n",
      "Epoch 189/200\n",
      "150/150 [==============================] - 0s 198us/step - loss: 0.0866 - acc: 0.9733\n",
      "Epoch 190/200\n",
      "150/150 [==============================] - 0s 235us/step - loss: 0.0808 - acc: 0.9667\n",
      "Epoch 191/200\n",
      "150/150 [==============================] - 0s 202us/step - loss: 0.0829 - acc: 0.9667\n",
      "Epoch 192/200\n",
      "150/150 [==============================] - 0s 241us/step - loss: 0.0862 - acc: 0.9667\n",
      "Epoch 193/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.0851 - acc: 0.9667\n",
      "Epoch 194/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.0865 - acc: 0.9667\n",
      "Epoch 195/200\n",
      "150/150 [==============================] - 0s 218us/step - loss: 0.0845 - acc: 0.9600\n",
      "Epoch 196/200\n",
      "150/150 [==============================] - 0s 251us/step - loss: 0.0863 - acc: 0.9733\n",
      "Epoch 197/200\n",
      "150/150 [==============================] - 0s 258us/step - loss: 0.0830 - acc: 0.9733\n",
      "Epoch 198/200\n",
      "150/150 [==============================] - 0s 274us/step - loss: 0.0922 - acc: 0.9667\n",
      "Epoch 199/200\n",
      "150/150 [==============================] - 0s 248us/step - loss: 0.0846 - acc: 0.9733\n",
      "Epoch 200/200\n",
      "150/150 [==============================] - 0s 202us/step - loss: 0.0848 - acc: 0.9667\n",
      "acc: 97.33%\n",
      "acc: 97.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\keras\\engine\\saving.py:473: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 97.33%\n"
     ]
    }
   ],
   "source": [
    "# Keras——基于JSON和YAML的模型序列化\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json,model_from_yaml\n",
    "# 导入数据\n",
    "dataset = datasets.load_iris()\n",
    "x = dataset.data\n",
    "Y = dataset.target\n",
    "Y_labels = to_categorical(Y, num_classes=3)\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# 构建模型函数\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init))\n",
    "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "# 构建模型\n",
    "model = create_model()\n",
    "model.fit(x, Y_labels, epochs=200, batch_size=5, verbose=1)\n",
    "scores = model.evaluate(x, Y_labels, verbose=0)\n",
    "print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n",
    "\n",
    "current_path = r'C:/Users/Lenovo/Desktop/data/'\n",
    "# 模型保存成Json文件\n",
    "model_json = model.to_json()\n",
    "with open(current_path + 'models/model.json', 'w') as file:\n",
    "    file.write(model_json)\n",
    "# 保存模型的权重值\n",
    "model.save_weights(current_path+'models/model.json.h5')\n",
    "\n",
    "# 从Json加载模型\n",
    "with open(current_path+'models/model.json', 'r') as file:\n",
    "    model_json = file.read()\n",
    "# 加载模型\n",
    "new_model = model_from_json(model_json)\n",
    "new_model.load_weights(current_path+'models/model.json.h5')\n",
    "# 编译模型\n",
    "new_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# 评估从Json加载的模型\n",
    "scores = new_model.evaluate(x, Y_labels, verbose=0)\n",
    "print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n",
    "\n",
    "# 模型保存成Yaml文件\n",
    "model_yaml = model.to_yaml()\n",
    "with open(current_path + 'models/model.yaml', 'w') as file:\n",
    "    file.write(model_yaml)\n",
    "# 保存模型的权重值\n",
    "model.save_weights(current_path + 'models/model.yaml.h5')\n",
    "# 从Json加载模型\n",
    "with open(current_path + 'models/model.yaml', 'r') as file:\n",
    "    model_json = file.read()\n",
    "# 加载模型\n",
    "new_model = model_from_yaml(model_json)\n",
    "new_model.load_weights(current_path + 'models/model.yaml.h5')\n",
    "# 编译模型\n",
    "new_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# 评估从YAML加载的模型\n",
    "scores = new_model.evaluate(x, Y_labels, verbose=0)\n",
    "print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 36.67% (0.11)\n"
     ]
    }
   ],
   "source": [
    "# Keras——基于CNN模型和鸢尾花数据集的分类\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "# 导入数据\n",
    "dataset = datasets.load_iris()\n",
    "x = dataset.data\n",
    "Y = dataset.target\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# 构建模型函数\n",
    "def create_model(optimizer='adam', init='glorot_uniform'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init))\n",
    "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(units=3, activation='relu', kernel_initializer=init))\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=200, batch_size=5, verbose=0)\n",
    "# 模型评估\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, x, Y, cv=kfold)\n",
    "print('Accuracy: %.2f%% (%.2f)' % (results.mean()*100, results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras——基于CNN模型和CIFAR-10数据集的分类\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils\n",
    "from keras import backend\n",
    "backend.set_image_data_format('channels_first')\n",
    "\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed=seed)\n",
    "# 导入数据\n",
    "(X_train, y_train), (X_validation, y_validation) = cifar10.load_data()\n",
    "# 格式化数据到0-1之间\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_validation = X_validation.astype('float32') / 255.0\n",
    "# one-hot编码\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_validation = np_utils.to_categorical(y_validation)\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "# 简单卷积神经网络:两个卷积层、一个池化层、一个Flatten层和一个全连接层\n",
    "def create_model(epochs=25):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    lrate = 0.01\n",
    "    decay = lrate / epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "epochs = 25\n",
    "model = create_model(epochs)\n",
    "model.fit(x=X_train, y=y_train, epochs=epochs, batch_size=32, verbose=2)\n",
    "scores = model.evaluate(x=X_validation, y=y_validation, verbose=0)\n",
    "print('Accuracy: %.2f%%' % (scores[1] * 100))\n",
    "\n",
    "# 大型卷积神经网络:按照特征图是32、64、128各两次重复构建模型。\n",
    "def create_model2(epochs=25):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    lrate = 0.01\n",
    "    decay = lrate / epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model2 = create_model2(epochs)\n",
    "model2.fit(x=X_train, y=y_train, epochs=epochs, batch_size=32, verbose=2)\n",
    "scores = model2.evaluate(x=X_validation, y=y_validation, verbose=0)\n",
    "print('Accuracy: %.2f%%' % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras——基于CNN模型和MNIST数据集的手写数字识别\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import  Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend\n",
    "backend.set_image_data_format('channels_first')\n",
    "\n",
    "# 从Keras导入Mnist数据集\n",
    "(X_train, y_train), (X_validation, y_validation) = mnist.load_data()\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "print(num_pixels, X_train.shape, y_validation.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32') / 255.0\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], num_pixels).astype('float32') / 255.0\n",
    "# one-hot编码\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_validation = np_utils.to_categorical(y_validation)\n",
    "num_classes = y_validation.shape[1]\n",
    "print(num_classes)\n",
    "\n",
    "# 定义基准多层感知机MLP模型:输入层784，隐藏层784，输出层10\n",
    "def create_model():\n",
    "    # 创建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model = create_model()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=200)\n",
    "score = model.evaluate(X_validation, y_validation)\n",
    "print('MLP: %.2f%%' % (score[1] * 100))\n",
    "\n",
    "# 定义简单卷积神经网络：输入784，卷积层32maps5*5,池化层2*2，dropout层，flatten层，全连接层128，输出层10\n",
    "(X_train, y_train), (X_validation, y_validation) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32') / 255.0\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], 1, 28, 28).astype('float32') / 255.0\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_validation = np_utils.to_categorical(y_validation)\n",
    "def create_model2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model2 = create_model2()\n",
    "model2.fit(X_train, y_train, epochs=10, batch_size=200, verbose=2)\n",
    "score = model2.evaluate(X_validation, y_validation, verbose=0)\n",
    "print('CNN_Small: %.2f%%' % (score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
